This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
index.html
MAKER.txt
metadata.json
package.json
postcss.config.js
README.md
scripts/icon.js
src-tauri/build.rs
src-tauri/capabilities/default.json
src-tauri/capabilities/developer.json
src-tauri/Cargo.toml
src-tauri/src/lib.rs
src-tauri/src/main.rs
src-tauri/tauri.conf.json
src/App.tsx
src/components/AgentManager.tsx
src/components/CodeEditor.tsx
src/components/CodeViewer.tsx
src/components/FileExplorer.tsx
src/components/GitHistory.tsx
src/components/MakerVisualizer.tsx
src/components/MergeConflictResolver.tsx
src/components/PlanEditor.tsx
src/components/SettingsPanel.tsx
src/components/SystemLogs.tsx
src/components/TerminalView.tsx
src/components/Toast.tsx
src/components/VersionControl.tsx
src/components/VotingInspector.tsx
src/index.css
src/index.tsx
src/services/contextManager.ts
src/services/engine/decompositionService.ts
src/services/engine/votingService.ts
src/services/gitService.ts
src/services/languages/interface.ts
src/services/languages/python.ts
src/services/languages/registry.ts
src/services/languages/rust.ts
src/services/languages/typescript.ts
src/services/llm.ts
src/services/logger.ts
src/services/makerService.ts
src/services/projectService.ts
src/services/tauriBridge.ts
src/services/toolService.ts
src/services/virtualFileSystem.ts
src/types.ts
tsconfig.json
vite.config.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
# Node / JS
node_modules
dist
dist-ssr
*.local
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

# Vite
.vite/

# Rust / Tauri
src-tauri/target/
src-tauri/gen/
src-tauri/Cargo.lock

# MAKER Framework Specific
# We exclude the worktrees directory as these are temporary isolation chambers
.maker/worktrees/
.maker/logs/
# We keep the .maker/config.json though, as that tracks project state

# Environment Variables
.env
.env.*
!.env.example

# OS Generated
.DS_Store
.AppleDouble
.LSOverride
Thumbs.db
ehthumbs.db
Desktop.ini

# Editor directories
.vscode/*
!.vscode/extensions.json
.idea
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="index.html">
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MakerCode - Agentic Editor</title>
  <script type="module" src="/src/index.tsx"></script>
  <link rel="stylesheet" href="/src/index.css">
</head>

<body class="bg-gray-950 text-gray-100 antialiased overflow-hidden h-screen w-screen">
  <div id="root"></div>
</body>

</html>
</file>

<file path="MAKER.txt">
Title: Solving a Million-Step LLM Task with Zero Errors

URL Source: https://arxiv.org/html/2511.09030v1

Published Time: Thu, 13 Nov 2025 01:26:57 GMT

Markdown Content:
Elliot Meyerson 

Cognizant AI Lab &Giuseppe Paolo 

Cognizant AI Lab &Roberto Dailey 

Cognizant AI Lab &Hormoz Shahrzad 

UT Austin & Cognizant AI Lab &Olivier Francon 

Cognizant AI Lab &Conor F. Hayes 

Cognizant AI Lab &Xin Qiu 

Cognizant AI Lab &Babak Hodjat 

Cognizant AI Lab &Risto Miikkulainen 

UT Austin & Cognizant AI Lab

###### Abstract

LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.

![Image 1: [Uncaptioned image]](https://arxiv.org/html/x1.png)

Figure 1: _Orthogonal directions to scaling AI._ The predominent approach to scaling AI is to make more and more ‚Äòintelligent‚Äô base LLMs. This paper introduces a framework and implementation of an orthogonal approach: MAKER, which solves the full task (described in Section[4](https://arxiv.org/html/2511.09030v1#S4 "4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")) with zero errors. In this figure, API cost per output token (as of 10/2025, from openai, anthropic, and together) is used as a proxy for intelligence, and consecutive error-free steps for base LLMs are computed from their per-step error rate (Figure[6](https://arxiv.org/html/2511.09030v1#S4.F6 "Figure 6 ‚Ä£ 4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")b). Appendix[A](https://arxiv.org/html/2511.09030v1#A1 "Appendix A Log Scale Version of Figure 1 ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") gives a log scale version of the plot. 

1 Introduction
--------------

Technological achievements of advanced societies are built on the capacity to reliably execute tasks with vast numbers of steps. Whether constructing a skyscraper, airplane, particle accelerator, or iPhone (which relies on tangible contributions from ‚âà1\approx 1 B people in an enormous supply chain spanning hundreds of suppliers across multiple countries [wikipedia_apple_supply_chain, apple_supplier_list]), running a hospital or medical research organization, processing tax returns and delivering social benefits at a national scale, or even something as seemingly simple as producing a loaf of bread [VegPatchKitchen_BreadStages], the precise execution of detailed plans and policies is critical to producing high-value outcomes and maintaining societal trust, as the impact of an error in such tasks can range from inconvenience to economic harm to physical harm to death.

Large language models (LLMs) are increasingly inserted into large and complex real-world processes like these. To maximize the benefit of using LLMs in these roles, it is critical to understand the limits of where and how LLMs can be reliably deployed. This paper focuses on the question of how/whether LLMs can execute large tasks with extreme precision, e.g., when a 1% per-step error rate is not acceptable.

This question is investigated by applying LLM-based reasoning to a task whose solution requires more than one million LLM steps with zero errors. The Towers of Hanoi problem, recently proposed as a benchmark for LLM reasoning [shojaee2025illusion], provides such a task. Most benchmarks for evaluating the quality of LLMs use independent examples, each requiring not many more than a few dependent logical execution steps [patel2024multistep], with a resulting score like accuracy averaged over all examples. Such a benchmark might be considered solved if the accuracy is 99%. However, a system with a 1% per-step error rate is expected to fail after only 100 steps of a million-step task. Therefore, solving a million-step task with zero errors requires a fundamentally different approach.

Such an approach is proposed in this paper: Massively decomposed agentic processes (MDAPs). The main contributions of this paper are as follows:

*   ‚Ä¢
A design of the MDAP framework, which consists of three core components: (1) decomposition into minimal subtasks; (2) error correction based on subtask-level voting; and (3) red-flagging to reduce correlated errors.

*   ‚Ä¢
A formalization of this framework that yields scaling laws, e.g., how probability of success and expected cost change w.r.t. the number of total steps and level of task decomposition. Under this formalization we find effective scaling under extreme decomposition and infeasibility without it.

*   ‚Ä¢
The empirical applications of the framework to successfully solve a task with over one million steps with zero errors. One main takeaway is that ‚Äòstate-of-the-art‚Äô reasoning models are not required; relatively small non-reasoning models suffice.

This paper provides a first implementation of the MDAP framework: MAKER (for M aximal A gentic decomposition, first-to-ahead-by-K E rror correction, and R ed-flagging), and evaluates it in the Towers of Hanoi domain. MAKER is a system of _agents_ in which each agent is assigned a single subtask to solve. In other words, the _role_ of each agent is defined by the subtask it is assigned. As advocated for in prior work [meyersonposition], by avoiding anthropomorphizing agents (i.e., by assigning them human-level roles) and instead assigning them tiny ‚Äòmicro-roles‚Äô, it is possible to exploit the inherent machine-like nature of LLMs. It may then be possible to take advantage of the kinds of error-correction methods that have been essential to scaling in many domains of computing, i.e., by assigning multiple agents to independently solve the same subtask.

The results demonstrate an instance of multi-agent advantage (akin to quantum advantage [harrow2017quantum]), that is, a solution to a problem that is not solvable by a monolithic single-agent system. This demonstration sets the stage for a new paradigm of scaling AI: instead of relying on continual improvement of simple underlying LLMs, more powerful AI is achieved through massively decomposed agentic processes (MDAPs).

2 Background
------------

While current LLM agents suffer from catastrophic errors on large tasks, there may be an opportunity for a multi-agent approach that decomposes the tasks into small steps. Error correction is critical for this process, as it is in many complex digital and biological systems.

### 2.1 Large Agentic LLM Tasks

As large language models have improved, increasing consideration has been given towards real world economic tasks that require multi-step, long horizon reasoning [kwa2025]. Research in this direction has repeatedly confirmed an inherent property of LLMs: their performance deteriorates significantly (and often exponentially) with the length of the task horizon, regardless of task complexity [schaeffer2023, Dziriexp]. This observation has led to the recent focus on the ability (and failure) of LLMs to _execute_, i.e., failing to complete many-step tasks, even when a correct plan to follow is explicitly provided to them [sinha2025]. While this work identified a fundamental liability of LLMs in long-horizon execution, it also presented an opportunity: Even small improvements in individual subtask performance could lead to exponential improvements in achievable task lengths [sinha2025].

At the same time, recent theoretical work has claimed that decomposing large tasks into the smallest possible subtasks can have substantial efficiency benefits [meyersonposition]. The rise of decomposing tasks into subtasks solvable by focused ‚Äúsmall language model‚Äù (SLM) agents in industry, motivated by both reliability and cost [belcak2025smalllanguagemodelsfuture], as well as the burgeoning study of multi-agent LLM systems in academia [guo2024largelanguagemodelbased, wang2024llm_agents_survey], provides evidence for the practicality of this idea. This paper continues this line of work. It is based on the premise that tasks should be broken up into the smallest possible elements, so that an LLM agent can focus on them one step at a time, improving per step error rate, and thus enabling scaling, reliability, and efficiency in the limit. Critical to the feasibility of such an approach is the granularity of the decomposition, i.e., what defines a single _step_. Since this paper focuses on execution, it is assumed the definition of step is given a priori; an orthogonal open question is how to automatically discover optimal decompositions [russell1991principles, horvitz2021ideal]. Informally, the main condition required for the methods in Section[3](https://arxiv.org/html/2511.09030v1#S3 "3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") to work is that steps are small enough that, for each step, a correct solution is likely to be sampled, and no incorrect solution is more likely.

Now, when an agentic system is applied to a long and expensive multi-step task, there is a natural desire to extract relevant information from responses even when formatted incorrectly. As a result, substantial work has gone in to generating correctly structured output from an LLM. Grammar-constrained (JSON/CFG) decoding reliably enforces structure and often improves downstream pipelines [geng2025jsonschemabench, openai2024structured], LLMs are fine-tuned to get the format right [grattafiori2024llama3herdmodels, qiu2025evolution], sampling is performed in a way that only tokens respecting the required format are selected [chen2022relation], and Python packages are developed dedicated to fixing an LLM‚Äôs output post-hoc so that it can be parsed in a meaningful way [pydantic, json_repair, guardrails_ai]. However, as described in Section[3.3](https://arxiv.org/html/2511.09030v1#S3.SS3 "3.3 Red-Flagging: Recognizing Signs of Unreliability ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"), when an agent makes an error in the output format, this error may indicate that its other reasoning is wrong as well. When a task has been broken into tiny pieces, this property may be exploited to mitigate errors.

### 2.2 Error Correction

Error correction is a critical capability across many important areas of computing, including communication [clark1981error, lin2004error], memory storage [chen1984error], and quantum computing [roffe2019quantum]. Error correction makes it possible to pretend that digital communication and classical computation are deterministic, when in fact, single bits are getting lost and flipped all the time [normand1996single, wang2008single]. Similarly, improved error correction is the single most important ingredient to achieving scalable quantum computing [fowler2012surface_code]. In biological systems, error correction is critical to large processes growing and persisting over time. Error correction is necessary both at the population level, e.g., through the error-correcting effects of recombination [otto2002resolving], and at the individual level, e.g., the cancer-fighting ability of mammals. At the individual level, it correlates highly with lifespan and body size (i.e., scale), with elephants showing the most impressive resistance [abegglen2015potential]. LLMs now serve as the basis of another substrate of computing, _linguistic computing_, whose constituent processes are _language-based algorithms_ (LbAs) [meyersonposition, chen2024design]. It should then come as no surprise that error correction is critical to achieving LbAs that scale, mitigating for the inherent nondeterminism that results from producing language by pulling from a probability distribution.

Many possible LbA error correction methods can be derived from instances in other fields [shannon1948]. One way to reduce errors is for an LLM to reflect on its output and explicitly correct any error it sees [manakul2023selfcheckgpt]. Another approach is to quantify and exploit LLM uncertainty explicitly [xue2023dynamicvoting, xin2024semantic]. For example, work on _semantic density_ shows that the semantic content most consistently sampled from an LLM for a given prompt is more likely to be correct than a greedy decoding [xin2024semantic]. This promise of semantic consistency in sampling makes a third, simpler, approach possible: voting, or _ensembling_, which has been a core machine learning technique for decades [opitz1999popular, mienye2022survey, ganaie2022ensemble], and is now commonly used to boost the accuracy of LLM-based systems [Trad2025voting]. To date, ensembling has mostly been implemented in LLMs at an action level far above that of a single minimal step. For example, state-of-the-art LLM-based coding systems often use a majority vote of outputs of complete programs that are each a candidate solution to a coding challenge [li2022alphacode, wang2022selfconsistency]. However, when scaling to tasks with thousands or millions of dependent steps, the level of granularity at which error correction is applied is critical, as will be shown in Section[3](https://arxiv.org/html/2511.09030v1#S3 "3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors").

### 2.3 Motivating Challenge Domain: Towers of Hanoi

Towers of Hanoi was recently introduced as a test domain for investigating the capabilities and limitations of state-of-the-art LLM reasoning models [shojaee2025illusion]. This benchmark is based on the classic game in which there are three pegs and D D disks, and the goal is to move all disks from the first to the third peg, moving only one disk at a time, and maintaining the condition that a larger disk never sits atop a smaller one [hinz2013tower]. In the benchmark, an LLM system is asked to produce a sequence of moves (m i=[d i,s i,t i])i=1 n(m_{i}=[d_{i},s_{i},t_{i}])_{i=1}^{n} whose execution completes the task, where the i i th move is executed by moving disk number d i‚àà{1,‚Ä¶,D}d_{i}\in\{1,...,D\} from source peg s i‚àà{0,1,2}s_{i}\in\{0,1,2\} to target peg t i‚àà{0,1,2}t_{i}\in\{0,1,2\}. The problem scales naturally to enormous numbers of required steps by simply adding more disks, since the optimal number of steps to complete the task is 2 D‚àí1 2^{D}-1. For example, solving Towers of Hanoi with ten disks takes just over a thousand steps, and with twenty disks just over a million steps. In its most famous (mythological) incarnation, monks work continuously on an instance with 64 disks, which is expected to take around 585 billion years, at which point the universe will end [moscovich20011].

Performance of state-of-the-art LLMs degrades catastrophically on this benchmark: They are able to complete the task with a high success rate up until five or six disks, after which the success rate plummets to zero [shojaee2025illusion]. What this degradation means with respect to whether or to what extent an LLM is really ‚Äòthinking‚Äô or ‚Äòreasoning‚Äô is up for philosophical debate and is outside the scope of this paper [varela2025rethinking, khan2025comment, opus2025illusion]. However, this result made it clear that the reliability of state-of-the-art LLMs is fundamentally limited: If they need to complete every step correctly in order to solve a task, after a certain number of steps they will almost surely fail as a result of an underlying propensity to make errors, even when the answer should be obvious. While an error rate of 1-in-1,000 seems low, and would be great on a traditional LLM benchmark, on a task that requires successful execution of thousands of steps in a row, such a system results in inevitable failure.

Two critiques of Towers of Hanoi as a benchmark should be addressed upfront. First, one could argue that it is not an ideal LLM task since one could write code to solve the problem, and optimal algorithms are known [hinz2013tower]. True, but producing solutions is not the point: instead, the domain provides an ideal testbed for investigating the capacity of LLM-based systems to scale their inherent intelligence to increasingly large numbers of steps. Second, one could argue that this problem is too hard, since large real-world tasks might allow for a handful of errors without catastrophic results [simon1957models]. However, focusing on a case where no error can be tolerated forces us to pursue the elimination of any kind of error that is likely to arise on a long timescale, and this focus can lead to insights and practical methods that might otherwise be overlooked. There also are real-world safety-critical systems where no error can be tolerated [kremer1993ring]. Therefore, as LLM-based systems become ubiquitous in real-world decision making processes, it is essential these systems can reliably make decisions without error. Thus, the problem provides an ideal testbed for developing techniques that will be critical to scaling LLM-based systems to one million steps and beyond.

Algorithm 1 generate_solution

1:Input x o,M,k x_{o},M,k

2:Initialize A‚Üê[]A\leftarrow[\,]‚ä≥\triangleright Action list

3:Initialize x‚Üêx o x\leftarrow x_{o}

4:for s s steps do

5:a,x‚Üêdo_voting‚Äã(x,M,k)a,x\leftarrow\text{do\_voting}(x,M,k)

6: Append a a to A A

7:end for

8:return A A

Algorithm 2 do_voting

1:Input: x,M,k x,M,k

2:V‚Üê{v:0‚Äã‚àÄv}V\leftarrow\{v:0\ \forall v\}‚ä≥\triangleright Vote counts

3:while True do

4:y‚Üêget_vote‚Äã(x,M)y\leftarrow\text{get\_vote}(x,M)

5:V‚Äã[y]=V‚Äã[y]+1 V[y]=V[y]+1

6:if V‚Äã[y]‚â•k+max v‚â†y‚Å°V‚Äã[v]V[y]\geq k+\max_{v\neq y}V[v]then

7:return y y

8:end if

9:end while

Algorithm 3 get_vote

1:Input x,M x,M

2:while True do

3:r‚àº(M‚àòœï)‚Äã(x)r\sim(M\circ\phi)(x)

4:if r r has no red flags then

5:return œà a‚Äã(r),œà x‚Äã(r)\psi_{a}(r),\psi_{x}(r)

6:end if

7:end while

Figure 2: _Core Components of MAKER._ (1) Maximal Agentic Decomposition (MAD; Section[3.1](https://arxiv.org/html/2511.09030v1#S3.SS1 "3.1 Maximal Agentic Decomposition ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")): By breaking a task with s s steps into s s subtasks, each agent can focus on a single step; (2) First-to-ahead-by-k k Voting (Section[3.2](https://arxiv.org/html/2511.09030v1#S3.SS2 "3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")): The modularity resulting from MAD makes error correction at the subtask level effective and scalable; (3) Red-flagging (Section[3.3](https://arxiv.org/html/2511.09030v1#S3.SS3 "3.3 Red-Flagging: Recognizing Signs of Unreliability ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")): Reliability can be further boosted by discarding any response r r with high-level indicators of risk. Together these methods enable scaling to solving a task with over one million steps with zero errors.

3 Methods
---------

MAKER involves three main ingredients (Figure[2](https://arxiv.org/html/2511.09030v1#S2.F2 "Figure 2 ‚Ä£ 2.3 Motivating Challenge Domain: Towers of Hanoi ‚Ä£ 2 Background ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")): (1) Decomposing a task into the smallest possible subtasks; (2) exploiting the modularity of such a decomposition to implement efficient error correction; and (3) ‚Äúred-flagging‚Äù LLM outputs, i.e., discarding outputs whose structure suggests increased risk of errors, particularly correlated errors. These three components are detailed in the next three subsections. Together, they make it possible to efficiently increase the probability of success across all steps to a level such that the entire process is likely to succeed.

### 3.1 Maximal Agentic Decomposition

In a long-horizon agentic task with s s steps, the goal of an LLM-based system is to produce a sequence of actions a 1,‚Ä¶,a s a_{1},\ldots,a_{s} that yields a target output y y given the initial input x x[sinha2025]. This paper is concerned with the following question: _How does the decomposition of the task into subtasks affect its solvability?_

The s s-step task can be decomposed into subtasks, with the granularity of the decomposition defined by the number of steps m m per subtask. Subtasks can then be solved by separate calls to LLM _agents_, where a templating function œï\phi maps the input and specification of a subtask to a prompt for an LLM M M, an extractor œà a\psi_{a} parses actions from the LLM‚Äôs output response r r, and a second extractor œà x\psi_{x} parses information from r r to include in the input to the next subtask. Let x 0=x x_{0}=x. A solution to the full task can then be sampled recursively:

r i+1\displaystyle r_{i+1}‚àºM‚Äã(œï‚Äã(x i)),\displaystyle\sim M(\phi(x_{i})),(1)
a m‚Äãi+1,‚Ä¶,a m‚Äãi+m\displaystyle a_{mi+1},\ldots,a_{mi+m}=œà a‚Äã(r i+1),\displaystyle=\psi_{a}(r_{i+1}),(2)
x i+1\displaystyle x_{i+1}=œà x‚Äã(r i+1)‚àÄi=0,‚Ä¶,s m‚àí1.\displaystyle=\psi_{x}(r_{i+1})\ \ \ \forall i=0,\ldots,\frac{s}{m}-1.(3)

Of particular interest are the two extreme cases: the case of no decomposition, i.e., m=s m=s, termed _single-agent_:

a 1,‚Ä¶,a s‚àº(œà a‚àòM‚àòœï)‚Äã(x);a_{1},\ldots,a_{s}\sim(\psi_{a}\circ M\circ\phi)(x);(4)

and the case of _maximal agentic decomposition_ (MAD), i.e., m=1 m=1:

r i+1\displaystyle r_{i+1}‚àºM‚Äã(œï‚Äã(x i)),\displaystyle\sim M(\phi(x_{i})),(5)
a i+1\displaystyle a_{i+1}=œà a‚Äã(r i+1),\displaystyle=\psi_{a}(r_{i+1}),(6)
x i+1\displaystyle x_{i+1}=œà x‚Äã(r i+1)‚àÄi=0,‚Ä¶,s‚àí1.\displaystyle=\psi_{x}(r_{i+1})\ \ \ \forall i=0,\ldots,s-1.(7)

Because LLMs are auto-regressive, when generating the i i th action, a single agent M M is increasingly burdened by the context produced in generating actions a 1,‚Ä¶,a i‚àí1 a_{1},\ldots,a_{i-1}. Therefore, as the context increases, its outputs become increasingly unreliable [du2025contextlengthhurtsllm]. However with MAD, an agent‚Äôs context is limited to an amount of information sufficient to execute its single assigned step, allowing it to focus on its assigned role and avoid confusion that can creep in from irrelevant context. This focus also allows the use of smaller LLMs with more limited context sizes.

One might argue that this decomposition might improve the reliability of any given LLM call, but by decomposing the task into s s independent calls, there are now s s possible points of failure, instead of just one. That is, there are s s opportunities for a weakest link to compromise the entire system, since for a correct action sequence a 1‚àó,‚Ä¶,a s‚àóa_{1}^{*},\ldots,a_{s}^{*}, the probability of generating it without error is exponentially decaying as the number of steps increases:

p‚Äã(a 1‚àó,‚Ä¶,a s‚àó)=‚àèi=0 s‚àí1 p‚Äã((œà a‚àòM‚àòœï)‚Äã(x i)=a i+1‚àó).p(a_{1}^{*},\ldots,a_{s}^{*})=\prod_{i=0}^{s-1}p\left((\psi_{a}\circ M\circ\phi)(x_{i})=a_{i+1}^{*}\right).(8)

First, note that a single long LLM call also suffers from a form of exponentially decaying probability of correctness [Dziriexp]. Second, and more importantly, the modularity induced through maximal decomposition allows for a form of effective and efficient error mitigation and unreliability detection (‚Äúred-flagging‚Äù) that is not possible with a single large call. These capabilities will be described in the next two subsections.

### 3.2 First-to-ahead-by-k k Voting and Scaling Laws

For simplicity, the error correction in this paper uses the statistical power of independent samples from a stochastic process (here an LLM). To determine a winner from these samples, a _first-to-ahead-by-k k_ voting process is used, motivated by the optimality of such an approach in the sequential probability ratio test (SPRT) [wald2004sequential, lee2025consol]. Many improvements are possible beyond this first implementation. For example, in the experiments in this paper, exact matches between actions are required, but in general, a classification function could be used to determine semantically equivalent outputs (e.g., implemented by an LLM, see Section[5](https://arxiv.org/html/2511.09030v1#S5 "5 Discussion and Future Work ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")).

Concretely, given an LLM M M, candidate samples are drawn for a subtask (Eq.[2](https://arxiv.org/html/2511.09030v1#S3.E2 "In 3.1 Maximal Agentic Decomposition ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")&[3](https://arxiv.org/html/2511.09030v1#S3.E3 "In 3.1 Maximal Agentic Decomposition ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")) until one has been sampled k k times more than any other (Alg.[2](https://arxiv.org/html/2511.09030v1#alg2 "Algorithm 2 ‚Ä£ Figure 2 ‚Ä£ 2.3 Motivating Challenge Domain: Towers of Hanoi ‚Ä£ 2 Background ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). This process is a generalization of the classic gambler‚Äôs ruin problem [bernoulli1713ars], but with simultaneous dependent races between all pairs of candidates [ross2025first]. Since there is no known closed form for this general case, the analysis is simplified by assuming the worst case, i.e., that a correct candidate with probability p p races against a single alternative with probability 1‚àíp 1-p. If p>0.5 p>0.5, the probability that the correct candidate gets selected through this process is

p‚Äã(a i=a‚àó)=1‚àí(1‚àíp p)k 1‚àí(1‚àíp p)2‚Äãk=p k p k+(1‚àíp)k=1 1+(1‚àíp p)k,p(a_{i}=a^{*})=\frac{1-\left(\frac{1-p}{p}\right)^{k}}{1-\left(\frac{1-p}{p}\right)^{2k}}=\frac{p^{k}}{p^{k}+(1-p)^{k}}=\frac{1}{1+\Big(\frac{1-p}{p}\Big)^{k}},(9)

and there exists some k k such that this voting process will result in the correct candidate winning with probability 1‚àíœµ 1-\epsilon, for any given error rate œµ‚àà(0,1)\epsilon\in(0,1).

![Image 2: Refer to caption](https://arxiv.org/html/x2.png)

(a) 

![Image 3: Refer to caption](https://arxiv.org/html/x3.png)

(b) 

Figure 3: _MAKER error-free solve rate scaling laws resulting from Eq.[13](https://arxiv.org/html/2511.09030v1#S3.E13 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")_. (a a) For a task with one million steps, MAKER, with first-to-ahead-by-k k error correction enables high probability zero-error solutions for practical values of k k, even as the base per-step error rate approaches 1-in-10; (b b) For the lower per-step error rates, in theory even a low k k allows scaling far beyond one million steps.

Now, suppose that the task requires s s total steps to complete, with an inherent per-step success rate p p, a decomposition level given by the number of steps per subtask m m, and suppose that a margin of k k votes is required to decide an action for each subtask. Again, assume that the correct solution for each subtask races against only a single most-likely alternative. Note that this assumption is much more favorable to larger values of m m, i.e., less decomposition, since a most likely alternative captures a vanishing proportion of the total alternative (incorrect) probability mass as m m grows. Let p vote p_{\textrm{vote}} be the probability of sampling a correct vote for a subtask, p alt p_{\textrm{alt}} the probability of sampling the alternative, p sub p_{\textrm{sub}} the probability that the voting procedure succeeds on a subtask, and p full p_{\textrm{full}} the probability that it succeeds on all subtasks, i.e., that the full task is completed successfully. Then,

p vote=p m,\displaystyle p_{\textrm{vote}}=p^{m},(10)
p alt=(1‚àíp)‚Äãp m‚àí1,\displaystyle p_{\textrm{alt}}=(1-p)p^{m-1},(11)
p sub=p vote k p vote k+p alt k=p m‚Äãk p m‚Äãk+((1‚àíp)‚Äãp m‚àí1)k=1 1+(1‚àíp p)k,\displaystyle p_{\textrm{sub}}=\frac{p_{\textrm{vote}}^{k}}{p_{\textrm{vote}}^{k}+p_{\textrm{alt}}^{k}}=\frac{p^{mk}}{p^{mk}+((1-p)p^{m-1})^{k}}=\frac{1}{1+\Big(\frac{1-p}{p}\Big)^{k}},(12)
p full=p sub s m=(1+(1‚àíp p)k)‚àís m,\displaystyle p_{\textrm{full}}=p_{\textrm{sub}}^{\frac{s}{m}}=\Bigg(1+\bigg(\frac{1-p}{p}\bigg)^{k}\Bigg)^{-\frac{s}{m}},(13)

where Eq.[12](https://arxiv.org/html/2511.09030v1#S3.E12 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") comes from plugging p vote p_{\textrm{vote}} and p alt p_{\textrm{alt}} into the hitting probability formula for gambler‚Äôs ruin [ross2025first]. Figure[3](https://arxiv.org/html/2511.09030v1#S3.F3 "Figure 3 ‚Ä£ 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") uses Eq.[13](https://arxiv.org/html/2511.09030v1#S3.E13 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") to illustrate how a high probability of overall success p full p_{\textrm{full}} can be maintained by increasing k k in the case of m=1 m=1, i.e. in a maximal decomposition.

Given Eq.[13](https://arxiv.org/html/2511.09030v1#S3.E13 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"), the expected cost of solving the entire task with a given level of reliability, i.e., given a target probability of overall success t t, can be computed. First, the minimal k k that yields success probability of at least t t is

k min=‚åàln‚Å°(t‚àím/s‚àí1)ln‚Å°(1‚àíp p)‚åâ=Œò‚Äã(ln‚Å°s).k_{\min}\;=\;\left\lceil\frac{\ln\left(t^{-m/s}-1\right)}{\ln\left(\frac{1-p}{p}\right)}\right\rceil\;=\;\Theta(\ln s).(14)

The detailed derivation is included in Appendix[B](https://arxiv.org/html/2511.09030v1#A2 "Appendix B Additional Derivations ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). Notably, k min k_{\min} grows logarithmically with s s no matter the decomposition level. Figure[4(a)](https://arxiv.org/html/2511.09030v1#S3.F4.sf1 "In Figure 4 ‚Ä£ 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows how k min k_{\min} scales with the number of steps when using MAD, i.e., when m=1 m=1.

![Image 4: Refer to caption](https://arxiv.org/html/x4.png)

(a) 

![Image 5: Refer to caption](https://arxiv.org/html/x5.png)

(b) 

Figure 4: _MAKER cost scaling laws resulting from Eqs.[14](https://arxiv.org/html/2511.09030v1#S3.E14 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") and [18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")._ (a a) The value of k k required in first-to-ahead-by-k k voting to maintain a 0.9 solution probability for the full task increases logarithmically with the number of steps in the task; (b b) The corresponding expected cost of running the system increases log-linearly. These plots illustrate the scalability of MAKER, in theory, to millions of steps and beyond. 

It is now possible to write down the expected cost in terms of calls to LLM primitives, i.e., perform AALPs analysis [meyersonposition]. Let c c be the cost of generating a response for a single step with LLM M M. Assuming the cost of generating tokens scales linearly with the number of tokens (since this is how APIs are priced), the cost of an agent generating a sample for m m steps is c sample=c‚Äãm c_{\textrm{sample}}=cm. Let c vote c_{\textrm{vote}} be the expected cost of sampling either a correct vote for a subtask or the alternative against which it races, c sub c_{\textrm{sub}} the expected cost of completing a subtask, and c full c_{\textrm{full}} the expected cost of completing the full task. Then,

c vote=c sample p vote+p alt=c‚Äãm p m+(1‚àíp)‚Äãp m‚àí1=c‚Äãm p m‚àí1,\displaystyle c_{\textrm{vote}}=\frac{c_{\textrm{sample}}}{p_{\textrm{vote}}+p_{\textrm{alt}}}=\frac{cm}{p^{m}+(1-p)p^{m-1}}=\frac{cm}{p^{m-1}},(15)
c sub=c vote‚ãÖ2‚Äãk min‚Äãp sub‚àík min 2‚Äãp‚àí1=c‚Äãm p m‚àí1‚ãÖ2‚Äãk min‚Äã(1+(1‚àíp p)k min)‚àí1‚àík min 2‚Äãp‚àí1‚âàc‚Äãm‚Äãk min p m‚àí1‚Äã(2‚Äãp‚àí1),\displaystyle c_{\textrm{sub}}=c_{\textrm{vote}}\cdot\frac{2k_{\min}p_{\textrm{sub}}-k_{\min}}{2p-1}=\frac{cm}{p^{m-1}}\cdot\frac{2k_{\min}\left(1+\left(\frac{1-p}{p}\right)^{k_{\min}}\right)^{-1}-k_{\min}}{2p-1}\approx\frac{cmk_{\min}}{p^{m-1}(2p-1)},(16)
c full=s m‚ãÖc sub=c‚Äãs‚Äãk min‚Äã(2‚Äã(1+(1‚àíp p)k min)‚àí1‚àí1)p m‚àí1‚Äã(2‚Äãp‚àí1)‚âàc‚Äãs‚Äãk min p m‚àí1‚Äã(2‚Äãp‚àí1)=Œò‚Äã(p‚àím‚Äãc‚Äãs‚Äãln‚Å°s),\displaystyle c_{\textrm{full}}=\frac{s}{m}\cdot c_{\textrm{sub}}=\frac{csk_{\min}\left(2\left(1+\left(\frac{1-p}{p}\right)^{k_{\min}}\right)^{-1}-1\right)}{p^{m-1}(2p-1)}\approx\frac{csk_{\min}}{p^{m-1}(2p-1)}=\Theta(p^{-m}cs\ln s),(17)

where Eq.[16](https://arxiv.org/html/2511.09030v1#S3.E16 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") comes from plugging Eq.[12](https://arxiv.org/html/2511.09030v1#S3.E12 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") into the hitting time for gambler‚Äôs ruin [bernoulli1713ars], Eq.[17](https://arxiv.org/html/2511.09030v1#S3.E17 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") comes from multiplying by the number of subtasks, and the approximation holds when p sub‚âà1 p_{\textrm{sub}}\approx 1, i.e., when the error tolerance is low. Notably, the cost grows exponentially with m m. Figure[5](https://arxiv.org/html/2511.09030v1#S3.F5 "Figure 5 ‚Ä£ 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") illustrates this phenomenon. As the number of meaningful decisions assigned to an agent grows, the chance that its sequence of decisions will match exactly across multiple samples vanishes. In contrast, in the MAD case, the system scales log-linearly with s s:

ùîº‚Äã[cost of solving full task;m=1]=Œò‚Äã(p‚àí1‚Äãc‚Äãs‚Äãln‚Å°s)=Œò‚Äã(s‚Äãln‚Å°s),\mathbb{E}[\textrm{cost of solving full task};m=1]=\Theta(p^{-1}cs\ln s)=\Theta(s\ln s),(18)

when p p, c c, and t t are held constant. Figure[4(b)](https://arxiv.org/html/2511.09030v1#S3.F4.sf2 "In Figure 4 ‚Ä£ 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") illustrates this efficient scaling. The discovery of algorithms that scale log-linearly has been critical to the scalability in classical computing [cormen2022introduction]. This result is therefore encouraging: It shows the potential of LLM-based systems to scale in a similar manner, increasing their reliability to a point where it is possible to trust them to complete long-running tasks. Furthermore, the Œò‚Äã(ln‚Å°s)\Theta(\ln s) factor in Eq.[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") corresponds to the number of votes required per step, which in practice can be parallelized across Œò‚Äã(ln‚Å°s)\Theta(\ln s) processes. So, the time cost of the parallelized system scales only linearly with s s.

Although Eq.[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows how MAD scales efficiently as the number of steps increases, in practice, the model cost c c and per-step success rate p p will have a major impact. Different LLMs will have different costs and different inherent error rates. Solving a task with a large number of steps will incur a meaningful e.g. economic cost, so before running on the full task, an LLM M M such that c/p\nicefrac{{c}}{{p}} is minimized should be selected. In other words, Eq.[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") makes it possible to select an LLM that will be most cost-effective at scale, and, since each individual step is so small, it is likely that smaller LLMs will be sufficient to solve the task.

![Image 6: Refer to caption](https://arxiv.org/html/x6.png)

(a) 

![Image 7: Refer to caption](https://arxiv.org/html/x7.png)

(b) 

Figure 5: _Task decomposition scaling laws resulting from Eq.[17](https://arxiv.org/html/2511.09030v1#S3.E17 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")._ (a a) For a task with 1M steps, as the number of steps assigned to each agent increases (and thus the number of agents decreases), there is an exponential increase in the expected cost to complete the task with sufficient reliability. Notice that while the x-axis is log(.)\log(.) scale, the y-axis is log(log(.))\log(\log(.)) scale. (b b) As the size of the task scales, this pattern continues: setups where agents are assigned more steps incur orders-of-magnitude of additional cost. 

### 3.3 Red-Flagging: Recognizing Signs of Unreliability

Since p p plays such an important role in the cost of the system, when possible, it is worth taking practical measures to push it higher. The simple premise is that ‚Äúbad‚Äù behaviors are correlated in LLMs, so if an LLM produces a response that signals pathological behavior, the response should be flagged and simply discarded. Since in MAD each agent is responsible for only a single step, each step is not too expensive, and it can be discarded and a new action resampled (i.e., by making another agent call). In this paper, two signs of unreliability are used as red flags: (1) overly long responses, and (2) incorrectly formatted responses. The hypothesis is that not only will discarding flagged respones increase p p, it will also meaningfully reduce _correlated errors_, since both flag types indicate that the LLM has been conditioned into a strange starting point before sampling. It is simple to detect these signs and discard their responses, but, since the paper focuses on understanding the impact on the expected cost of highly scaled long-horizon tasks, it is worth elaborating on the motivation and impact of this implementation choice.

Consistent with observations in prior work that longer answers tend to have more errors [liu2024lostinthemiddle], preliminary experiments for this paper showed that once an LLM gets initially confused, it can go off the rails and over-analyze a situation in a cycle of self-destruction. In MAD, each agent‚Äôs role is highly focused and relatively simple; if an agent is doing too much work to figure out its answer, it is likely to be confused and missing the point, and therefore more likely to give an incorrect answer. Even if the success rate is increased only from 99% to 99.9%, such an increase can have a large impact when the number of steps is large.

Similarly, preliminary experiments showed that when an agent produces an answer in an incorrect format, it is more likely to have become confused at some point on the way to that answer. So, instead of trying to fix the format of the answer in some way, the detection of the incorrect format can be flagged and the sample discarded.

Experimental evidence for the above two phenomena is detailed in Section[4](https://arxiv.org/html/2511.09030v1#S4 "4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). Formally, if v v is the probability that a valid response is parsed from the LLM‚Äôs output, i.e., no red flags, then the expected cost of MAKER can be written as:

ùîº‚Äã[cost of MAKER]‚âàc‚Äãs‚Äãk min v‚Äã(2‚Äãp‚àí1)=Œò‚Äã(c‚Äãs‚Äãln‚Å°s v‚Äãp),\mathbb{E}[\textrm{cost of MAKER}]\approx\frac{csk_{\min}}{v(2p-1)}=\Theta\left(\frac{cs\ln s}{vp}\right),(19)

where p p now indicates the per-step success rate _given that the response is valid_. In practice, this formula can be used to decide the trade-off between incorporating more red flags to increase p p (potentially resulting in a lower k min k_{\min}, whose calculation depends on p p but not v v) and the incurred cost overhead of discarded samples.

The most straightforward approach is to estimate p p on a relatively small number of steps to determine the choice of model and red flags, i.e., c c and v v, as well as the value of k k, before running the system on the full task with s s steps. An example application of this approach is demonstrated in the next section.

4 Experiments
-------------

This section details the application of MAKER to solving the Towers of Hanoi problem with 20 disks, i.e. over one million LLM steps with zero errors. First, the experimental setup is described (Section[4.1](https://arxiv.org/html/2511.09030v1#S4.SS1 "4.1 Setup ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). Next, single-step error-rates are estimated (Section[4.2](https://arxiv.org/html/2511.09030v1#S4.SS2 "4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")), which are used to project the cost of different setups (Section[4.3](https://arxiv.org/html/2511.09030v1#S4.SS3 "4.3 Projecting the cost of error correction ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). Then, a selected setup is run and evaluated on the full task (Section[4.4](https://arxiv.org/html/2511.09030v1#S4.SS4 "4.4 Solving the 20-disk problem: Over one million steps with zero errors ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). Finally, the impacts of red-flagging are investigated (Section[4.5](https://arxiv.org/html/2511.09030v1#S4.SS5 "4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). All in all, these experiments validate the components and scalability of the MAKER implementation of the MDAP framework.

### 4.1 Setup

The implementation of MAKER for this problem was derived from the single-agent approach introduced in prior work [shojaee2025illusion]. The single-agent prompts were modified so that each agent knows that it must only perform a single step of the problem, i.e., to move a single disk.

For efficiency, and to focus the agents as much as possible, each agent is given the minimal context it needs to perform its single step. In the case of Tower of Hanoi, everything the agent needs to know is the overall strategy and the current state of the problem, i.e., the configuration of disks. As in prior work [sinha2025, shojaee2025illusion], the overall strategy is provided in the prompt for each agent. The strategy works for any even number of disks and is the one most often suggested by the LLMs themselves when no strategy is provided a priori. (Appendix[C](https://arxiv.org/html/2511.09030v1#A3 "Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). This design choice effectively isolates the ability of agents to _execute_ clear instructions from the ability of LLMs to have _insights_ about how tasks should be solved (Section[5](https://arxiv.org/html/2511.09030v1#S5 "5 Discussion and Future Work ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"); see also [sinha2025]). Both insight and execution are essential to the capabilities of LLMs, but often they are entangled in experiments, making it difficult to identify the source of failure. Focusing on execution makes it possible to pursue the goal of finding minimal conditions for scaling LLM systems with respect to the number of steps.

The full agent prompt template is given in Appendix[C](https://arxiv.org/html/2511.09030v1#A3 "Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). Given the current state (i.e., configuration of disks) and prior move (which disk was moved from where to where), each agent is asked to provide the next move and the resulting next state. Unlike in the single-agent case, where only the sequence of moves needs to be produced, in the MAD case each agent must produce the resulting state, since this is critical information to be fed to the next agent. Each agent is asked to format its answers as ‚Äúmove = <move>‚Äù and ‚Äúnext_state = <next_state>‚Äù. Superficially, the requirement to produce the next state along with the action creates even more potential points of failure beyond the single-agent case, but, as it turns out, any drawbacks are overcome by the advantages of extreme decomposition and error correction.

### 4.2 Estimating single-step success rates

Running an LLM-based system at the scale of a million steps is expensive. It is thus desirable to calibrate the parameters of the system and estimate the success rate and cost before any large experiments are run. Equation[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") provides such a calibration and estimation method. Key to this estimation is the per-step success rate p p, which depends on the underlying LLM used.

A straightforward way to estimate the per-step success rate is to run the system on a random subset of steps. One advantage of having the same strategy in the prompt of each agent is that the correct answer is known for each step, and, assuming every prior step is correct, the inputs are known as well. This knowledge also makes it possible to use the API to obtain a batch of answers for many steps asynchronously, thus greatly speeding up wall-clock time of experiments and reducing cost [OpenAI_BatchAPI_Pricing]. These properties are part of what makes Towers of Hanoi such a practical testbed for many-step methods. For other problems, it may not be possible to estimate p p as efficiently, but, in any case, it should be possible to estimate it to a practical degree.

These initial exploratory estimation experiments were run without red-flagging. That is, agents were given a maximum of 2048 output tokens as an initial conservative upper bound, ensuring they have plenty of space to express whatever answer they need to express. They also used a ‚Äúrepairing parser‚Äù (written by an LLM, Appendix[C](https://arxiv.org/html/2511.09030v1#A3 "Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")) that attempted to correct some of the more common formatting errors in order to extract the LLM‚Äôs intended answer reliably out of its output. Importantly, since these experiments focus on the inherent generative reasoning capabilities of LLMs, they do not include LLMs that have access to auxiliary tools.

Figure[6(a)](https://arxiv.org/html/2511.09030v1#S4.F6.sf1 "In Figure 6 ‚Ä£ 4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows the single-step error rates across various LLMs as the number of disks is increased.

![Image 8: Refer to caption](https://arxiv.org/html/x8.png)

(a) 

Model$/M tok 1‚àíp 1-p k min k_{\min}ùîº‚Äã[cost]\mathbb{E}[\text{cost}]
gpt-4.1-nano 0.4 842.3571 29$41.9K
gpt-4.1-mini (œÑ=1.0\tau=1.0)1.6 580.0040 4$4.9K
gpt-4.1-mini (œÑ=0.1\tau=0.1)1.6 538.0022 3$3.5K
o3-mini (low)4.4 535.0018 3$9.4K
haiku-4.5 5.0 588.1839 12$71.2K
llama-3.2-3B 0.06 434 1.0--
gpt-oss-20B 0.2 1104.0358 6$1.7K
qwen-3 0.6 449.2342 15$11.5K
deepseek-v3.1 1.7 1004.0569 6$14.6K
kimi-k2 3.0 925.0393 6$22.9K

(b) 

Figure 6: _Empirical estimates of single-step error rates across models._ (a a) Different models have different per-step error rates, but these rates do not notably decrease as the number of disks (log of the solution length) increases, which is an encouraging sign for the ability of the system to scale. (b b) Given the per-token API cost of each model, the error rate estimate, and the mean number of output tokens, Eq.[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") can be used to estimate the cost of running the full 20-disk experiment with t=0.95 t=0.95. Among the proprietary models, although gpt-4.1-nano has the cheapest per-token cost, and o3-mini has the lowest per-step error rate, the expected cost of gpt-4.1-mini (with low temperature) is by far the lowest, and gpt-oss-20B is the clear open-source choice. In this manner, using Eq.[18](https://arxiv.org/html/2511.09030v1#S3.E18 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") to estimate cost can lead to substantial savings. 

There are two important and perhaps surprising takeaways from this figure: (1) Different LLMs have different base error rates, but those of relatively small non-reasoning models are comparable to more advanced reasoning models, suggesting that non-reasoning models may be a more effective fit for long-range tasks with MAKER. Figure[6(b)](https://arxiv.org/html/2511.09030v1#S4.F6.sf2 "In Figure 6 ‚Ä£ 4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows that this difference cannot be explained by a difference in output tokens, since the models use a similar number of tokens. (2) The per-step error rate is remarkably stable as the number of disks increases, a highly encouraging sign that MAKER will enable scaling to a large number of steps without the kind of exploding error rates often seen with single agents.

### 4.3 Projecting the cost of error correction

Based on the single-step error rates estimated above, it is possible to estimate the cost of successfully solving the full 20-disk task for models with p>0.5 p>0.5, i.e., models for which voting converges to correct subtask answers as k k increases. The table in Figure[6(b)](https://arxiv.org/html/2511.09030v1#S4.F6.sf2 "In Figure 6 ‚Ä£ 4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows these estimates, given the per-token cost of the model, the mean number of output tokens per step, and the empirical estimates of p p and k min k_{\min}. For a given model, its estimated cost per sample (Section[3.2](https://arxiv.org/html/2511.09030v1#S3.SS2 "3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")) is:

c sample=c in‚ãÖn in+c out‚ãÖn out,c_{\textrm{sample}}=c_{\textrm{in}}\cdot n_{\textrm{in}}+c_{\textrm{out}}\cdot n_{\textrm{out}},(20)

where c in c_{\textrm{in}} and c out c_{\textrm{out}} are the cost of input and output tokens, respectively, and n in n_{\textrm{in}} and n out n_{\textrm{out}} are the estimated average number of input and output tokens per sample. The cost per sample is multiplied by the expected number of samples to get the overall cost. For the target probability of success t=0.95 t=0.95, these results make it clear that the most effective proprietary choice is gpt-4.1-mini, and the most effective open-source choice is gpt-oss-20B. Whether these estimates are useful depends on whether the errors are sufficiently decorrelated across runs. Indeed they appear to be: In two independent runs of gpt-4.1-mini (œÑ=0.1\tau=0.1) on the set of 10K random samples, there were zero steps that had errors in both runs. Decorrelation of errors is discussed further in Sections[4.5](https://arxiv.org/html/2511.09030v1#S4.SS5 "4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") and [5](https://arxiv.org/html/2511.09030v1#S5 "5 Discussion and Future Work ‚Ä£ Solving a Million-Step LLM Task with Zero Errors").

Although the projected cost of gpt-oss-20B is lowest overall, in the scale-up experiment, gpt-4.1-mini was used because the OpenAI API was found to be more reliable than that of together.ai (a critical factor for experiments requiring millions of agentic calls). Note also that for reasoning LLMs with higher per-token cost than those in Figure[6(b)](https://arxiv.org/html/2511.09030v1#S4.F6.sf2 "In Figure 6 ‚Ä£ 4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"), even if their estimated per-step error rate were zero, and therefore k min=1 k_{\min}=1, their overall cost would be higher than that of gpt-4.1-mini, simply due to the cost of running on all 2 20‚àí1 2^{20}-1 steps, and it would be practical to assume the error estimate is a lower bound and set k=2 k=2. Thus, using the non-reasoning gpt-4.1-mini saves thousands of dollars in the scale-up experiment compared to the other proprietary models.

### 4.4 Solving the 20-disk problem: Over one million steps with zero errors

With gpt-4.1-mini as the base model, the maximum output token threshold was set to 750, and a red-flagging output parser was used to enforce the basic formatting requirements. Beyond this cutoff, the model often found itself in confusing logical loops; misformatted output was often correlated with such twisted reasoning, allowing them to be detected and discarded (as will be discussed further in Section[4.5](https://arxiv.org/html/2511.09030v1#S4.SS5 "4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). Since k min=3 k_{\min}=3, at least three responses were generated in parallel for each step. The first step was generated with a temperature of 0 to make sure the best possible guess is included in the votes. For all subsequent votes, a temperature of 0.1 was used.

With these calibrations, the full system solved the problem perfectly. Figure[7](https://arxiv.org/html/2511.09030v1#S4.F7 "Figure 7 ‚Ä£ 4.4 Solving the 20-disk problem: Over one million steps with zero errors ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows a snapshot of an animation visualizing the movement of the disks through the million steps as well as the sequence of agent activations that accomplish it. This result constitutes the first successful solution of a task with one million LLM steps with zero errors, establishing that scaling LLM-based systems to large time horizons is possible.

![Image 9: Refer to caption](https://arxiv.org/html/figures/1magentsscreenshot.png)

Figure 7: _A snapshot of the million-step problem-solving process._ The dots in the background represent the steps, ordered in rows from top to bottom. At step 479,806, MAKER is near the middle of the million steps, and about a half of the agents have already executed (green) and about a half are waiting to do so (blue). An animation of this process can be seen at [www.youtube.com/watch?v=gLkehsQy4H4](https://arxiv.org/html/www.youtube.com/watch?v=gLkehsQy4H4).

The behavior of the process can be analyzed by looking at how many samples had to be drawn for each step and how many votes were required (i.e., how many valid samples after red-flagging). A step is considered _undecided_ after i i rounds if an action decision has not yet been made based on the voting rule. Figure[8](https://arxiv.org/html/2511.09030v1#S4.F8 "Figure 8 ‚Ä£ 4.4 Solving the 20-disk problem: Over one million steps with zero errors ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows how the number of undecided steps decreases with the number of sampling rounds (including invalid samples) and voting rounds (excluding invalid samples).

![Image 10: Refer to caption](https://arxiv.org/html/x9.png)

(a) 

![Image 11: Refer to caption](https://arxiv.org/html/x10.png)

(b) 

Figure 8: _Convergence to zero-error solution._ The number of undecided steps decreases with sampling round (a a) and voting round (b b). In both cases, as expected from the theory, after the first k=3 k=3 rounds, there is a steady exponential decrease in the number of undecided steps, finally resulting in zero undecided steps and with zero errors. This sharp exponential convergence means that the vast majority of the overall cost is incurred in the first k k rounds of sampling; the cost of completing the remaining steps is effectively a rounding error. This effect emerges when p p is sufficiently high. It may at first appear disconcerting that there are any steps at all that require more than five voting rounds, but the decorrelation of errors is sufficient to prevent the voting mechanism from being overwhelmed (as described in Section[4.5](https://arxiv.org/html/2511.09030v1#S4.SS5 "4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). Details on specific steps, including the one pathological step that took 18 rounds, are in Appendix[D](https://arxiv.org/html/2511.09030v1#A4 "Appendix D Sample Responses ‚Ä£ Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). 

The exponential decay in the number of undecided steps mirrors the theoretical prediction. Due to this exponential decay, the vast majority of LLM calls (and therefore cost) is spent in the first k k calls, while the remaining cost is, for practical purposes, a rounding error. Notably, the task is solved perfectly even when using a less statistically powerful _first-to-k k_ voting (i.e., the first candidate k k votes wins), illustrating the robustness of the approach.

Although the system completes with zero errors and as efficiently as expected, the fact that a few of the steps take notably more sampling and voting rounds than others could be cause for concern. The next section looks into how red-flagging reduces the negative impact of such correlated errors.

### 4.5 Investigating the impact of red-flagging

Red-flagging was hypothesized to reduce the per-step error rate, but also the impact of correlated errors, i.e., particular steps that have unusually high error rates compared to the average step. Figure[9](https://arxiv.org/html/2511.09030v1#S4.F9 "Figure 9 ‚Ä£ 4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows evidence for both of these phenomena; however, the impact on correlated errors turns out to be a much more important effect. In the first two rounds of voting, the max number of output tokens (when calling the API) was set to 2048 to enable this analysis. Figure[9(a)](https://arxiv.org/html/2511.09030v1#S4.F9.sf1 "In Figure 9 ‚Ä£ 4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") shows that the per-step error rate increases precipitously once the response length crosses about 700. Although p p past this threshold is still around 90%, this is a drastic degradation compared to error rates on the order of 1-in-1000 with shorter responses. Even so, since so few of the overall responses are overly long, the overall p p at higher max token thresholds is not much larger, and in particular, not large enough to induce an increase in k min k_{\min}.

However, the main benefit of red-flagging becomes clear in Figure[9(b)](https://arxiv.org/html/2511.09030v1#S4.F9.sf2 "In Figure 9 ‚Ä£ 4.5 Investigating the impact of red-flagging ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). This figure plots the number of collisions across the first two votes of all steps in the 20-disk experiment, i.e., how many steps have _both_ votes incorrect. The number of collisions is computed across max token cutoffs for both the repairing parser used in Section[4.2](https://arxiv.org/html/2511.09030v1#S4.SS2 "4.2 Estimating single-step success rates ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"), as well as the red-flagging parser used in Section[4.4](https://arxiv.org/html/2511.09030v1#S4.SS4 "4.4 Solving the 20-disk problem: Over one million steps with zero errors ‚Ä£ 4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). Assuming the steps are i.i.d. with a uniform success rate, the expected number of collisions is no more than one or two in all cases. However, with a high max token cutoff the observed number of collisions is much higher, especially with the repairing parser. Red-flagging successfully reduces some of these correlated errors and may be critical to the success of the method on many-step tasks. Appendix[D](https://arxiv.org/html/2511.09030v1#A4 "Appendix D Sample Responses ‚Ä£ Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") illustrates what correlated errors in this domain can look like, and Section[5](https://arxiv.org/html/2511.09030v1#S5 "5 Discussion and Future Work ‚Ä£ Solving a Million-Step LLM Task with Zero Errors") discusses techniques for reducing correlation.

![Image 12: Refer to caption](https://arxiv.org/html/x11.png)

(a) 

![Image 13: Refer to caption](https://arxiv.org/html/x12.png)

(b) 

Figure 9: _Impact of red-flagging on reducing errors._ (a a) The error rate increases precipitously once the response length crosses about 700. However, since so few of the overall responses are overly long, the overall error rate at higher max token thresholds is not much larger, i.e., not large enough to induce an increase in k min k_{\min}. (b b) However, when focusing on correlated errors, the advantage of red-flagging becomes clear: Moving from a ‚Äòhelpful‚Äô repairing output parser to one that discards samples with any formatting issues leads to lower collision counts (i.e., number of steps whose first two votes are incorrect). These results confirm that robust decorrelation is crucial in many-step tasks, and that red-flagging helps with correlated errors. 

5 Discussion and Future Work
----------------------------

This paper introduced a framework for massively decomposed agentic processes (MDAPs) that can reliably solve tasks with large numbers of steps, as well as the first implementation of this framework, MAKER, which was successfully applied to the Towers of Hanoi benchmark task. This initial study established core principles that open many directions for future work.

#### More General Applications

LLM behaviors can be divided into two categories: _insights_ and _execution_. Insights come from an LLM creatively generating ideas, plans, and strategies, while execution involves following through with them. This paper focused on execution: the overall strategy to solve the problem is set at the beginning of the process, and given this strategy, the answer to each subtask is clearly achievable. Extending the framework to handle LLM-based insights is an important area of future work, since insights are inherently more open-ended and may come with irreducible step-wise uncertainty. One concrete way is to apply MAKER to the case where the creation of each subtask is itself treated as a step in an overall decomposition. The goal is to automate the entire problem-solving pipeline: the task is decomposed into minimal chunks, each one is solved, and the results are aggregated into a complete solution. The framework needs to be extended to handle an unknown number of total steps, as well as steps of different types, different underlying success rates, inexact matches between insight steps, and possible failures of the matching process.

Preliminary experiments in this direction are promising (Appendix[F](https://arxiv.org/html/2511.09030v1#A6 "Appendix F Multiplication Experiments ‚Ä£ Appendix E Open-source Model Details ‚Ä£ Appendix D Sample Responses ‚Ä£ Appendix C Prompts and Parsers ‚Ä£ Solving a Million-Step LLM Task with Zero Errors")). A more general version of MAKER was created with four agent types: decomposition agents, called recursively to break a task into two simpler sub-tasks and a composition function; decomposition discriminator agents, called to vote (with first-to-k k voting) for one of n=2‚Äãk‚àí1 n=2k-1 decomposition candidates; solution discriminator agents, called to vote for one of n n composition candidates; and problem solver agents used to solve minimal subtasks without decomposing them. The system achieved promising results on large-digit multiplication, a notoriously difficult task for transformer-based models [Dziriexp, bai2025canttransformerslearnmultiplication]. Future work will investigate the broader potential of such a system.

For simplicity, in this paper, all MAKER agents used the same underlying LLM and their prompts only differed in the subtask they were assigned. More general systems will likely require different LLMs for different kinds of roles, and a general increased diversity across agents. One of the benefits of such diversity will be decorrelation of errors, as is discussed next.

#### The Importance of Decorrelated Errors

For clarity and simplicity, theoretical analysis in this paper assumed that the errors are i.i.d. across steps. This assumption was reasonable because the steps were relatively uniform. Even so, there were a few steps that, for no apparent reason, had substantially higher inherent error rates than others. Such strange behaviors for particular inputs are well-known side-effects of LLM training, and dealing with such correlated errors is an open foundational problem in machine learning [lehman2025evolution].

The independent sampling plus red-flagging method used in this paper was sufficient to overcome them, but there may be other real-world cases where more sophisticated decorrelation methods are required. For example, instead of simple resampling using temperature, paraphrasing the prompt [wahle2024paraphrase] or adding noise to the prompt in some other way could help avoid such anomalous states caused by a particular fixed context. The error rate of each step would then approach the true ability of the LLM to understand and execute that step. Further, the framework could be extended to account for different values of p p for different steps, and decorrelation methods that make sampling more effective. Such extensions are critical to make the framework more broadly applicable, since in a long-range task, even a single step with an abnormally high error rate can cause the reasoning process to fail.

#### Parallels with microservices

Parallels can be drawn between microagents and microservices. The benefits of decomposing a monolithic agent‚Äôs task into subtasks are similar to those of decomposing a monolithic application into smaller services [fowler_microservices]:

*   ‚Ä¢
Modularity: Each microagent can be tailored to a specific task and leverage the right tools for the job.

*   ‚Ä¢
Data management: Each microagent is responsible for managing its data.

*   ‚Ä¢
Independent development: Microagents can be updated and tested in isolation from the rest of the system.

*   ‚Ä¢
Scalability: Microagents can be scaled independently, adjusting the resources to the actual needs of the system.

*   ‚Ä¢
Communication: Natural language is a powerful, well-understood communication protocol.

*   ‚Ä¢
Complexity: As microservices solve for large-scale systems, microagents solve for complex reasoning tasks.

*   ‚Ä¢
Real-time monitoring: Microagents can be monitored in real-time.

*   ‚Ä¢
Design for failure: Microagents are designed to tolerate the failure of any of the agents.

*   ‚Ä¢
Evolutionary design: Change is easier to manage with microagents than with a monolithic agent.

In fact, microagents could be considered a natural evolution of microservices. The framework could be extended in that direction, leveraging the lessons learned from microservice architectures [goyal2025microservices].

#### Limits of Decomposition

The application of MAKER assumes a task can be decomposed into small enough and simple enough steps such that each step can be solved by an LLM agent with reasonable probability. There is thus one central question that will dictate how broadly the methods can be applied: Are there important problems where such a decomposition is not possible or is computationally infeasible to discover? At the lowest level of LLM implementation, there is a decomposition into primitive operations executed on CPUs or GPUs; one can hope that there is some decomposition between that and the entire problem that is still linguistic but effectively compartmentalizes context and different behaviors. It remains to be seen which kinds of tasks are most resistant to such a decomposition.

#### Safety, Morality, and the Future of Superintelligence

If large and important real-world problems can be successfully decomposed into microsteps, there could be major benefits with respect to safety. If each step has a clearly defined and limited focus and purpose, the LLM‚Äôs view of the world and domain of influence can be strictly limited, allowing for more effective sand-boxing, auditing, and general control. Multiple focused agents can be run independently on each step, which also substantially reduces the ability of agents to collude to produce harmful actions. As was seen in the experiments in this paper, the vast majority of work can be performed by relatively small LLMs that are capable of handling these small steps, thus avoiding the risks of harmful behaviors that can arise in more powerful models [lynch2025agentic]. In other words, it could help mitigate the risk of uncontrollable superintelligence. Complementing these reduced societal risks, extreme decomposition could reduce the chance of unintended suffering of the machines themselves, as model welfare has become an increased area of concern [anthropic2025claude4systemcard]. As argued in prior work, relying on smaller models and having models focus entirely on limited-scope subtasks, as is done through decomposition, could reduce the chance that sentience unintentionally emerges [meyersonposition, tkachenko2024position].

LLMs today have just about all the raw intelligence needed to scaffold them into the great superintelligent skyscrapers of the coming age, and to scaffold themselves into productive organizations of technological progress. MDAPs present an alternative path to realizing the benefits of superintelligence, which, compared to endlessly building bigger and smarter single-agent models, comes with substantially reduced risks to both humans and machines.

6 Conclusion
------------

This paper focused on the question of how LLM-based agentic systems can be massively scaled. Decomposing tasks into minimal subtasks makes it possible to apply error-correction techniques effectively and efficiently, supporting scaling to millions of steps and beyond. A new category of AI systems results, i.e. massively decomposed agentic processes, or MDAPs. MAKER is a first implementation of this approach, and the experiments in this paper on Towers of Hanoi a first demonstration of its value. This foundation opens the door to more general-purpose implementations and large-scale, long-running real-world applications. Such MDAPs offer an alternative to building endlessly larger and more intelligent LLMs: By smashing intelligence into a million pieces, it is possible to build AI that is efficient, safe, and reliable.

Appendix A Log Scale Version of Figure 1
----------------------------------------

![Image 14: [Uncaptioned image]](https://arxiv.org/html/x13.png)

Figure 10:  This is the same figure as [1](https://arxiv.org/html/2511.09030v1#S0.F1 "Figure 1 ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"), but with a log-scale x-axis. 

Appendix B Additional Derivations
---------------------------------

This section provides details for the derivation of Eq.[14](https://arxiv.org/html/2511.09030v1#S3.E14 "In 3.2 First-to-ahead-by-ùëò Voting and Scaling Laws ‚Ä£ 3 Methods ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). Suppose the target probability for solving the full task with zero errors is t t. The goal is to find the minimum k k such that

t‚â•p full=(1+(1‚àíp p)k)‚àís m‚üπt‚àím s‚â•1+(1‚àíp p)k.t\geq p_{\textrm{full}}=\Bigg(1+\bigg(\frac{1-p}{p}\bigg)^{k}\Bigg)^{-\frac{s}{m}}\implies t^{-\frac{m}{s}}\geq 1+\left(\frac{1-p}{p}\right)^{k}.(21)

Plugging in a=t‚àím s a=t^{-\frac{m}{s}} and b=1‚àíp p b=\frac{1-p}{p} gives

a‚â•1+b k‚üπa‚àí1‚â•b k‚üπln‚Å°(a‚àí1)‚â•k‚Äãln‚Å°b‚üπk‚â•ln‚Å°(a‚àí1)ln‚Å°b,a\geq 1+b^{k}\implies a-1\geq b^{k}\implies\ln(a-1)\geq k\ln b\implies k\geq\frac{\ln(a-1)}{\ln b},(22)

since ln‚Å°b=ln‚Å°(1‚àíp p)<0\ln b=\ln\left(\frac{1-p}{p}\right)<0 when p>0.5 p>0.5. Replacing a a and b b and taking the first satisfying integer yields

k min=‚åàln‚Å°(t‚àím/s‚àí1)ln‚Å°(1‚àíp p)‚åâ.k_{\min}\;=\;\left\lceil\frac{\ln\left(t^{-m/s}-1\right)}{\ln\left(\frac{1-p}{p}\right)}\right\rceil.(23)

To understand the asymptotic behavior of k min k_{\min}, first note

t‚àím s=e‚àím s‚Äãln‚Å°t=e x,t^{-\frac{m}{s}}=e^{-\frac{m}{s}\ln t}=e^{x},(24)

where x=‚àím s‚Äãln‚Å°t x=-\frac{m}{s}\ln t. Suppose t>e‚àí1 t>e^{-1} (in our experiments it is close to 1). Then, x‚àà(0,1)x\in(0,1), and the classic bounds hold:

x\displaystyle x‚â§e x‚àí1‚â§e‚Äãx\displaystyle\leq e^{x}-1\leq ex(25)
‚üπ‚àím s‚Äãln‚Å°t\displaystyle\implies-\frac{m}{s}\ln t‚â§t‚àím s‚àí1‚â§‚àíe‚Äãm s‚Äãln‚Å°t\displaystyle\leq t^{-\frac{m}{s}}-1\leq-\frac{em}{s}\ln t(26)
‚üπln‚Å°(‚àím s‚Äãln‚Å°t)\displaystyle\implies\ln\left(-\frac{m}{s}\ln t\right)‚â§ln‚Å°(t‚àím s‚àí1)‚â§ln‚Å°(‚àíe‚Äãm s‚Äãln‚Å°t)\displaystyle\leq\ln\left(t^{-\frac{m}{s}}-1\right)\leq\ln\left(-\frac{em}{s}\ln t\right)(27)
‚üπln‚Å°(‚àím‚Äãln‚Å°(t))‚àíln‚Å°(s)\displaystyle\implies\ln\left(-m\ln(t)\right)-\ln(s)‚â§ln‚Å°(t‚àím s‚àí1)‚â§ln‚Å°(‚àíe‚Äãm‚Äãln‚Å°(t))‚àíln‚Å°(s)\displaystyle\leq\ln\left(t^{-\frac{m}{s}}-1\right)\leq\ln\left(-em\ln(t)\right)-\ln(s)(28)
‚üπln‚Å°(‚àím‚Äãln‚Å°(t))‚àíln‚Å°(s)ln‚Å°(1‚àíp p)\displaystyle\implies\frac{\ln\left(-m\ln(t)\right)-\ln(s)}{\ln\left(\frac{1-p}{p}\right)}‚â•ln‚Å°(t‚àím s‚àí1)ln‚Å°(1‚àíp p)‚â•ln‚Å°(‚àíe‚Äãm‚Äãln‚Å°(t))‚àíln‚Å°(s)ln‚Å°(1‚àíp p)\displaystyle\geq\frac{\ln\left(t^{-\frac{m}{s}}-1\right)}{\ln\left(\frac{1-p}{p}\right)}\geq\frac{\ln\left(-em\ln(t)\right)-\ln(s)}{\ln\left(\frac{1-p}{p}\right)}(29)
‚åàŒò‚Äã(1)‚àíln‚Å°(s)‚àíŒò‚Äã(1)‚åâ\displaystyle\left\lceil\frac{\Theta(1)-\ln(s)}{-\Theta(1)}\right\rceil‚â•k min‚â•‚åàŒò‚Äã(1)‚àíln‚Å°(s)‚àíŒò‚Äã(1)‚åâ\displaystyle\geq k_{\min}\geq\left\lceil\frac{\Theta(1)-\ln(s)}{-\Theta(1)}\right\rceil(30)
‚üπk min\displaystyle\implies k_{\min}=Œò‚Äã(ln‚Å°(s)).\displaystyle=\Theta(\ln(s)).(31)

Appendix C Prompts and Parsers
------------------------------

This section provides python code for the prompt templates (œà\psi) and parsers (œà a\psi_{a} and œà x\psi_{x}) used in the experiments in Section[4](https://arxiv.org/html/2511.09030v1#S4 "4 Experiments ‚Ä£ Solving a Million-Step LLM Task with Zero Errors"). The prompts are based on ones used in prior work [shojaee2025illusion].

_Prompt templates:_

\`\`\`
Repairing parser:
 Red-flagging parser:
 

Appendix D Sample Responses
This section provides sample responses from the full experiment in Section 4.4.
To give a sense of the kind of behavior that can occur, a shortest and a longest sample (with respect to number of tokens) from the first round of voting are shown, along with samples for the three racing candidates in the pathological step, step 10241, that takes 18 votes.
Figure 11 illustrates the process of that race.

Short sample, 256 Tokens, Step 950202:

This sample demonstrates straightforward reasoning.
 Long sample, 2048 Tokens, Step 539011:
This sample demonstrates confusion.
After it makes an error in its early reasoning, it talks in circles (‚ÄúWait, maybe the stacks are not as we think.‚Äù) until it hits the max token limit on the API call before outputting a correctly-formatted answer.
 Step 10241, Candidate A (correct) sample:
 Step 10241, Candidate B (incorrect) sample:
 Step 10241, Candidate C (incorrect) sample:
 

Figure 11: 
Vote race for step 10241.
This figure depicts the vote race for the pathological step 102421 that requires far more votes than any other step, though the correct decision is eventually made under both voting rules (first-to-kk and first-to-ahead-by-kk; Figure 8).
Sample responses leading to each candidate are shown above.
Additional samples were drawn after the decision was made to confirm that Candidate A does keep pulling further ahead.
Although the correct decision was made, the fact that this pathological sample exists serves as motivation for developing more sophisticated error decorrelation methods in the future (Section 5).

Appendix E Open-source Model Details
The below table gives details on the open-source models used in this paper, which were accessed via the together.ai API.
Temperature 0.1 was used for all open-source models.

Model Name
# Params
Endpoint
Input $/MTok
Output $/MTok

Qwen-3
235B
Qwen/Qwen3-235B-A22B-Instruct-2507-tput
0.2
0.6

DeepSeek-v3.1
671B
deepseek-ai/DeepSeek-V3
0.6
1.7

Kimi-K2
1T
moonshotai/Kimi-K2-Instruct
1.0
3.0

GPT-OSS-20B
20B
OpenAI/gpt-oss-20B
0.05
0.2

Llama-3.2-3B
3.2B
meta-llama/Llama-3.2-3B-Instruct-Turbo
0.06
0.06

Table 1: Open-source model details. Models accessed through together.ai API.

Appendix F Multiplication Experiments

Figure 12: 
Solve rate of the multi-agent system on 5√ó5 and 6√ó6 digit multiplication tasks as a function of voting parameter kk, with decomposition depth fixed at 55. Dotted horizontal lines indicate baseline single-agent performance for each task. As kk increases, accuracy improves for both 5√ó5 and 6√ó6 multiplication, reaching a perfect solve rate for 5x5 and reaching the target solve rate used in Section 4 of t=0.95t=0.95 for 6x6.
These results demonstrate the benefit of voting even at fixed reasoning depth (Algorithm 4).
In this experiment, gpt-4.1-mini was used for all agents.

Bai et al. [bai2025canttransformerslearnmultiplication] showed that standard Transformers struggle with multi-digit multiplication because attention alone fails to maintain long-range dependencies between intermediate digit interactions. Their reverse-engineering analysis revealed that successful computation requires constructing a directed acyclic ‚Äúattention tree‚Äù to propagate partial products across steps. The MDAP implementation, validated here on the same multiplication benchmark, is more general: it recursively decomposes any given task into subtasks and mitigates the multi-step degradation of accuracy by voting on each decomposition step, composition step, and atomic reasoning step. In contrast to model-specific architectural fixes, this voting-based recursive reasoning mechanism scales naturally with task complexity, allowing reliable multi-step inference beyond the arithmetic domain (Algorithm 4). The source code for this experiment is available here: www.github.com/cognizant-ai-lab/neuro-san-benchmarking.

Algorithm 4  Recursive multi-agent solve: decomposition sampling + voting until non-decomposable or depth limit, then solution sampling + voting, recursively composed to a final answer

1:N‚Üê2‚Äãk‚àí1N\leftarrow 2k-1 ‚ä≥\triangleright First-to-kk voting, NN candidates per step

2:function Decompose(xx) 

3:‚ÄÉ‚ÄÇsample NN decompositions via Decomposer(x)(x); vote via SolutionDiscriminator until one reaches kk (else argmax); return (P1,P2,C)(P_{1},P_{2},C)

4:end function

5:function Atomic(xx) 

6:‚ÄÉ‚ÄÇsample NN answers via ThinkingModule(x)(x); vote via CompositionDiscriminator; return winner 

7:end function

8:function Solve(x,dx,d)

9:‚ÄÉ‚ÄÇif d‚â•MAX_DEPTHd\geq\text{MAX\_DEPTH} then

10:‚ÄÉ‚ÄÉ‚ÄÉreturn Atomic(xx) 

11:‚ÄÉ‚ÄÇend if

12:‚ÄÉ‚ÄÇ(P1,P2,C)‚ÜêDecompose‚Äã(x)(P_{1},P_{2},C)\leftarrow\textsc{Decompose}(x)

13:‚ÄÉ‚ÄÇif P1=‚àÖP_{1}=\varnothing or P2=‚àÖP_{2}=\varnothing or C=‚àÖC=\varnothing then

14:‚ÄÉ‚ÄÉ‚ÄÉreturn Atomic(xx) 

15:‚ÄÉ‚ÄÇend if

16:‚ÄÉ‚ÄÇs1‚ÜêSolve‚Äã(P1,d+1)s_{1}\leftarrow\textsc{Solve}(P_{1},d+1),‚ÄÉs2‚ÜêSolve‚Äã(P2,d+1)s_{2}\leftarrow\textsc{Solve}(P_{2},d+1)

17:‚ÄÉ‚ÄÇsample NN composed solutions via ThinkingModule(‚ÄúSolve ‚ÄãC‚Äã(P1,P2)‚Äã with ‚ÄãP1=s1,P2=s2‚Äã‚Äù)(\text{``Solve }C(P_{1},P_{2})\text{ with }P_{1}{=}s_{1},P_{2}{=}s_{2}\text{''})

18:‚ÄÉ‚ÄÇvote via CompositionDiscriminator until one reaches kk (else argmax); return winner

19:end function
\`\`\`
</file>

<file path="metadata.json">
{
  "name": "MakerCode",
  "description": "A refined, agentic code editor implementing the MAKER framework for zero-error execution via massive decomposition and voting.",
  "requestFramePermissions": []
}
</file>

<file path="package.json">
{
  "name": "makercode",
  "private": true,
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "tauri": "tauri"
  },
  "dependencies": {
    "@google/genai": "^1.30.0",
    "@tauri-apps/plugin-dialog": "^2.0.0",
    "@tauri-apps/plugin-fs": "^2.0.0",
    "@tauri-apps/plugin-shell": "^2.0.0",
    "lucide-react": "^0.554.0",
    "react": "^19.2.0",
    "react-dom": "^19.2.0"
  },
  "devDependencies": {
    "@tailwindcss/postcss": "^4.1.17",
    "@tauri-apps/cli": "^2.0.0",
    "@types/node": "^22.14.0",
    "@vitejs/plugin-react": "^5.0.0",
    "postcss": "^8.4.38",
    "tailwindcss": "^4.1.17",
    "typescript": "~5.8.2",
    "vite": "^6.2.0"
  }
}
</file>

<file path="postcss.config.js">
export default {
  plugins: {
    '@tailwindcss/postcss': {},
    },
}
</file>

<file path="README.md">
# MakerCode

**The Agentic Editor for Zero-Error Execution.**

MakerCode is a next-generation code editor built on the **MAKER Framework** (Massive Agentic Decomposition, Error Correction, and Red-flagging). Unlike traditional AI assistants that simply autocomplete code, MakerCode acts as a fully autonomous software engineering organization in a box. It decomposes high-level tasks into atomic units, executing them in parallel with rigorous consensus mechanisms to ensure correctness.

## üöÄ Core Philosophy

The project is built on the premise that LLMs are "autoregressive queens of failure" when asked to do too much at once. To solve this, MakerCode implements:

1.  **Extreme Decomposition**: Tasks are broken down until they are atomic (e.g., "Write this specific function").
2.  **Adaptive Consensus**: High-risk changes trigger a multi-agent voting process (The "Architect", "Security Auditor", and "QA" agents must agree).
3.  **Isolation**: Agents work in Git Worktrees to prevent race conditions.
4.  **Polyglot Context**: Intelligent, language-aware context injection (The "Context Onion") prevents hallucination.

---

## üõ† Tech Stack

*   **Frontend**: React 19, TailwindCSS, Lucide Icons.
*   **Backend / System**: Tauri v2 (Rust), `tauri-plugin-fs`, `tauri-plugin-shell`.
*   **AI Orchestration**: Provider Agnostic (Gemini, OpenAI, DeepSeek, Ollama).
*   **State Management**: In-Memory Virtual File System (VFS) with Event Subscription.

---

## üó∫Ô∏è ROADMAP

### Phase 1: The Foundation (‚úÖ Completed)
*   [x] **Hybrid Architecture**: React 19 frontend + Rust/Tauri v2 backend.
*   [x] **Virtual File System (VFS)**: Async read/write layer bridging UI and Disk.
*   [x] **Real I/O**: `tauri-plugin-fs` integration for opening/saving actual files.
*   [x] **Project Persistence**: Auto-loading `.maker/config.json` for per-project agent settings.
*   [x] **Secret Management**: Secure (local) storage of API Keys.

### Phase 2: The Wiring (‚úÖ Completed)
*   [x] **Local Git Abstraction**:
    *   [x] **Internal Client**: App manages its own "Shadow Repo" state.
    *   [x] **Worktree Isolation**: Agents run in isolated git worktrees to prevent conflicts.
    *   [x] **Dirty State Protection**: Prevents agents from running on unstable state.
    *   [x] **Remote Sync**: Push/Pull integration with GitHub/GitLab.
*   [x] **Polyglot Support**:
    *   [x] **Language Registry**: Modular support for TypeScript, Rust, and Python.
    *   [x] **Manifest Detection**: Auto-detects `package.json`, `Cargo.toml`, etc.
*   [x] **Context Awareness (RAG Lite)**:
    *   [x] **The Context Onion**: Layered context injection (Tree -> Manifests -> Dependencies).
    *   [x] **Keyword Scouting**: Heuristic scanning for relevant files based on user prompt.
    *   [x] **Reactive Expansion**: Auto-healing context when linter errors occur.

### Phase 3: The "Brain" Upgrade (‚úÖ Completed)
*   [x] **Provider Agnostic AI**:
    *   [x] Support for OpenAI, DeepSeek, and Local LLMs via standard API.
    *   [x] Dynamic configuration via Settings Panel.
*   [x] **Modular Architecture**:
    *   [x] Split monolithic service into `DecompositionService`, `VotingService`, and `MakerEngine`.
*   [x] **Consensus Engine**:
    *   [x] **The Judge**: Semantic evaluation of candidate code by a superior model.
    *   [x] **Voting Logic**: Multi-agent proposal generation and selection.

### Phase 4: Safety & Robustness (‚úÖ Completed)
*   [x] **Static Safety**:
    *   [x] Path traversal prevention in VFS.
    *   [x] Banned module checks (child_process, unsafe) in generated code.
*   [x] **Dynamic Re-planning**:
    *   [x] Architect auto-decomposes failed steps into smaller sub-tasks.
*   [x] **Production Terminal**:
    *   [x] Real-time streaming output for `npm install` / `cargo build`.
    *   [x] Process control (Stop/Kill).

### Phase 5: Extensibility (üöß Next Up)
*   [ ] **Dynamic Agent Profiles**:
    *   [ ] UI to create/edit agents (e.g., "Rust Expert", "Python Data Scientist").
    *   [ ] Persist agent roster to `.maker/config.json` so it travels with the repo.
    *   [ ] **Preserve Defaults**: Ensure "Atlas", "Bolt", "Cipher", and "Dash" remain the default team.
*   [ ] **Plugin System**:
    *   [ ] Allow users to define custom "Tools" (e.g., "Run Database Migration") that Agents can invoke.

---

## üì¶ Running the Project

### Prerequisites
*   Node.js 18+
*   Rust (cargo)
*   Tauri CLI (`npm install -g @tauri-apps/cli`)
*   **Git**: Must be installed and available in PATH.

### Development
1.  Install dependencies:
    ```bash
    pnpm install
    ```
2.  Run the web interface (UI Only, Mocked Backend):
    ```bash
    pnpm tauri dev
    ```
3.  Build the Desktop App (Requires Rust):
    ```bash
    pnpm tauri build
    ```
</file>

<file path="scripts/icon.js">
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const iconDir = path.resolve(__dirname, '../src-tauri/icons');

if (!fs.existsSync(iconDir)) {
    fs.mkdirSync(iconDir, { recursive: true });
}

// 1. Valid 1x1 Transparent PNG (for .png files)
const PNG_BASE64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+P+/HgAFhAJ/wlseKgAAAABJRU5ErkJggg==";
const pngBuffer = Buffer.from(PNG_BASE64, 'base64');

// 2. Valid 16x16 ICO (Real binary structure, not just renamed PNG)
// This is a minimal valid ICO file to satisfy Windows RC.EXE
const ICO_BASE64 = "AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//w==";
const icoBuffer = Buffer.from(ICO_BASE64, 'base64');

const pngFiles = [
    '32x32.png',
    '128x128.png',
    '128x128@2x.png',
    'icon.icns' // MacOS usually accepts PNGs renamed to ICNS for dev, though real ICNS is different.
];

// Write PNGs
pngFiles.forEach(file => {
    fs.writeFileSync(path.join(iconDir, file), pngBuffer);
    console.log(`Generated PNG: ${file}`);
});

// Write Valid ICO
fs.writeFileSync(path.join(iconDir, 'icon.ico'), icoBuffer);
console.log(`Generated Valid ICO: icon.ico`);
</file>

<file path="src-tauri/build.rs">
fn main() {
  tauri_build::build()
}
</file>

<file path="src-tauri/capabilities/developer.json">
{
    "identifier": "developer",
    "description": "Full access for development",
    "windows": [
        "main"
    ],
    "permissions": [
        "core:default",
        "shell:allow-open",
        "dialog:default",
        "fs:default",
        "fs:allow-watch",
        "fs:allow-read-text-file",
        "fs:allow-write-text-file",
        "fs:allow-read-dir",
        "fs:allow-mkdir",
        "fs:allow-exists",
        "shell:allow-execute",
        {
            "identifier": "fs:scope",
            "allow": [
                "$HOME/**",
                "**",
                "C:\\**",
                "D:\\**",
                "E:\\**",
                "F:\\**"
            ]
        },
        {
            "identifier": "shell:allow-execute",
            "allow": [
                {
                    "name": "git",
                    "cmd": "git",
                    "args": true
                },
                {
                    "name": "npx",
                    "cmd": "npx",
                    "args": true
                },
                {
                    "name": "npm",
                    "cmd": "npm",
                    "args": true
                },
                {
                    "name": "node",
                    "cmd": "node",
                    "args": true
                },
                {
                    "name": "cargo",
                    "cmd": "cargo",
                    "args": true
                },
                {
                    "name": "python",
                    "cmd": "python",
                    "args": true
                },
                {
                    "name": "pip",
                    "cmd": "pip",
                    "args": true
                },
                {
                    "name": "ls",
                    "cmd": "ls",
                    "args": true
                },
                {
                    "name": "echo",
                    "cmd": "echo",
                    "args": true
                },
                {
                    "name": "mkdir",
                    "cmd": "mkdir",
                    "args": true
                }
            ]
        }
    ]
}
</file>

<file path="src-tauri/Cargo.toml">
[package]
name = "makercode"
version = "0.1.0"
description = "A refined, agentic code editor implementing the MAKER framework"
authors = ["MakerCode Team"]
edition = "2021"
build = "build.rs"

[build-dependencies]
tauri-build = { version = "2.0.0", features = [] }

[dependencies]
tauri = { version = "2.0.0", features = [] }
tauri-plugin-shell = "2.0.0"
tauri-plugin-fs = "2.0.0"
tauri-plugin-dialog = "2.0.0"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
log = "0.4"
env_logger = "0.10"

[features]
custom-protocol = ["tauri/custom-protocol"]
</file>

<file path="src-tauri/src/lib.rs">
use std::process::Command;
use tauri::Manager; // Import Manager trait so it is available

// Example custom command to verify backend connectivity and prerequisites
#[tauri::command]
fn check_system_health() -> Result<String, String> {
    // Check if Git is installed on the host system
    let output = Command::new("git")
        .arg("--version")
        .output()
        .map_err(|e| format!("Failed to execute git: {}", e))?;

    if output.status.success() {
        let version = String::from_utf8_lossy(&output.stdout);
        Ok(format!("System Healthy. {}", version.trim()))
    } else {
        Err("Git not found or not responding".into())
    }
}

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    tauri::Builder::default()
        // Initialize Plugins
        .plugin(tauri_plugin_shell::init())
        .plugin(tauri_plugin_fs::init())
        .plugin(tauri_plugin_dialog::init())
        
        // Register Custom Commands
        .invoke_handler(tauri::generate_handler![
            check_system_health
        ])
        
        // App Setup Hook
        .setup(|app| {
            // Perform initialization tasks here
            #[cfg(debug_assertions)]
            {
                let window = app.get_webview_window("main").unwrap();
                window.open_devtools(); 
            }
            
            // Silence unused variable warning in release mode
            let _ = app;
            
            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
</file>

<file path="src-tauri/src/main.rs">
// Prevents additional console window on Windows in release, DO NOT REMOVE!!
#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

fn main() {
    // Initialize the logging system immediately
    env_logger::init();
    
    // Delegate execution to the library entry point
    // The crate name matches the [package] name in Cargo.toml ("makercode")
    makercode::run();
}
</file>

<file path="src/components/AgentManager.tsx">
import React, { useState } from 'react';
import { Bot, Cpu, Zap, User, Plus, Trash2, Edit3, Save, X } from 'lucide-react';
import { SubTask, AgentProfile, MakerConfig } from '../types';

interface AgentManagerProps {
    activeWorkers: number;
    maxParallelism: number;
    activeTasks: SubTask[];
    agentProfiles: AgentProfile[];
    onConfigUpdate: (config: Partial<MakerConfig>) => void;
}

export const AgentManager: React.FC<AgentManagerProps> = ({ activeWorkers, maxParallelism, activeTasks, agentProfiles, onConfigUpdate }) => {
    const [editingId, setEditingId] = useState<string | null>(null);
    const [tempAgent, setTempAgent] = useState<AgentProfile | null>(null);

    const slots = Array.from({ length: maxParallelism }, (_, i) => {
        const activeTask = activeTasks[i];
        return {
            id: i + 1,
            isOccupied: !!activeTask,
            task: activeTask
        };
    });

    const getAgentProfile = (agentId?: string): AgentProfile | undefined => {
        return agentProfiles.find(p => p.id === agentId);
    };

    const handleEdit = (agent: AgentProfile) => {
        setEditingId(agent.id);
        setTempAgent({ ...agent });
    };

    const handleSave = () => {
        if (!tempAgent) return;
        const updatedProfiles = agentProfiles.map(p => p.id === tempAgent.id ? tempAgent : p);
        onConfigUpdate({ agentProfiles: updatedProfiles });
        setEditingId(null);
        setTempAgent(null);
    };

    const handleAddAgent = () => {
        const newAgent: AgentProfile = {
            id: Math.random().toString(36).substring(2, 9),
            name: "New Agent",
            role: "Developer",
            riskTolerance: 0.5,
            color: "text-gray-400",
            model: "gemini-2.0-flash"
        };
        onConfigUpdate({ agentProfiles: [...agentProfiles, newAgent] });
        handleEdit(newAgent);
    };

    const handleDelete = (id: string) => {
        onConfigUpdate({ agentProfiles: agentProfiles.filter(p => p.id !== id) });
    };

    return (
        <div className="space-y-6">

            <div className="bg-gray-900 border border-gray-800 rounded-lg p-5 shadow-lg relative overflow-hidden">
                <div className="absolute top-0 right-0 p-4 opacity-10 pointer-events-none">
                    <Cpu size={100} className="text-teal-400" />
                </div>

                <div className="flex justify-between items-center mb-6 border-b border-gray-800 pb-4 relative z-10">
                    <div className="flex items-center gap-3">
                        <div className="p-2 bg-teal-500/10 rounded-lg text-teal-400">
                            <ActivityIcon active={activeWorkers > 0} />
                        </div>
                        <div>
                            <h2 className="text-lg font-bold text-gray-100">Runtime Status</h2>
                            <div className="text-xs text-gray-500 flex items-center gap-2">
                                <span className={`w-2 h-2 rounded-full ${activeWorkers > 0 ? 'bg-green-500 animate-pulse' : 'bg-gray-600'}`}></span>
                                {activeWorkers} / {maxParallelism} Threads Active
                            </div>
                        </div>
                    </div>
                    <div className="flex items-center gap-1.5 px-3 py-1.5 bg-gray-950 rounded-sm text-xs font-mono text-gray-400 border border-gray-800">
                        <Zap size={14} className={activeWorkers > 0 ? "text-yellow-400" : "text-gray-600"} />
                        <span>System Load: {Math.round((activeWorkers / maxParallelism) * 100)}%</span>
                    </div>
                </div>

                <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4 relative z-10">
                    {slots.map(slot => {
                        const profile = slot.isOccupied ? getAgentProfile(slot.task?.assignedAgentId) : undefined;

                        return (
                            <div key={slot.id} className={`relative border rounded-lg p-4 transition-all duration-500 flex flex-col h-44 ${slot.isOccupied
                                ? 'bg-teal-950/20 border-teal-500/30 shadow-[0_0_20px_rgba(20,184,166,0.1)]'
                                : 'bg-gray-950/30 border-gray-800 border-dashed opacity-60 hover:opacity-100'
                                }`}>
                                <div className="flex items-center justify-between mb-3 border-b border-gray-800/50 pb-2">
                                    <span className="text-[10px] font-mono text-gray-500 uppercase tracking-widest">
                                        SLOT {slot.id.toString().padStart(2, '0')}
                                    </span>
                                    {slot.isOccupied ? (
                                        <span className="text-[9px] bg-green-500/20 text-green-400 px-1.5 py-0.5 rounded-sm font-bold animate-pulse">ACTIVE</span>
                                    ) : (
                                        <span className="text-[9px] bg-gray-800 text-gray-500 px-1.5 py-0.5 rounded-sm">IDLE</span>
                                    )}
                                </div>

                                {slot.isOccupied && profile && slot.task ? (
                                    <div className="flex-1 flex flex-col">
                                        {/* AGENT IDENTITY - Primary Visual */}
                                        <div className="mb-3">
                                            <div className="flex items-center gap-2 mb-1">
                                                <div className={`w-8 h-8 rounded-lg bg-gray-900 border border-gray-800 flex items-center justify-center font-bold text-sm ${profile.color}`}>
                                                    {profile.name.charAt(0)}
                                                </div>
                                                <div>
                                                    <div className={`text-sm font-bold ${profile.color}`}>{profile.name}</div>
                                                    <div className="text-[10px] text-gray-400 flex items-center gap-1">
                                                        <span>{profile.role}</span>
                                                        <span className="text-gray-600">‚Ä¢</span>
                                                        <span className="font-mono">{profile.model}</span>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>

                                        <div className="mt-auto">
                                            <div className="text-[10px] text-gray-500 uppercase mb-1">Processing Task</div>
                                            <div className="text-xs font-medium text-teal-100 line-clamp-1 bg-teal-900/30 px-2 py-1.5 rounded-sm border border-teal-900/50" title={slot.task.description}>
                                                {slot.task.description}
                                            </div>
                                            <div className="w-full bg-gray-800 h-1 rounded-full overflow-hidden mt-2">
                                                <div className="h-full bg-teal-500 animate-progress-indeterminate"></div>
                                            </div>
                                        </div>
                                    </div>
                                ) : (
                                    <div className="flex-1 flex flex-col items-center justify-center text-gray-600 gap-2">
                                        <Bot size={24} className="opacity-20" />
                                        <span className="text-xs">Waiting for job assignment...</span>
                                    </div>
                                )}
                            </div>
                        );
                    })}
                </div>
            </div>

            <div className="bg-gray-900 border border-gray-800 rounded-lg p-5 shadow-lg">
                <div className="flex justify-between items-center mb-6">
                    <div>
                        <h2 className="text-lg font-bold text-gray-100 flex items-center gap-2">
                            <User size={18} className="text-indigo-400" />
                            Personnel Roster
                        </h2>
                        <p className="text-xs text-gray-500">Configure the AI agents available for decomposition and voting tasks.</p>
                    </div>
                    <button
                        onClick={handleAddAgent}
                        className="flex items-center gap-2 px-3 py-1.5 bg-indigo-600 hover:bg-indigo-500 text-white rounded-sm text-xs font-medium transition-colors"
                    >
                        <Plus size={14} /> Add Agent
                    </button>
                </div>

                <div className="space-y-3">
                    {agentProfiles.map(agent => (
                        <div key={agent.id} className="bg-gray-950 border border-gray-800 rounded-lg p-4 flex flex-col md:flex-row gap-4 items-start md:items-center hover:border-gray-700 transition-colors">
                            {editingId === agent.id && tempAgent ? (
                                <div className="flex-1 w-full grid grid-cols-1 md:grid-cols-4 gap-4 animate-in fade-in">
                                    <div className="space-y-1">
                                        <label className="text-[10px] text-gray-500 uppercase">Name</label>
                                        <input
                                            value={tempAgent.name}
                                            onChange={(e) => setTempAgent({ ...tempAgent, name: e.target.value })}
                                            className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1.5 text-sm text-white focus:border-indigo-500 outline-hidden"
                                        />
                                    </div>
                                    <div className="space-y-1">
                                        <label className="text-[10px] text-gray-500 uppercase">Role</label>
                                        <select
                                            value={tempAgent.role}
                                            onChange={(e) => setTempAgent({ ...tempAgent, role: e.target.value as any })}
                                            className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1.5 text-sm text-gray-300 outline-hidden"
                                        >
                                            <option value="Architect">Architect</option>
                                            <option value="Developer">Developer</option>
                                            <option value="QA">QA</option>
                                            <option value="Security">Security</option>
                                        </select>
                                    </div>
                                    <div className="space-y-1">
                                        <label className="text-[10px] text-gray-500 uppercase">Risk Tolerance ({tempAgent.riskTolerance})</label>
                                        <input
                                            type="range" min="0" max="1" step="0.1"
                                            value={tempAgent.riskTolerance}
                                            onChange={(e) => setTempAgent({ ...tempAgent, riskTolerance: parseFloat(e.target.value) })}
                                            className="w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-indigo-500 mt-2"
                                        />
                                    </div>
                                    <div className="flex items-end gap-2">
                                        <button onClick={handleSave} className="flex-1 bg-green-600 hover:bg-green-500 text-white h-[34px] rounded-sm flex items-center justify-center gap-1 text-xs">
                                            <Save size={14} /> Save
                                        </button>
                                        <button onClick={() => setEditingId(null)} className="px-3 bg-gray-800 hover:bg-gray-700 text-gray-400 h-[34px] rounded-sm">
                                            <X size={14} />
                                        </button>
                                    </div>
                                </div>
                            ) : (
                                <>
                                    <div className="flex items-center gap-4 flex-1">
                                        <div className={`w-10 h-10 rounded-lg bg-gray-900 border border-gray-800 flex items-center justify-center font-bold text-sm ${agent.color}`}>
                                            {agent.name.charAt(0)}
                                        </div>
                                        <div>
                                            <div className="font-bold text-sm text-gray-200">{agent.name}</div>
                                            <div className="text-xs text-gray-500">{agent.role}</div>
                                        </div>
                                    </div>

                                    <div className="flex items-center gap-6 flex-1 justify-start md:justify-center">
                                        <div className="flex flex-col">
                                            <span className="text-[10px] text-gray-500 uppercase">Model</span>
                                            <span className="text-xs font-mono text-gray-400">{agent.model}</span>
                                        </div>
                                        <div className="flex flex-col">
                                            <span className="text-[10px] text-gray-500 uppercase">Risk Profile</span>
                                            <div className="flex items-center gap-2">
                                                <div className="w-16 h-1.5 bg-gray-800 rounded-full overflow-hidden">
                                                    <div className={`h-full rounded-full ${agent.riskTolerance < 0.3 ? 'bg-red-500' :
                                                        agent.riskTolerance > 0.7 ? 'bg-green-500' : 'bg-blue-500'
                                                        }`} style={{ width: `${agent.riskTolerance * 100}%` }}></div>
                                                </div>
                                                <span className="text-xs font-mono text-gray-400">{agent.riskTolerance}</span>
                                            </div>
                                        </div>
                                    </div>

                                    <div className="flex items-center gap-2">
                                        <button onClick={() => handleEdit(agent)} className="p-2 hover:bg-gray-800 rounded-sm text-gray-500 hover:text-indigo-400 transition-colors">
                                            <Edit3 size={16} />
                                        </button>
                                        <button onClick={() => handleDelete(agent.id)} className="p-2 hover:bg-red-900/20 rounded-sm text-gray-600 hover:text-red-400 transition-colors">
                                            <Trash2 size={16} />
                                        </button>
                                    </div>
                                </>
                            )}
                        </div>
                    ))}
                </div>
            </div>
        </div>
    );
};

const ActivityIcon = ({ active }: { active: boolean }) => (
    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" className={active ? "animate-pulse" : ""}>
        <path d="M22 12H18L15 21L9 3L6 12H2" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" />
    </svg>
);
</file>

<file path="src/components/CodeEditor.tsx">
import React, { useState, useEffect } from 'react';
import { FileCode, File, Save, MousePointerClick, Loader2 } from 'lucide-react';
import { VirtualFileSystem } from '../services/virtualFileSystem';

interface CodeEditorProps {
    activeFile: string | null;
}

export const CodeEditor: React.FC<CodeEditorProps> = ({ activeFile }) => {
    const [content, setContent] = useState<string>('');
    const [isSaved, setIsSaved] = useState(true);
    const [isLoading, setIsLoading] = useState(false);

    // Load file content when activeFile changes
    useEffect(() => {
        if (!activeFile) {
            setContent('');
            return;
        }

        const loadContent = async () => {
            setIsLoading(true);
            const vfs = VirtualFileSystem.getInstance();
            const fileContent = await vfs.readFile(activeFile);
            setContent(fileContent || '// File not found or empty');
            setIsSaved(true);
            setIsLoading(false);
        };

        loadContent();

        const vfs = VirtualFileSystem.getInstance();
        const unsub = vfs.subscribe(async () => {
            // In a real app, strictly check if *this* file changed to avoid re-renders
            // For now, we simple re-fetch if we are in a "saved" state (safe to overwrite)
            if (isSaved) {
                const updated = await vfs.readFile(activeFile);
                if (updated && updated !== content) {
                    setContent(updated);
                }
            }
        });
        return unsub;
    }, [activeFile]); // Removed isSaved from dependency to prevent infinite loops

    const handleSave = async () => {
        if (activeFile) {
            const vfs = VirtualFileSystem.getInstance();
            await vfs.writeFile(activeFile, content);
            setIsSaved(true);
        }
    };

    const handleChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
        setContent(e.target.value);
        setIsSaved(false);
    };

    const lines = content.split('\n');

    if (!activeFile) {
        return (
            <div className="flex-1 flex flex-col items-center justify-center bg-gray-950 text-gray-600 space-y-4">
                <MousePointerClick size={48} className="text-gray-800" />
                <div className="text-center">
                    <p className="text-sm font-medium text-gray-500">No file selected</p>
                    <p className="text-xs mt-1">Select a file from the explorer sidebar to edit.</p>
                </div>
            </div>
        );
    }

    return (
        <div className="flex h-full bg-gray-950 flex-col min-w-0">
            {/* Editor Toolbar */}
            <div className="h-10 border-b border-gray-800 bg-gray-900 flex items-center justify-between px-4">
                <div className="flex items-center gap-2 text-sm text-gray-300">
                    <File size={14} className="text-indigo-400" />
                    <span className="font-mono">{activeFile}</span>
                    {!isSaved && <span className="text-[10px] text-yellow-500 animate-pulse">‚óè Unsaved</span>}
                </div>
                <button
                    onClick={handleSave}
                    className={`flex items-center gap-2 px-3 py-1 rounded-sm text-xs font-medium transition-colors ${isSaved ? 'text-gray-500 hover:text-gray-300' : 'bg-indigo-600 text-white hover:bg-indigo-500'}`}
                >
                    <Save size={12} /> Save
                </button>
            </div>

            {/* Editor Area */}
            <div className="flex-1 relative bg-gray-950 overflow-hidden">
                {isLoading ? (
                    <div className="absolute inset-0 flex items-center justify-center text-gray-500 gap-2">
                        <Loader2 className="animate-spin" size={20} /> Loading...
                    </div>
                ) : (
                    <div className="absolute inset-0 flex font-mono text-sm leading-6">
                        {/* Line Numbers */}
                        <div className="w-10 bg-gray-900/50 border-r border-gray-800 text-gray-600 text-right pr-2 py-4 select-none overflow-hidden">
                            {lines.map((_, i) => (
                                <div key={i}>{i + 1}</div>
                            ))}
                        </div>
                        {/* Editable Area */}
                        <textarea
                            className="flex-1 p-4 bg-transparent text-gray-300 outline-hidden resize-none whitespace-pre"
                            value={content}
                            onChange={handleChange}
                            spellCheck={false}
                        />
                    </div>
                )}
            </div>
        </div>
    );
};
</file>

<file path="src/components/CodeViewer.tsx">
import React, { useState } from 'react';
import { FileCode, File, Copy, Check } from 'lucide-react';

// Simple mocked content for files
const MOCK_FILES: Record<string, string> = {
    'src/auth/service.ts': `import { db } from '../db';
import { User } from '../types';

export class AuthService {
    /**
     * Authenticates a user based on credentials
     */
    async login(email: string, pass: string): Promise<User | null> {
        // MAKER Consensus: Optimized query
        const user = await db.users.findUnique({ where: { email } });
        
        if (!user || !user.validatePassword(pass)) {
            return null;
        }

        return user;
    }
}`,
    'src/utils/jwt.ts': `import jwt from 'jsonwebtoken';

const SECRET = process.env.JWT_SECRET || 'dev-secret';

export function sign(payload: any): string {
    return jwt.sign(payload, SECRET, { expiresIn: '1h' });
}

export function verify(token: string): any {
    try {
        return jwt.verify(token, SECRET);
    } catch (e) {
        return null;
    }
}`
};

export const CodeViewer: React.FC = () => {
    const [selectedFile, setSelectedFile] = useState<string>('src/auth/service.ts');
    const [copied, setCopied] = useState(false);

    const handleCopy = () => {
        setCopied(true);
        setTimeout(() => setCopied(false), 2000);
    };

    const content = MOCK_FILES[selectedFile] || '// Select a file to view content';
    const lines = content.split('\n');

    return (
        <div className="flex h-full bg-gray-950">
            {/* Sidebar File List */}
            <div className="w-48 border-r border-gray-800 bg-gray-900/50 flex flex-col">
                <div className="p-3 text-xs font-semibold text-gray-500 uppercase">Open Files</div>
                {Object.keys(MOCK_FILES).map(fileName => (
                    <button
                        key={fileName}
                        onClick={() => setSelectedFile(fileName)}
                        className={`flex items-center gap-2 px-3 py-2 text-xs text-left truncate transition-colors ${
                            selectedFile === fileName 
                                ? 'bg-indigo-600/20 text-indigo-300 border-r-2 border-indigo-500' 
                                : 'text-gray-400 hover:bg-gray-800 hover:text-gray-200'
                        }`}
                    >
                        <FileCode size={12} />
                        <span className="truncate">{fileName.split('/').pop()}</span>
                    </button>
                ))}
            </div>

            {/* Editor Area */}
            <div className="flex-1 flex flex-col min-w-0">
                <div className="h-10 border-b border-gray-800 bg-gray-900 flex items-center justify-between px-4">
                    <div className="flex items-center gap-2 text-sm text-gray-300">
                        <File size={14} className="text-indigo-400" />
                        {selectedFile}
                    </div>
                    <button 
                        onClick={handleCopy}
                        className="p-1.5 rounded-sm hover:bg-gray-800 text-gray-500 hover:text-gray-300 transition-colors"
                    >
                        {copied ? <Check size={14} className="text-green-500" /> : <Copy size={14} />}
                    </button>
                </div>

                <div className="flex-1 overflow-auto font-mono text-sm leading-6 relative bg-gray-950">
                    <div className="flex min-h-full">
                        {/* Line Numbers */}
                        <div className="w-10 bg-gray-900/50 border-r border-gray-800 text-gray-600 text-right pr-2 py-4 select-none">
                            {lines.map((_, i) => (
                                <div key={i}>{i + 1}</div>
                            ))}
                        </div>
                        {/* Code Content */}
                        <div className="flex-1 p-4">
                            {lines.map((line, i) => (
                                <div key={i} className="whitespace-pre">
                                    <SyntaxHighlighter line={line} />
                                </div>
                            ))}
                        </div>
                    </div>
                </div>
            </div>
        </div>
    );
};

const SyntaxHighlighter: React.FC<{ line: string }> = ({ line }) => {
    // Very basic syntax highlighting for demo
    if (line.trim().startsWith('//')) {
        return <span className="text-gray-500 italic">{line}</span>;
    }
    
    const parts = line.split(/(\s+|[(){}[\].,;])/g);
    
    return (
        <span>
            {parts.map((part, i) => {
                let className = 'text-gray-300';
                if (['import', 'export', 'class', 'function', 'const', 'let', 'var', 'return', 'async', 'await', 'try', 'catch', 'if', 'else'].includes(part)) className = 'text-purple-400';
                else if (['string', 'number', 'boolean', 'any', 'void', 'Promise'].includes(part)) className = 'text-yellow-400';
                else if (['true', 'false', 'null', 'undefined'].includes(part)) className = 'text-orange-400';
                else if (part.match(/^[A-Z][a-zA-Z0-9]*$/)) className = 'text-blue-300'; // Class/Type-ish
                else if (part.startsWith("'") || part.startsWith('"')) className = 'text-green-400';
                
                return <span key={i} className={className}>{part}</span>;
            })}
        </span>
    );
};
</file>

<file path="src/components/FileExplorer.tsx">
import React, { useState, useEffect } from 'react';
import { ChevronRight, ChevronDown, File, Folder, Loader2 } from 'lucide-react';
import { VirtualFileSystem } from '../services/virtualFileSystem';

interface FileExplorerProps {
  onSelectFile: (path: string) => void;
  activeFile: string | null;
}

export const FileExplorer: React.FC<FileExplorerProps> = ({ onSelectFile, activeFile }) => {
  const [files, setFiles] = useState<any[]>([]);
  const [loading, setLoading] = useState(false);

  useEffect(() => {
    const vfs = VirtualFileSystem.getInstance();

    const updateFiles = async () => {
      setLoading(true);
      const tree = await vfs.getDirectoryTree();
      setFiles(tree);
      setLoading(false);
    };

    // Initial load
    updateFiles();

    // Subscribe to changes
    return vfs.subscribe(updateFiles);
  }, []);

  if (loading && files.length === 0) {
    return <div className="p-4 text-gray-500 flex items-center gap-2 text-xs"><Loader2 className="animate-spin" size={12} /> Loading...</div>;
  }

  return (
    <div className="pl-2">
      {files.map((file, i) => (
        <FileTreeItem
          key={file.path + i}
          item={file}
          level={0}
          onSelect={onSelectFile}
          activeFile={activeFile}
        />
      ))}
    </div>
  );
};

interface FileTreeItemProps {
  item: any;
  level: number;
  onSelect: (path: string) => void;
  activeFile: string | null;
}

const FileTreeItem: React.FC<FileTreeItemProps> = ({ item, level, onSelect, activeFile }) => {
  const [isOpen, setIsOpen] = useState(false);
  const paddingLeft = level * 12 + 8;
  const isActive = activeFile === item.path;

  const handleClick = () => {
    if (item.isDirectory) {
      setIsOpen(!isOpen);
    } else {
      onSelect(item.path);
    }
  };

  return (
    <div>
      <div
        onClick={handleClick}
        className={`flex items-center gap-1 py-1 pr-2 cursor-pointer select-none text-sm transition-colors ${isActive
          ? 'bg-indigo-600/20 text-indigo-300 border-r-2 border-indigo-500'
          : 'hover:bg-gray-800 text-gray-400 hover:text-gray-100'
          }`}
        style={{ paddingLeft: `${paddingLeft}px` }}
      >
        <span className="opacity-70">
          {item.isDirectory ? (
            isOpen ? <ChevronDown size={14} /> : <ChevronRight size={14} />
          ) : <div className="w-3.5" />}
        </span>
        <span className="opacity-70">
          {item.isDirectory ? <Folder size={14} className="text-indigo-400" /> : <File size={14} />}
        </span>
        <span className="truncate">{item.name}</span>
      </div>
      {isOpen && item.children && (
        <div>
          {item.children.map((child: any, i: number) => (
            <FileTreeItem
              key={child.path + i}
              item={child}
              level={level + 1}
              onSelect={onSelect}
              activeFile={activeFile}
            />
          ))}
        </div>
      )}
      {/* Visual placeholder for empty directories */}
      {isOpen && (!item.children || item.children.length === 0) && item.isDirectory && (
        <div className="text-[10px] text-gray-600 py-1 select-none italic" style={{ paddingLeft: `${paddingLeft + 20}px` }}>
          (empty)
        </div>
      )}
    </div>
  );
};
</file>

<file path="src/components/GitHistory.tsx">
import React, { useEffect, useState } from 'react';
import { GitCommit, GitPullRequest, Hash, Calendar, User, FileDiff } from 'lucide-react';
import { GitService } from '../services/gitService';
import { GitLogEntry } from '../types';

export const GitHistory: React.FC = () => {
    const [history, setHistory] = useState<GitLogEntry[]>([]);
    const [loading, setLoading] = useState(true);

    useEffect(() => {
        const loadHistory = async () => {
            const git = new GitService();
            const log = await git.getHistory();
            setHistory(log);
            setLoading(false);
        };
        loadHistory();

        // Poll for updates (simplified for demo)
        const interval = setInterval(loadHistory, 5000);
        return () => clearInterval(interval);
    }, []);

    if (loading) {
        return <div className="p-8 text-center text-gray-500 font-mono text-xs">Loading Repository History...</div>;
    }

    return (
        <div className="h-full w-full bg-gray-950 p-4 overflow-y-auto">
            <div className="max-w-4xl mx-auto">
                <div className="flex items-center justify-between mb-6 pb-4 border-b border-gray-800">
                    <h2 className="text-xl font-bold text-gray-200 flex items-center gap-2">
                        <GitCommit className="text-orange-500" />
                        Project Timeline
                    </h2>
                    <span className="text-xs font-mono text-gray-500 bg-gray-900 px-2 py-1 rounded-sm">
                        Branch: <span className="text-indigo-400">main</span>
                    </span>
                </div>

                <div className="space-y-4">
                    {history.map((commit, idx) => (
                        <div key={commit.hash} className="relative pl-8 pb-4 group">
                            {/* Connector Line */}
                            {idx !== history.length - 1 && (
                                <div className="absolute left-[11px] top-6 bottom-0 w-0.5 bg-gray-800 group-hover:bg-gray-700 transition-colors"></div>
                            )}

                            {/* Node Point */}
                            <div className="absolute left-0 top-1.5 w-6 h-6 rounded-full bg-gray-900 border-2 border-orange-500/50 flex items-center justify-center z-10">
                                <div className="w-2 h-2 bg-orange-500 rounded-full"></div>
                            </div>

                            <div className="bg-gray-900/50 border border-gray-800 rounded-lg p-4 hover:border-orange-500/30 transition-colors">
                                <div className="flex justify-between items-start mb-2">
                                    <div>
                                        <h3 className="font-semibold text-gray-200 text-sm mb-1">{commit.message}</h3>
                                        <div className="flex items-center gap-3 text-xs text-gray-500">
                                            <span className="flex items-center gap-1">
                                                <User size={10} /> {commit.author}
                                            </span>
                                            <span className="flex items-center gap-1">
                                                <Calendar size={10} /> {commit.date}
                                            </span>
                                            <span className="flex items-center gap-1 font-mono text-gray-600">
                                                <Hash size={10} /> {commit.hash.substring(0, 7)}
                                            </span>
                                        </div>
                                    </div>

                                    {commit.stats && (
                                        <div className="flex items-center gap-2 text-[10px] font-mono bg-gray-950 px-2 py-1 rounded-sm border border-gray-800">
                                            <span className="text-green-400">+{commit.stats.additions}</span>
                                            <span className="text-gray-700">|</span>
                                            <span className="text-red-400">-{commit.stats.deletions}</span>
                                        </div>
                                    )}
                                </div>

                                {commit.tags && commit.tags.length > 0 && (
                                    <div className="flex gap-2 mt-2">
                                        {commit.tags.map(tag => (
                                            <span key={tag} className="text-[10px] px-1.5 py-0.5 rounded-sm bg-indigo-500/20 text-indigo-300 border border-indigo-500/30">
                                                {tag}
                                            </span>
                                        ))}
                                    </div>
                                )}
                            </div>
                        </div>
                    ))}
                </div>
            </div>
        </div>
    );
};
</file>

<file path="src/components/MakerVisualizer.tsx">
import React, { useState } from 'react';
import { SubTask, AgentStatus, TaskStatus, MakerConfig } from '../types';
import { CheckCircle, Circle, AlertCircle, Loader2, Cpu, Zap, ShieldAlert, GitBranch, GitMerge, Clock, Save, Eye, ClipboardList } from 'lucide-react';
import { VotingInspector } from './VotingInspector';

interface MakerVisualizerProps {
  state: TaskStatus | null;
  config: MakerConfig;
}

export const MakerVisualizer: React.FC<MakerVisualizerProps> = ({ state, config }) => {
  const [inspectingStep, setInspectingStep] = useState<SubTask | null>(null);

  if (!state || state.decomposition.length === 0) {
    return (
      <div className="h-full w-full p-8 flex flex-col items-center justify-center text-gray-600 space-y-4">
        <div className="relative">
          <div className="absolute -inset-1 bg-indigo-500 rounded-full opacity-20 blur-xl"></div>
          <Cpu size={64} className="relative text-gray-700" />
        </div>
        <p className="text-sm font-mono">MAKER Engine Standby</p>
        <p className="text-xs text-gray-700 max-w-xs text-center">
          System ready. Configure agents above or enter a prompt to begin decomposition.
        </p>
      </div>
    );
  }

  return (
    <div className="h-full w-full p-8 overflow-y-auto relative">
      {inspectingStep && (
        <VotingInspector step={inspectingStep} onClose={() => setInspectingStep(null)} />
      )}

      <div className="max-w-3xl mx-auto">

        {/* Planning Mode Banner */}
        {state.isPlanning && (
          <div className="mb-8 p-4 bg-indigo-900/20 border border-indigo-500/30 rounded-lg flex items-center justify-between animate-in slide-in-from-top duration-500">
            <div className="flex items-center gap-3">
              <div className="p-2 bg-indigo-500/20 rounded-full text-indigo-400">
                <ClipboardList size={24} />
              </div>
              <div>
                <h2 className="text-sm font-bold text-indigo-200">Plan Review Required</h2>
                <p className="text-xs text-indigo-400/70">MAKER has decomposed the task into {state.decomposition.length} atomic steps.</p>
              </div>
            </div>
            <div className="text-xs text-indigo-300 font-mono animate-pulse">Waiting for approval...</div>
          </div>
        )}

        <div className="mb-8 text-center mt-2">
          {!state.isPlanning && (
            <>
              <h2 className="text-lg font-bold text-gray-100 mb-2">Execution Graph</h2>
              <div className="flex flex-wrap justify-center gap-4 text-xs font-mono text-gray-500 bg-gray-900/50 py-2 rounded-xl border border-gray-800 px-6">
                <span>Steps: {state.completedSteps}/{state.totalSteps}</span>
                <span className="text-teal-400">Workers: {state.activeWorkers}</span>
                <span className="text-red-400">Red Flags: {state.errorCount}</span>
              </div>
            </>
          )}
        </div>

        <div className="space-y-6 relative">
          {/* Vertical connector line */}
          <div className="absolute left-6 top-4 bottom-4 w-0.5 bg-gray-800 z-0"></div>

          {state.decomposition.map((step, idx) => (
            <StepCard
              key={step.id}
              step={step}
              index={idx}
              onInspect={() => step.status === AgentStatus.PASSED || step.status === AgentStatus.VOTING ? setInspectingStep(step) : null}
            />
          ))}
        </div>
      </div>
    </div>
  );
};

const StepCard: React.FC<{ step: SubTask; index: number; onInspect: () => void }> = ({ step, index, onInspect }) => {
  const getStatusColor = (s: AgentStatus) => {
    switch (s) {
      case AgentStatus.PLANNING: return 'border-indigo-500/30 bg-indigo-900/5 text-gray-400';
      case AgentStatus.QUEUED: return 'border-gray-800 bg-gray-900/50 text-gray-500';
      case AgentStatus.ANALYZING: return 'border-yellow-500/30 bg-yellow-900/10 text-yellow-500';
      case AgentStatus.THINKING: return 'border-indigo-500/50 bg-indigo-900/10 text-indigo-300';
      case AgentStatus.VOTING: return 'border-purple-500/50 bg-purple-900/10 text-purple-300';
      case AgentStatus.PASSED: return 'border-green-500/50 bg-green-900/10 text-green-300';
      case AgentStatus.SKIPPED_VOTE: return 'border-teal-500/50 bg-teal-900/10 text-teal-300';
      case AgentStatus.FAILED: return 'border-red-500/50 bg-red-900/10 text-red-300';
      case AgentStatus.EXECUTING: return 'border-blue-500/50 bg-blue-900/10 text-blue-300';
      case AgentStatus.CHECKPOINTING: return 'border-orange-500/50 bg-orange-900/10 text-orange-300';
      case AgentStatus.MERGING: return 'border-pink-500/50 bg-pink-900/10 text-pink-300';
      default: return 'border-gray-800';
    }
  };

  const getIcon = (s: AgentStatus) => {
    switch (s) {
      case AgentStatus.PLANNING: return <Circle size={18} className="text-indigo-500/50" />;
      case AgentStatus.PASSED: return <CheckCircle size={18} className="text-green-500" />;
      case AgentStatus.SKIPPED_VOTE: return <Zap size={18} className="text-teal-400" />;
      case AgentStatus.FAILED: return <AlertCircle size={18} className="text-red-500" />;
      case AgentStatus.ANALYZING: return <ShieldAlert size={18} className="text-yellow-500 animate-pulse" />;
      case AgentStatus.QUEUED: return <Clock size={18} className="text-gray-600" />;
      case AgentStatus.CHECKPOINTING: return <Save size={18} className="text-orange-500 animate-pulse" />;
      case AgentStatus.MERGING: return <GitMerge size={18} className="text-pink-500 animate-bounce" />;
      case AgentStatus.THINKING:
      case AgentStatus.VOTING:
      case AgentStatus.EXECUTING:
        return <Loader2 size={18} className="animate-spin text-indigo-500" />;
      default: return <Circle size={18} className="text-gray-600" />;
    }
  };

  const isInspectable = (step.status === AgentStatus.PASSED || step.status === AgentStatus.VOTING) && step.candidates && step.candidates.length > 0;

  return (
    <div className={`relative z-10 flex items-start gap-4 transition-all duration-500 ${step.status === AgentStatus.QUEUED ? 'opacity-60' : 'opacity-100'}`}>
      <div className={`mt-3 w-12 h-12 rounded-full border-4 border-gray-950 flex items-center justify-center bg-gray-900 shadow-xl ${step.status === AgentStatus.PASSED ? 'ring-2 ring-green-500/50' :
        step.status === AgentStatus.SKIPPED_VOTE ? 'ring-2 ring-teal-500/50' :
          step.status === AgentStatus.VOTING ? 'ring-2 ring-purple-500/50' :
            step.status === AgentStatus.CHECKPOINTING ? 'ring-2 ring-orange-500/50' : ''
        }`}>
        {getIcon(step.status)}
      </div>

      <div className={`flex-1 p-4 rounded-lg border backdrop-blur-xs shadow-xs transition-colors ${getStatusColor(step.status)}`}>
        <div className="flex justify-between items-start mb-2">
          <div className="flex flex-col">
            <h3 className="font-semibold text-sm flex items-center gap-2">
              Step {index + 1}: {step.description}
              {isInspectable && (
                <button
                  onClick={onInspect}
                  className="p-1 rounded-sm hover:bg-white/10 text-white/50 hover:text-white transition-colors"
                  title="Inspect Voting Consensus"
                >
                  <Eye size={14} />
                </button>
              )}
            </h3>
            {step.riskReason && step.status !== AgentStatus.PLANNING && (
              <span className="text-[10px] text-gray-400 mt-0.5 flex items-center gap-1">
                Risk Analysis: {step.riskScore > 0.5 ? <span className="text-red-400 font-bold">HIGH</span> : <span className="text-green-400 font-bold">LOW</span>} ({step.riskScore.toFixed(2)}) - {step.riskReason}
              </span>
            )}
          </div>
          <span className="text-[10px] font-mono uppercase tracking-wider px-2 py-0.5 rounded-sm bg-gray-950/30 border border-white/5">
            {step.status.replace('_', ' ')}
          </span>
        </div>

        {/* Git Branch Info */}
        {step.gitBranch && (
          <div className="text-[10px] font-mono text-orange-400/80 mb-2 flex items-center gap-1 bg-orange-950/20 w-fit px-1.5 py-0.5 rounded-sm border border-orange-900/30">
            <GitBranch size={10} /> {step.gitBranch}
          </div>
        )}

        <div className="text-xs font-mono opacity-70 mb-3 flex items-center gap-2">
          <span className="bg-gray-800 px-1 rounded-sm text-[10px]">FILE</span> {step.fileTarget}
          {step.dependencies.length > 0 && (
            <span className="ml-2 text-gray-500">Wait for: [{step.dependencies.join(', ')}]</span>
          )}
        </div>

        {/* Voting Visuals */}
        {(step.status === AgentStatus.VOTING || (step.status === AgentStatus.PASSED && step.riskScore > 0.5)) && (
          <div
            className={`mt-2 pt-2 border-t border-gray-700/50 ${isInspectable ? 'cursor-pointer hover:bg-white/5 p-2 -mx-2 rounded-sm transition-colors' : ''}`}
            onClick={isInspectable ? onInspect : undefined}
          >
            <div className="flex items-center gap-2 mb-1">
              <span className="text-[10px] uppercase font-bold text-gray-500">MAKER Consensus Engine</span>
              <div className="h-px bg-gray-700/50 flex-1"></div>
            </div>
            <div className="flex gap-2">
              {[1, 2, 3].map((agentId) => (
                <div key={agentId} className="flex-1 bg-gray-950/50 rounded-sm p-2 flex items-center gap-2 border border-gray-800">
                  <div className={`w-1.5 h-1.5 rounded-full ${step.status === AgentStatus.PASSED ? 'bg-green-500' : 'bg-purple-500 animate-pulse'}`}></div>
                  <span className="text-[10px] text-gray-400">Agent {agentId}</span>
                </div>
              ))}
            </div>
            {isInspectable && <div className="text-[9px] text-center text-gray-600 mt-1">Click to inspect candidates</div>}
          </div>
        )}

        {/* Logs (Linter & Errors) */}
        {step.logs.length > 0 && (
          <div className={`mt-2 pt-2 border-t ${step.status === AgentStatus.FAILED ? 'border-red-900/30' : 'border-gray-800'}`}>
            {step.logs.map((log, i) => (
              <div key={i} className={`text-[10px] font-mono mb-0.5 ${log.includes("Error") || log.includes("failed") ? 'text-red-400' :
                log.includes("AutoFix") ? 'text-blue-400' :
                  log.includes("verified") ? 'text-green-500' :
                    'text-gray-500'
                }`}>
                {log}
              </div>
            ))}
          </div>
        )}
      </div>
    </div>
  );
};
</file>

<file path="src/components/MergeConflictResolver.tsx">
import React, { useState } from 'react';
import { GitMerge, Wand2, Check, X, FileDiff, ArrowRight } from 'lucide-react';
import { MergeConflict } from '../types';

interface MergeConflictResolverProps {
    conflicts: MergeConflict[];
    onResolve: (id: string, content: string) => void;
}

export const MergeConflictResolver: React.FC<MergeConflictResolverProps> = ({ conflicts, onResolve }) => {
    const [selectedConflict, setSelectedConflict] = useState<string | null>(conflicts[0]?.id || null);
    const activeConflict = conflicts.find(c => c.id === selectedConflict);

    if (conflicts.length === 0) {
        return (
            <div className="flex flex-col items-center justify-center h-full text-gray-500">
                <Check className="text-green-500 mb-2" size={32} />
                <p>No active merge conflicts.</p>
            </div>
        );
    }

    return (
        <div className="h-full flex flex-col bg-gray-950">
            <div className="p-4 border-b border-gray-800 bg-red-950/10 flex items-center gap-3">
                <div className="p-2 bg-red-500/10 rounded-sm text-red-500">
                    <GitMerge size={20} />
                </div>
                <div>
                    <h3 className="text-sm font-bold text-red-200">Merge Conflict Detected</h3>
                    <p className="text-xs text-red-400/70">MAKER has detected {conflicts.length} files requiring resolution.</p>
                </div>
            </div>

            <div className="flex-1 flex min-h-0">
                {/* File List */}
                <div className="w-64 border-r border-gray-800 bg-gray-900/50 p-2 overflow-y-auto">
                    <div className="text-xs font-semibold text-gray-500 mb-2 px-2 uppercase">Conflicted Files</div>
                    {conflicts.map(conflict => (
                        <div
                            key={conflict.id}
                            onClick={() => setSelectedConflict(conflict.id)}
                            className={`flex items-center gap-2 px-3 py-2 rounded text-sm cursor-pointer mb-1 ${selectedConflict === conflict.id ? 'bg-indigo-600/20 text-indigo-300' : 'hover:bg-gray-800 text-gray-400'
                                }`}
                        >
                            <FileDiff size={14} />
                            <span className="truncate">{conflict.filePath}</span>
                        </div>
                    ))}
                </div>

                {/* Conflict Editor */}
                {activeConflict ? (
                    <div className="flex-1 flex flex-col min-h-0">
                        {/* Comparison View */}
                        <div className="flex-1 grid grid-cols-2 divide-x divide-gray-800 min-h-0">
                            <div className="flex flex-col">
                                <div className="h-8 bg-gray-900 border-b border-gray-800 flex items-center px-4 text-xs font-mono text-gray-400">
                                    HEAD ({activeConflict.branchA})
                                </div>
                                <div className="flex-1 p-4 font-mono text-xs overflow-auto bg-gray-950/50 text-red-300 whitespace-pre">
                                    {activeConflict.contentA}
                                </div>
                            </div>
                            <div className="flex flex-col">
                                <div className="h-8 bg-gray-900 border-b border-gray-800 flex items-center px-4 text-xs font-mono text-gray-400">
                                    Incoming ({activeConflict.branchB})
                                </div>
                                <div className="flex-1 p-4 font-mono text-xs overflow-auto bg-gray-950/50 text-green-300 whitespace-pre">
                                    {activeConflict.contentB}
                                </div>
                            </div>
                        </div>

                        {/* AI Resolution Proposal */}
                        <div className="h-1/3 border-t border-gray-800 bg-gray-900 flex flex-col">
                            <div className="h-8 bg-gray-800 flex items-center justify-between px-4 text-xs border-b border-gray-700">
                                <div className="flex items-center gap-2 text-indigo-300">
                                    <Wand2 size={12} /> MAKER Proposal
                                </div>
                                <div className="flex gap-2">
                                    <button className="flex items-center gap-1 hover:text-white text-gray-400">
                                        Regenerate
                                    </button>
                                </div>
                            </div>
                            <div className="flex-1 p-4 font-mono text-xs overflow-auto text-indigo-100 whitespace-pre">
                                {activeConflict.aiResolutionProposal}
                            </div>
                            <div className="p-3 border-t border-gray-800 flex justify-end gap-3 bg-gray-950">
                                <button className="px-4 py-1.5 rounded-sm text-xs bg-gray-800 hover:bg-gray-700 text-gray-300">
                                    Manual Edit
                                </button>
                                <button
                                    onClick={() => onResolve(activeConflict.id, activeConflict.aiResolutionProposal || "")}
                                    className="px-4 py-1.5 rounded-sm text-xs bg-green-600 hover:bg-green-500 text-white flex items-center gap-2"
                                >
                                    <Check size={14} /> Accept Resolution
                                </button>
                            </div>
                        </div>
                    </div>
                ) : (
                    <div className="flex-1 flex items-center justify-center text-gray-500">Select a file</div>
                )}
            </div>
        </div>
    );
};
</file>

<file path="src/components/PlanEditor.tsx">
import React, { useState } from 'react';
import { SubTask, AgentStatus } from '../types';
import { X, ArrowUp, ArrowDown, Plus, Save, AlertCircle } from 'lucide-react';

interface PlanEditorProps {
    steps: SubTask[];
    onUpdate: (steps: SubTask[]) => void;
    onClose: () => void;
}

export const PlanEditor: React.FC<PlanEditorProps> = ({ steps, onUpdate, onClose }) => {
    const [editedSteps, setEditedSteps] = useState<SubTask[]>([...steps]);
    const [newStepDesc, setNewStepDesc] = useState('');

    const handleStepChange = (index: number, field: keyof SubTask, value: any) => {
        const updated = [...editedSteps];
        updated[index] = { ...updated[index], [field]: value };
        setEditedSteps(updated);
    };

    const handleDelete = (index: number) => {
        const updated = editedSteps.filter((_, i) => i !== index);
        setEditedSteps(updated);
    };

    const handleMove = (index: number, direction: -1 | 1) => {
        if (index + direction < 0 || index + direction >= editedSteps.length) return;
        const updated = [...editedSteps];
        const temp = updated[index];
        updated[index] = updated[index + direction];
        updated[index + direction] = temp;
        setEditedSteps(updated);
    };

    const handleAddStep = () => {
        if (!newStepDesc.trim()) return;
        const newStep: SubTask = {
            id: Math.random().toString(36).substring(2, 9),
            description: newStepDesc,
            fileTarget: './new-file.ts',
            status: AgentStatus.QUEUED,
            attempts: 0,
            votes: 0,
            riskScore: 0.1,
            logs: [],
            dependencies: index > 0 ? [editedSteps[editedSteps.length - 1].id] : [],
            candidates: []
        };
        // Insert at end
        const index = editedSteps.length;
        setEditedSteps([...editedSteps, newStep]);
        setNewStepDesc('');
    };

    const handleSave = () => {
        onUpdate(editedSteps);
        onClose();
    };

    return (
        <div className="absolute inset-0 z-50 flex items-center justify-center bg-gray-950/90 backdrop-blur-xs p-8">
            <div className="bg-gray-900 border border-gray-700 rounded-xl shadow-2xl w-full max-w-4xl h-[80vh] flex flex-col overflow-hidden animate-in fade-in zoom-in-95 duration-200">

                {/* Header */}
                <div className="h-16 border-b border-gray-800 flex items-center justify-between px-6 bg-gray-900">
                    <div>
                        <h2 className="text-lg font-bold text-gray-100">Execution Plan Editor</h2>
                        <p className="text-xs text-gray-500">Review and modify agent tasks before execution.</p>
                    </div>
                    <div className="flex gap-3">
                        <button onClick={onClose} className="px-4 py-2 rounded-sm text-xs font-medium text-gray-400 hover:text-white hover:bg-gray-800 transition-colors">
                            Cancel
                        </button>
                        <button onClick={handleSave} className="px-4 py-2 rounded-sm text-xs font-medium bg-indigo-600 hover:bg-indigo-500 text-white flex items-center gap-2 shadow-lg shadow-indigo-500/20">
                            <Save size={14} /> Save Plan
                        </button>
                    </div>
                </div>

                {/* List */}
                <div className="flex-1 overflow-y-auto p-6 space-y-3">
                    {editedSteps.length === 0 && (
                        <div className="text-center text-gray-500 py-12 border-2 border-dashed border-gray-800 rounded-lg">
                            <AlertCircle className="mx-auto mb-2 opacity-50" />
                            <p>No steps in plan. Add one below.</p>
                        </div>
                    )}

                    {editedSteps.map((step, idx) => (
                        <div key={step.id} className="bg-gray-950 border border-gray-800 rounded-lg p-3 flex gap-4 items-start group hover:border-gray-700 transition-colors">
                            {/* Order Controls */}
                            <div className="flex flex-col gap-1 mt-1 text-gray-600">
                                <button onClick={() => handleMove(idx, -1)} disabled={idx === 0} className="hover:text-indigo-400 disabled:opacity-30">
                                    <ArrowUp size={14} />
                                </button>
                                <span className="text-[10px] font-mono text-center">{idx + 1}</span>
                                <button onClick={() => handleMove(idx, 1)} disabled={idx === editedSteps.length - 1} className="hover:text-indigo-400 disabled:opacity-30">
                                    <ArrowDown size={14} />
                                </button>
                            </div>

                            {/* Inputs */}
                            <div className="flex-1 grid grid-cols-1 md:grid-cols-3 gap-4">
                                <div className="md:col-span-2 space-y-1">
                                    <label className="text-[10px] uppercase text-gray-600 font-bold">Task Description</label>
                                    <input
                                        value={step.description}
                                        onChange={(e) => handleStepChange(idx, 'description', e.target.value)}
                                        className="w-full bg-gray-900 border border-gray-800 rounded-sm px-2 py-1.5 text-sm text-gray-200 focus:border-indigo-500 outline-hidden"
                                    />
                                </div>
                                <div className="space-y-1">
                                    <label className="text-[10px] uppercase text-gray-600 font-bold">Target File</label>
                                    <input
                                        value={step.fileTarget}
                                        onChange={(e) => handleStepChange(idx, 'fileTarget', e.target.value)}
                                        className="w-full bg-gray-900 border border-gray-800 rounded-sm px-2 py-1.5 text-xs font-mono text-indigo-300 focus:border-indigo-500 outline-hidden"
                                    />
                                </div>
                            </div>

                            {/* Delete */}
                            <button onClick={() => handleDelete(idx)} className="mt-1 p-2 text-gray-600 hover:text-red-400 hover:bg-red-900/10 rounded-sm transition-colors">
                                <X size={16} />
                            </button>
                        </div>
                    ))}
                </div>

                {/* Add New */}
                <div className="p-4 bg-gray-900 border-t border-gray-800 flex gap-2">
                    <input
                        value={newStepDesc}
                        onChange={(e) => setNewStepDesc(e.target.value)}
                        onKeyDown={(e) => e.key === 'Enter' && handleAddStep()}
                        placeholder="Add a new task step..."
                        className="flex-1 bg-gray-950 border border-gray-800 rounded-sm px-3 py-2 text-sm text-gray-200 focus:border-indigo-500 outline-hidden"
                    />
                    <button onClick={handleAddStep} className="px-4 py-2 bg-gray-800 hover:bg-gray-700 text-gray-300 rounded-sm flex items-center gap-2">
                        <Plus size={16} /> Add
                    </button>
                </div>
            </div>
        </div>
    );
};
</file>

<file path="src/components/SettingsPanel.tsx">
import React, { useState } from 'react';
import { Settings, GitBranch, Wand2, Key, Eye, EyeOff, Server, Globe, User, Plus, Trash2, Save, Wrench, Play, Zap } from 'lucide-react';
import { MakerConfig, AgentProfile, ToolDefinition } from '../types';

interface SettingsPanelProps {
    config: MakerConfig;
    onUpdate: (config: Partial<MakerConfig>) => void;
    isOpen: boolean;
    onToggle: () => void;
}

export const SettingsPanel: React.FC<SettingsPanelProps> = ({ config, onUpdate, isOpen, onToggle }) => {
    const [showKey, setShowKey] = useState(false);
    const [activeTab, setActiveTab] = useState<'general' | 'agents' | 'tools'>('general');

    const [editingAgent, setEditingAgent] = useState<AgentProfile | null>(null);
    const [editingTool, setEditingTool] = useState<ToolDefinition | null>(null);

    if (!isOpen) return null;

    // --- AGENT HANDLERS ---
    const handleAddAgent = () => {
        const newAgent: AgentProfile = {
            id: Math.random().toString(36).substr(2, 9),
            name: "New Agent",
            role: "Developer",
            riskTolerance: 0.5,
            color: "text-gray-400",
            model: config.llmProvider === 'openai' ? config.openaiModel || "gpt-4o" : "gemini-2.0-flash"
        };
        onUpdate({ agentProfiles: [...config.agentProfiles, newAgent] });
        setEditingAgent(newAgent);
    };

    const handleUpdateAgent = (agent: AgentProfile) => {
        const updated = config.agentProfiles.map(p => p.id === agent.id ? agent : p);
        onUpdate({ agentProfiles: updated });
    };

    const handleDeleteAgent = (id: string) => {
        if (config.agentProfiles.length <= 1) return;
        onUpdate({ agentProfiles: config.agentProfiles.filter(p => p.id !== id) });
        if (editingAgent?.id === id) setEditingAgent(null);
    };

    // --- TOOL HANDLERS ---
    const handleAddTool = () => {
        const newTool: ToolDefinition = {
            id: Math.random().toString(36).substr(2, 9),
            name: "New_Tool",
            description: "Description of what this tool does",
            command: "echo {{message}}",
            requiresApproval: true
        };
        const currentTools = config.tools || [];
        onUpdate({ tools: [...currentTools, newTool] });
        setEditingTool(newTool);
    };

    const handleUpdateTool = (tool: ToolDefinition) => {
        const currentTools = config.tools || [];
        const updated = currentTools.map(t => t.id === tool.id ? tool : t);
        onUpdate({ tools: updated });
    };

    const handleDeleteTool = (id: string) => {
        const currentTools = config.tools || [];
        onUpdate({ tools: currentTools.filter(t => t.id !== id) });
        if (editingTool?.id === id) setEditingTool(null);
    };

    return (
        <div className="absolute bottom-full right-0 mb-2 w-96 bg-gray-900 border border-gray-700 rounded-lg shadow-2xl overflow-hidden flex flex-col z-50 max-h-[600px]">

            {/* Header Tabs */}
            <div className="flex items-center border-b border-gray-800 bg-gray-950">
                <button
                    onClick={() => setActiveTab('general')}
                    className={`flex-1 py-3 text-xs font-medium flex items-center justify-center gap-2 ${activeTab === 'general' ? 'text-indigo-400 border-b-2 border-indigo-500' : 'text-gray-500 hover:text-gray-300'}`}
                >
                    <Settings size={14} /> Engine
                </button>
                <button
                    onClick={() => setActiveTab('agents')}
                    className={`flex-1 py-3 text-xs font-medium flex items-center justify-center gap-2 ${activeTab === 'agents' ? 'text-teal-400 border-b-2 border-teal-500' : 'text-gray-500 hover:text-gray-300'}`}
                >
                    <User size={14} /> Agents
                </button>
                <button
                    onClick={() => setActiveTab('tools')}
                    className={`flex-1 py-3 text-xs font-medium flex items-center justify-center gap-2 ${activeTab === 'tools' ? 'text-orange-400 border-b-2 border-orange-500' : 'text-gray-500 hover:text-gray-300'}`}
                >
                    <Wrench size={14} /> Tools
                </button>
            </div>

            <div className="p-4 overflow-y-auto">

                {/* --- GENERAL SETTINGS --- */}
                {activeTab === 'general' && (
                    <div className="space-y-5">
                        {/* Provider Selector */}
                        <div className="space-y-2">
                            <label className="text-xs text-gray-400 font-semibold flex items-center gap-1">
                                <Globe size={12} /> AI Provider
                            </label>
                            <div className="flex bg-gray-950 p-1 rounded-sm border border-gray-800">
                                <button
                                    onClick={() => onUpdate({ llmProvider: 'gemini' })}
                                    className={`flex-1 text-xs py-1 rounded-xs transition-colors ${config.llmProvider === 'gemini' ? 'bg-indigo-600 text-white' : 'text-gray-500 hover:text-gray-300'}`}
                                >
                                    Gemini
                                </button>
                                <button
                                    onClick={() => onUpdate({ llmProvider: 'openai' })}
                                    className={`flex-1 text-xs py-1 rounded-xs transition-colors ${config.llmProvider === 'openai' ? 'bg-indigo-600 text-white' : 'text-gray-500 hover:text-gray-300'}`}
                                >
                                    OpenAI
                                </button>
                            </div>
                        </div>

                        {/* Gemini Config */}
                        {config.llmProvider === 'gemini' && (
                            <div className="bg-gray-950/50 p-3 rounded-sm border border-indigo-500/20">
                                <label className="text-xs text-indigo-400 flex items-center gap-1 mb-2 font-semibold">
                                    <Key size={12} /> Gemini API Key
                                </label>
                                <div className="relative flex items-center">
                                    <input
                                        type={showKey ? "text" : "password"}
                                        value={config.geminiApiKey || ''}
                                        onChange={(e) => onUpdate({ geminiApiKey: e.target.value })}
                                        placeholder="AI Studio Key..."
                                        className="w-full bg-gray-800 border border-gray-700 rounded-sm px-2 py-1.5 text-xs text-gray-200 focus:border-indigo-500 outline-hidden pr-8 font-mono"
                                    />
                                    <button
                                        onClick={() => setShowKey(!showKey)}
                                        className="absolute right-2 text-gray-500 hover:text-gray-300"
                                    >
                                        {showKey ? <EyeOff size={12} /> : <Eye size={12} />}
                                    </button>
                                </div>
                            </div>
                        )}

                        {/* OpenAI Config */}
                        {config.llmProvider === 'openai' && (
                            <div className="bg-gray-950/50 p-3 rounded-sm border border-green-500/20 space-y-3">
                                <div>
                                    <label className="text-xs text-green-400 flex items-center gap-1 mb-1 font-semibold">
                                        <Server size={12} /> Base URL
                                    </label>
                                    <input
                                        type="text"
                                        value={config.openaiBaseUrl || ''}
                                        onChange={(e) => onUpdate({ openaiBaseUrl: e.target.value })}
                                        placeholder="https://api.openai.com/v1"
                                        className="w-full bg-gray-800 border border-gray-700 rounded-sm px-2 py-1.5 text-xs text-gray-200 focus:border-green-500 outline-hidden font-mono"
                                    />
                                </div>
                                <div>
                                    <label className="text-xs text-green-400 flex items-center gap-1 mb-1 font-semibold">
                                        <Key size={12} /> API Key
                                    </label>
                                    <input
                                        type="password"
                                        value={config.openaiApiKey || ''}
                                        onChange={(e) => onUpdate({ openaiApiKey: e.target.value })}
                                        placeholder="sk-..."
                                        className="w-full bg-gray-800 border border-gray-700 rounded-sm px-2 py-1.5 text-xs text-gray-200 focus:border-green-500 outline-hidden font-mono"
                                    />
                                </div>
                                <div>
                                    <label className="text-xs text-green-400 flex items-center gap-1 mb-1 font-semibold">
                                        <Zap size={12} /> Default Model
                                    </label>
                                    <input
                                        type="text"
                                        value={config.openaiModel || ''}
                                        onChange={(e) => onUpdate({ openaiModel: e.target.value })}
                                        placeholder="gpt-4o"
                                        className="w-full bg-gray-800 border border-gray-700 rounded-sm px-2 py-1.5 text-xs text-gray-200 focus:border-green-500 outline-hidden font-mono"
                                    />
                                </div>
                            </div>
                        )}

                        {/* Toggles */}
                        <div className="space-y-3 pt-2 border-t border-gray-800">
                            <div className="flex items-center justify-between">
                                <label className="text-xs text-gray-400 flex items-center gap-1">
                                    <GitBranch size={12} /> Git Worktrees
                                </label>
                                <button
                                    onClick={() => onUpdate({ useGitWorktrees: !config.useGitWorktrees })}
                                    className={`w-10 h-5 rounded-full flex items-center px-0.5 transition-colors ${config.useGitWorktrees ? 'bg-orange-600' : 'bg-gray-700'}`}
                                >
                                    <div className={`w-4 h-4 bg-white rounded-full shadow-xs transition-transform ${config.useGitWorktrees ? 'translate-x-5' : 'translate-x-0'}`} />
                                </button>
                            </div>
                            <div className="flex items-center justify-between">
                                <label className="text-xs text-gray-400 flex items-center gap-1">
                                    <Wand2 size={12} /> Auto-Fix Linter
                                </label>
                                <button
                                    onClick={() => onUpdate({ autoFixLinter: !config.autoFixLinter })}
                                    className={`w-10 h-5 rounded-full flex items-center px-0.5 transition-colors ${config.autoFixLinter ? 'bg-green-600' : 'bg-gray-700'}`}
                                >
                                    <div className={`w-4 h-4 bg-white rounded-full shadow-xs transition-transform ${config.autoFixLinter ? 'translate-x-5' : 'translate-x-0'}`} />
                                </button>
                            </div>
                        </div>
                    </div>
                )}

                {/* --- AGENT ROSTER --- */}
                {activeTab === 'agents' && (
                    <div className="space-y-4">
                        <div className="flex justify-between items-center">
                            <span className="text-xs text-gray-500">Configure your AI team.</span>
                            <button
                                onClick={handleAddAgent}
                                className="text-[10px] bg-teal-600 hover:bg-teal-500 text-white px-2 py-1 rounded-sm flex items-center gap-1"
                            >
                                <Plus size={10} /> Add Agent
                            </button>
                        </div>

                        <div className="space-y-2">
                            {config.agentProfiles.map(agent => (
                                <div key={agent.id} className="bg-gray-950 border border-gray-800 rounded-md p-3 hover:border-gray-700 transition-colors">
                                    {editingAgent?.id === agent.id ? (
                                        <div className="space-y-3 animate-in fade-in">
                                            <div className="grid grid-cols-2 gap-2">
                                                <div>
                                                    <label className="text-[9px] uppercase text-gray-500">Name</label>
                                                    <input
                                                        value={editingAgent.name}
                                                        onChange={e => setEditingAgent({ ...editingAgent, name: e.target.value })}
                                                        className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs text-gray-200"
                                                    />
                                                </div>
                                                <div>
                                                    <label className="text-[9px] uppercase text-gray-500">Role</label>
                                                    <select
                                                        value={editingAgent.role}
                                                        onChange={e => setEditingAgent({ ...editingAgent, role: e.target.value as any })}
                                                        className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs text-gray-300"
                                                    >
                                                        <option value="Architect">Architect</option>
                                                        <option value="Developer">Developer</option>
                                                        <option value="QA">QA</option>
                                                        <option value="Security">Security</option>
                                                    </select>
                                                </div>
                                            </div>
                                            <div>
                                                <label className="text-[9px] uppercase text-gray-500">Model Override</label>
                                                <input
                                                    value={editingAgent.model}
                                                    onChange={e => setEditingAgent({ ...editingAgent, model: e.target.value })}
                                                    className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs font-mono text-gray-300"
                                                    placeholder="Inherit Default"
                                                />
                                            </div>
                                            <div>
                                                <label className="text-[9px] uppercase text-gray-500 flex justify-between">
                                                    <span>Risk Tolerance</span>
                                                    <span>{editingAgent.riskTolerance}</span>
                                                </label>
                                                <input
                                                    type="range" min="0" max="1" step="0.1"
                                                    value={editingAgent.riskTolerance}
                                                    onChange={e => setEditingAgent({ ...editingAgent, riskTolerance: parseFloat(e.target.value) })}
                                                    className="w-full h-1 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-teal-500"
                                                />
                                            </div>
                                            <div className="flex gap-2 pt-2">
                                                <button
                                                    onClick={() => { handleUpdateAgent(editingAgent); setEditingAgent(null); }}
                                                    className="flex-1 bg-green-600 hover:bg-green-500 text-white text-xs py-1.5 rounded-sm flex items-center justify-center gap-1"
                                                >
                                                    <Save size={10} /> Save
                                                </button>
                                            </div>
                                        </div>
                                    ) : (
                                        <div className="flex justify-between items-start">
                                            <div className="flex gap-3">
                                                <div className={`w-8 h-8 rounded bg-gray-900 border border-gray-800 flex items-center justify-center font-bold text-xs ${agent.color}`}>
                                                    {agent.name.charAt(0)}
                                                </div>
                                                <div>
                                                    <div className="text-sm font-bold text-gray-200">{agent.name}</div>
                                                    <div className="text-[10px] text-gray-500 flex items-center gap-1">
                                                        {agent.role} <span className="text-gray-700">‚Ä¢</span> {agent.model}
                                                    </div>
                                                </div>
                                            </div>
                                            <div className="flex gap-1">
                                                <button
                                                    onClick={() => setEditingAgent(agent)}
                                                    className="p-1.5 text-gray-500 hover:text-indigo-400 hover:bg-gray-900 rounded-sm"
                                                >
                                                    <Settings size={12} />
                                                </button>
                                                <button
                                                    onClick={() => handleDeleteAgent(agent.id)}
                                                    className="p-1.5 text-gray-500 hover:text-red-400 hover:bg-gray-900 rounded-sm"
                                                >
                                                    <Trash2 size={12} />
                                                </button>
                                            </div>
                                        </div>
                                    )}
                                </div>
                            ))}
                        </div>
                    </div>
                )}

                {/* --- TOOL REGISTRY --- */}
                {activeTab === 'tools' && (
                    <div className="space-y-4">
                        <div className="flex justify-between items-center">
                            <span className="text-xs text-gray-500">Define custom CLI tools.</span>
                            <button
                                onClick={handleAddTool}
                                className="text-[10px] bg-orange-600 hover:bg-orange-500 text-white px-2 py-1 rounded-sm flex items-center gap-1"
                            >
                                <Plus size={10} /> Add Tool
                            </button>
                        </div>

                        <div className="space-y-2">
                            {(config.tools || []).length === 0 && (
                                <div className="text-center text-gray-600 text-xs py-4 border border-dashed border-gray-800 rounded-md">
                                    No tools defined.
                                </div>
                            )}
                            {(config.tools || []).map(tool => (
                                <div key={tool.id} className="bg-gray-950 border border-gray-800 rounded-md p-3 hover:border-gray-700 transition-colors">
                                    {editingTool?.id === tool.id ? (
                                        <div className="space-y-3 animate-in fade-in">
                                            <div>
                                                <label className="text-[9px] uppercase text-gray-500">Tool Name (Unique)</label>
                                                <input
                                                    value={editingTool.name}
                                                    onChange={e => setEditingTool({ ...editingTool, name: e.target.value.replace(/\s+/g, '_') })}
                                                    className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs text-gray-200 font-mono"
                                                />
                                            </div>
                                            <div>
                                                <label className="text-[9px] uppercase text-gray-500">Command Template</label>
                                                <input
                                                    value={editingTool.command}
                                                    onChange={e => setEditingTool({ ...editingTool, command: e.target.value })}
                                                    className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs text-gray-300 font-mono"
                                                    placeholder="npm run test -- {{file}}"
                                                />
                                                <p className="text-[9px] text-gray-600 mt-1">Use {'{{variable}}'} for dynamic arguments.</p>
                                            </div>
                                            <div>
                                                <label className="text-[9px] uppercase text-gray-500">Description (For AI)</label>
                                                <textarea
                                                    value={editingTool.description}
                                                    onChange={e => setEditingTool({ ...editingTool, description: e.target.value })}
                                                    className="w-full bg-gray-900 border border-gray-700 rounded-sm px-2 py-1 text-xs text-gray-300 h-16 resize-none"
                                                />
                                            </div>
                                            <div className="flex gap-2 pt-2">
                                                <button
                                                    onClick={() => { handleUpdateTool(editingTool); setEditingTool(null); }}
                                                    className="flex-1 bg-green-600 hover:bg-green-500 text-white text-xs py-1.5 rounded-sm flex items-center justify-center gap-1"
                                                >
                                                    <Save size={10} /> Save
                                                </button>
                                            </div>
                                        </div>
                                    ) : (
                                        <div className="flex justify-between items-start">
                                            <div className="flex gap-3">
                                                <div className="w-8 h-8 rounded bg-gray-900 border border-gray-800 flex items-center justify-center text-orange-500">
                                                    <Play size={14} />
                                                </div>
                                                <div>
                                                    <div className="text-sm font-bold text-gray-200 font-mono">{tool.name}</div>
                                                    <div className="text-[10px] text-gray-500 line-clamp-1">
                                                        {tool.command}
                                                    </div>
                                                </div>
                                            </div>
                                            <div className="flex gap-1">
                                                <button
                                                    onClick={() => { setEditingTool(tool); setEditingAgent(null); }}
                                                    className="p-1.5 text-gray-500 hover:text-indigo-400 hover:bg-gray-900 rounded-sm"
                                                >
                                                    <Settings size={12} />
                                                </button>
                                                <button
                                                    onClick={() => handleDeleteTool(tool.id)}
                                                    className="p-1.5 text-gray-500 hover:text-red-400 hover:bg-gray-900 rounded-sm"
                                                >
                                                    <Trash2 size={12} />
                                                </button>
                                            </div>
                                        </div>
                                    )}
                                </div>
                            ))}
                        </div>
                    </div>
                )}

            </div>
        </div>
    );
};
</file>

<file path="src/components/SystemLogs.tsx">
import React, { useEffect, useRef, useState } from 'react';
import { AlertCircle, Info, AlertTriangle, Trash2 } from 'lucide-react';
import { Logger, LogEntry } from '../services/logger';

export const SystemLogs: React.FC = () => {
    const [logs, setLogs] = useState<LogEntry[]>([]);
    const scrollRef = useRef<HTMLDivElement>(null);

    useEffect(() => {
        const logger = Logger.getInstance();
        const unsub = logger.subscribe(setLogs);
        return unsub;
    }, []);

    useEffect(() => {
        if (scrollRef.current) {
            scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
        }
    }, [logs]);

    return (
        <div className="flex flex-col h-full bg-gray-950">
            <div className="flex justify-between items-center px-2 py-1 border-b border-gray-800 bg-gray-900/50">
                <span className="text-[10px] text-gray-500 uppercase tracking-wider">Application Events</span>
                <button
                    onClick={() => Logger.getInstance().clear()}
                    className="p-1 hover:bg-gray-800 rounded text-gray-500 hover:text-gray-300"
                    title="Clear Logs"
                >
                    <Trash2 size={12} />
                </button>
            </div>
            <div className="flex-1 p-2 font-mono text-xs overflow-y-auto" ref={scrollRef}>
                {logs.length === 0 && <div className="text-gray-600 italic p-2">No system logs recorded.</div>}
                {logs.map(log => (
                    <div key={log.id} className="mb-1 flex gap-2 break-all hover:bg-white/5 p-0.5 rounded-sm">
                        <span className="text-gray-600 shrink-0">[{log.timestamp}]</span>
                        <span className="shrink-0 pt-0.5">
                            {log.type === 'error' && <AlertCircle size={12} className="text-red-500" />}
                            {log.type === 'warn' && <AlertTriangle size={12} className="text-yellow-500" />}
                            {log.type === 'info' && <Info size={12} className="text-blue-500" />}
                        </span>
                        <span className={
                            log.type === 'error' ? 'text-red-400' :
                                log.type === 'warn' ? 'text-yellow-400' :
                                    'text-gray-400'
                        }>
                            {log.message}
                        </span>
                    </div>
                ))}
            </div>
        </div>
    );
};
</file>

<file path="src/components/TerminalView.tsx">
import React, { useEffect, useRef, useState } from 'react';
import { VirtualFileSystem } from '../services/virtualFileSystem';
import { MockTauriService, ProcessHandle } from '../services/tauriBridge';
import { XCircle } from 'lucide-react';

interface LogLine {
  id: string;
  type: 'input' | 'stdout' | 'stderr' | 'system';
  content: string;
  cwd?: string;
}

export const TerminalView: React.FC = () => {
  const scrollRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);

  const [history, setHistory] = useState<string[]>([]);
  const [historyIndex, setHistoryIndex] = useState(-1);
  const [cwd, setCwd] = useState<string>('.');
  const [logs, setLogs] = useState<LogLine[]>([
    { id: 'init', type: 'system', content: 'MAKER Shell v2.3.1 [Ready]' },
    { id: 'help', type: 'system', content: 'Commands: git, npm, npx, cd, ls, clear' }
  ]);
  const [input, setInput] = useState('');

  const [activeProcess, setActiveProcess] = useState<ProcessHandle | null>(null);

  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [logs]);

  const addLog = (type: LogLine['type'], content: string, cmdCwd?: string) => {
    setLogs(prev => [...prev, {
      id: Math.random().toString(36),
      type,
      content,
      cwd: cmdCwd
    }]);
  };

  const handleCommand = async (cmdStr: string) => {
    if (!cmdStr.trim()) return;

    setHistory(prev => [...prev, cmdStr]);
    setHistoryIndex(-1);
    addLog('input', cmdStr, cwd);
    setInput('');

    const vfs = VirtualFileSystem.getInstance();
    const projectRoot = vfs.getRoot();

    const parts = cmdStr.match(/(?:[^\s"]+|"[^"]*")+/g)?.map(s => s.replace(/"/g, '')) || [];
    const cmd = parts[0];
    const args = parts.slice(1);

    try {
      if (cmd === 'clear') {
        setLogs([]);
        return;
      }
      if (cmd === 'cd') {
        if (!args[0] || args[0] === '.') { /* noop */ }
        else if (args[0] === '..') {
          const segments = cwd.split('/');
          if (segments.length > 1 && cwd !== '.') {
            segments.pop();
            setCwd(segments.join('/') || '.');
          } else setCwd('.');
        } else {
          setCwd(cwd === '.' ? args[0] : `${cwd}/${args[0]}`);
        }
        return;
      }
      // RESTORED: Internal LS command for fast feedback
      if (cmd === 'ls' || cmd === 'dir') {
        const tree = await vfs.getDirectoryTree();
        // Simple flat list of root for now, ideally filter by CWD
        const listing = tree.map(n => n.isDirectory ? `\u001b[34m${n.name}/\u001b[0m` : n.name).join('  ');
        addLog('stdout', listing || '(empty directory)');
        return;
      }

      const absCwd = projectRoot ? (cwd === '.' ? projectRoot : `${projectRoot}/${cwd}`) : undefined;

      const proc = await MockTauriService.spawnShell(
        cmd,
        args,
        absCwd,
        (data, type) => {
          const cleanData = data.endsWith('\n') ? data.slice(0, -1) : data;
          addLog(type, cleanData);
        },
        (code) => {
          if (code !== 0) addLog('system', `Exited with code ${code}`);
          setActiveProcess(null);
          setTimeout(() => inputRef.current?.focus(), 50);
        }
      );

      setActiveProcess(proc);

    } catch (e: any) {
      addLog('stderr', e.message || 'Execution failed');
    }
  };

  const handleKill = async () => {
    if (activeProcess) {
      await activeProcess.kill();
      setActiveProcess(null);
      addLog('system', '^C');
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      if (activeProcess) {
        // activeProcess.write(input + '\n');
      } else {
        handleCommand(input);
      }
    } else if (e.key === 'c' && e.ctrlKey) {
      if (activeProcess) {
        handleKill();
      } else {
        setInput('');
        addLog('input', '^C', cwd);
      }
    } else if (e.key === 'ArrowUp') {
      e.preventDefault();
      if (history.length > 0) {
        const newIdx = historyIndex === -1 ? history.length - 1 : Math.max(0, historyIndex - 1);
        setHistoryIndex(newIdx);
        setInput(history[newIdx]);
      }
    } else if (e.key === 'ArrowDown') {
      e.preventDefault();
      if (historyIndex !== -1) {
        const newIdx = Math.min(history.length - 1, historyIndex + 1);
        setHistoryIndex(newIdx);
        setInput(history[newIdx]);
      } else {
        setInput('');
      }
    }
  };

  return (
    <div className="h-full w-full bg-gray-950 flex flex-col">
      <div
        className="flex-1 p-2 font-mono text-xs overflow-y-auto"
        onClick={() => inputRef.current?.focus()}
        ref={scrollRef}
      >
        {logs.map((log) => (
          <div key={log.id} className="mb-0.5 break-all whitespace-pre-wrap leading-relaxed">
            {log.type === 'input' && (
              <div className="flex items-center gap-2 text-gray-500 mt-2 mb-1">
                <span className="text-indigo-400 font-bold">‚ûú</span>
                <span className="text-cyan-600">{log.cwd}</span>
                <span className="text-gray-300">{log.content}</span>
              </div>
            )}
            {log.type !== 'input' && (
              <div className="pl-4">
                <AnsiRenderer text={log.content} type={log.type} />
              </div>
            )}
          </div>
        ))}

        <div className="flex items-center gap-2 mt-2 pl-0.5">
          <span className={`font-bold ${activeProcess ? 'text-yellow-500 animate-pulse' : 'text-green-500'}`}>
            {activeProcess ? '‚öô' : '‚ûú'}
          </span>
          <span className="text-cyan-600">{cwd}</span>
          <input
            ref={inputRef}
            type="text"
            className="flex-1 bg-transparent outline-hidden border-none text-gray-100 placeholder-gray-700"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={handleKeyDown}
            autoFocus
            spellCheck={false}
            autoComplete="off"
            disabled={!!activeProcess}
            placeholder={activeProcess ? "Running... (Ctrl+C to stop)" : ""}
          />
        </div>
      </div>

      {activeProcess && (
        <div className="h-8 bg-gray-900 border-t border-gray-800 flex items-center justify-between px-4">
          <span className="text-xs text-yellow-500 flex items-center gap-2">
            <div className="w-2 h-2 bg-yellow-500 rounded-full animate-ping"></div>
            Process Active (PID: {activeProcess.pid})
          </span>
          <button
            onClick={handleKill}
            className="flex items-center gap-1 text-xs text-red-400 hover:text-red-300 bg-red-900/20 px-2 py-1 rounded-sm border border-red-900/50 transition-colors"
          >
            <XCircle size={12} /> Stop
          </button>
        </div>
      )}
    </div>
  );
};

const AnsiRenderer: React.FC<{ text: string, type: string }> = ({ text, type }) => {
  if (!text) return null;
  const baseClass = type === 'stderr' ? 'text-red-400' : type === 'system' ? 'text-blue-400' : 'text-gray-300';
  const parts = text.split(/(\u001b\[\d+m)/g);
  let currentColor = baseClass;
  let isBold = false;

  return (
    <span>
      {parts.map((part, i) => {
        if (part.startsWith('\u001b[')) {
          if (part === '\u001b[0m') { currentColor = baseClass; isBold = false; }
          else if (part === '\u001b[1m') { isBold = true; }
          else if (part === '\u001b[31m') { currentColor = 'text-red-500'; }
          else if (part === '\u001b[32m') { currentColor = 'text-green-500'; }
          else if (part === '\u001b[33m') { currentColor = 'text-yellow-500'; }
          else if (part === '\u001b[34m') { currentColor = 'text-blue-500'; }
          else if (part === '\u001b[36m') { currentColor = 'text-cyan-500'; }
          return null;
        }
        return <span key={i} className={`${currentColor} ${isBold ? 'font-bold' : ''}`}>{part}</span>;
      })}
    </span>
  );
};
</file>

<file path="src/components/Toast.tsx">
import React, { useEffect } from 'react';
import { X, CheckCircle, AlertCircle, Info } from 'lucide-react';

export interface ToastMessage {
    id: string;
    type: 'success' | 'error' | 'info';
    message: string;
}

interface ToastContainerProps {
    toasts: ToastMessage[];
    onDismiss: (id: string) => void;
}

export const ToastContainer: React.FC<ToastContainerProps> = ({ toasts, onDismiss }) => {
    return (
        <div className="fixed bottom-4 right-4 z-50 flex flex-col gap-2 pointer-events-none">
            {toasts.map(t => (
                <ToastItem key={t.id} toast={t} onDismiss={onDismiss} />
            ))}
        </div>
    );
};

const ToastItem: React.FC<{ toast: ToastMessage, onDismiss: (id: string) => void }> = ({ toast, onDismiss }) => {
    useEffect(() => {
        const timer = setTimeout(() => {
            onDismiss(toast.id);
        }, 5000);
        return () => clearTimeout(timer);
    }, [toast.id, onDismiss]);

    const bg = toast.type === 'success' ? 'bg-green-900/90 border-green-500/50' :
        toast.type === 'error' ? 'bg-red-900/90 border-red-500/50' :
            'bg-gray-800/90 border-gray-600/50';

    const icon = toast.type === 'success' ? <CheckCircle size={16} className="text-green-400" /> :
        toast.type === 'error' ? <AlertCircle size={16} className="text-red-400" /> :
            <Info size={16} className="text-blue-400" />;

    return (
        <div className={`pointer-events-auto flex items-center gap-3 px-4 py-3 rounded-sm shadow-lg border backdrop-blur-xs animate-in slide-in-from-right fade-in duration-300 w-80 ${bg}`}>
            {icon}
            <p className="flex-1 text-xs text-gray-200">{toast.message}</p>
            <button onClick={() => onDismiss(toast.id)} className="text-gray-400 hover:text-white">
                <X size={14} />
            </button>
        </div>
    );
};
</file>

<file path="src/components/VotingInspector.tsx">
import React from 'react';
import { X, Award, GitGraph, ThumbsUp, ShieldAlert } from 'lucide-react';
import { SubTask, AgentCandidate } from '../types';

interface VotingInspectorProps {
    step: SubTask;
    onClose: () => void;
}

export const VotingInspector: React.FC<VotingInspectorProps> = ({ step, onClose }) => {
    if (!step.candidates || step.candidates.length === 0) return null;

    const sortedCandidates = [...step.candidates].sort((a, b) => b.voteCount - a.voteCount);

    return (
        <div className="absolute inset-0 z-50 flex items-center justify-center bg-gray-950/80 backdrop-blur-xs p-8">
            <div className="bg-gray-900 border border-gray-700 rounded-xl shadow-2xl w-full max-w-5xl h-[80vh] flex flex-col overflow-hidden animate-in fade-in zoom-in-95 duration-200">

                {/* Header */}
                <div className="h-16 border-b border-gray-800 flex items-center justify-between px-6 bg-gray-900">
                    <div>
                        <h2 className="text-lg font-bold text-gray-100 flex items-center gap-2">
                            <GitGraph className="text-purple-500" />
                            Consensus Inspector
                        </h2>
                        <p className="text-xs text-gray-500 font-mono">Step ID: {step.id} ‚Ä¢ {step.description}</p>
                    </div>
                    <button onClick={onClose} className="p-2 hover:bg-gray-800 rounded-full transition-colors text-gray-400 hover:text-white">
                        <X size={20} />
                    </button>
                </div>

                {/* Body */}
                <div className="flex-1 overflow-hidden flex">
                    {/* Candidate List */}
                    <div className="w-1/3 border-r border-gray-800 bg-gray-900/50 overflow-y-auto p-4 space-y-4">
                        <div className="text-xs font-semibold text-gray-500 uppercase tracking-wider mb-2">Agent Proposals</div>

                        {sortedCandidates.map((cand, idx) => (
                            <div key={cand.id} className={`p-4 rounded-lg border relative ${idx === 0
                                ? 'bg-purple-900/10 border-purple-500/50'
                                : 'bg-gray-800/30 border-gray-700 hover:border-gray-600'
                                }`}>
                                {idx === 0 && (
                                    <div className="absolute -top-2 -right-2 bg-purple-600 text-white p-1 rounded-full shadow-lg">
                                        <Award size={14} />
                                    </div>
                                )}
                                <div className="flex justify-between items-center mb-2">
                                    <span className={`text-sm font-bold ${idx === 0 ? 'text-purple-300' : 'text-gray-300'}`}>
                                        {cand.agentName}
                                    </span>
                                    <span className="flex items-center gap-1 text-xs bg-gray-950 px-2 py-1 rounded-sm border border-gray-800">
                                        <ThumbsUp size={10} className={idx === 0 ? 'text-purple-400' : 'text-gray-500'} />
                                        {cand.voteCount} Votes
                                    </span>
                                </div>
                                <p className="text-xs text-gray-500 italic mb-2">"{cand.reasoning}"</p>
                                <div className="text-[10px] font-mono bg-gray-950/50 p-2 rounded-sm text-gray-400 overflow-hidden h-20 relative">
                                    {cand.content}
                                    <div className="absolute inset-x-0 bottom-0 h-8 bg-linear-to-t from-gray-950 to-transparent"></div>
                                </div>
                            </div>
                        ))}
                    </div>

                    {/* Winner Detail View */}
                    <div className="flex-1 flex flex-col bg-gray-950">
                        <div className="p-4 border-b border-gray-800 bg-purple-900/5 flex items-center justify-between">
                            <span className="text-xs font-bold text-purple-400 flex items-center gap-2">
                                <Award size={14} /> WINNING CANDIDATE
                            </span>
                            <div className="flex gap-2">
                                <span className="text-[10px] px-2 py-0.5 rounded-sm bg-green-900/20 text-green-400 border border-green-900/30">Linter Passed</span>
                                <span className="text-[10px] px-2 py-0.5 rounded-sm bg-blue-900/20 text-blue-400 border border-blue-900/30">Security Verified</span>
                            </div>
                        </div>
                        <div className="flex-1 p-6 overflow-auto font-mono text-sm leading-relaxed text-gray-300">
                            <pre>{sortedCandidates[0].content}</pre>
                        </div>
                    </div>
                </div>

                {/* Footer */}
                <div className="h-12 border-t border-gray-800 bg-gray-900 flex items-center px-6 gap-4 text-xs text-gray-500">
                    <ShieldAlert size={14} className="text-yellow-500" />
                    <span>Consensus reached with {(step.votes / 3 * 100).toFixed(0)}% confidence. Risk score: {step.riskScore.toFixed(2)}.</span>
                </div>
            </div>
        </div>
    );
};
</file>

<file path="src/index.css">
@import 'tailwindcss';

/*
  The default border color has changed to `currentcolor` in Tailwind CSS v4,
  so we've added these compatibility styles to make sure everything still
  looks the same as it did with Tailwind CSS v3.

  If we ever want to remove these styles, we need to add an explicit border
  color utility to any element that depends on these defaults.
*/
@layer base {
  *,
  ::after,
  ::before,
  ::backdrop,
  ::file-selector-button {
    border-color: var(--color-gray-200, currentcolor);
  }
}

@utility animate-in {
  animation-duration: 300ms;
  animation-fill-mode: forwards;
}

@layer utilities {
  /* Custom Scrollbar */
  ::-webkit-scrollbar {
    width: 10px;
    height: 10px;
  }

  ::-webkit-scrollbar-track {
    background: #0d1117;
  }

  ::-webkit-scrollbar-thumb {
    background: #2d3748;
    border-radius: 5px;
  }

  ::-webkit-scrollbar-thumb:hover {
    background: #4a5568;
  }
}
</file>

<file path="src/index.tsx">
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import { Logger } from './services/logger';

// Initialize Logger early to capture startup events
Logger.getInstance();

const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}

const root = ReactDOM.createRoot(rootElement);
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);
</file>

<file path="src/services/contextManager.ts">
import { VirtualFileSystem } from "./virtualFileSystem";
import { LanguageRegistry } from "./languages/registry";

export interface ProjectContext {
    fileTree: string;
    manifests: string;
    scoutedFiles: { path: string, content: string }[];
}

export class ContextManager {
    private static instance: ContextManager;
    private vfs: VirtualFileSystem;
    private langRegistry: LanguageRegistry;

    private constructor() {
        this.vfs = VirtualFileSystem.getInstance();
        this.langRegistry = LanguageRegistry.getInstance();
    }

    public static getInstance(): ContextManager {
        if (!ContextManager.instance) {
            ContextManager.instance = new ContextManager();
        }
        return ContextManager.instance;
    }

    async getArchitectContext(userPrompt: string): Promise<ProjectContext> {
        const fileTree = await this.generateFileTree();
        const manifests = await this.getManifests();
        const scoutedFiles = await this.scoutFiles(userPrompt);

        return {
            fileTree,
            manifests,
            scoutedFiles
        };
    }

    async getTaskContext(fileTarget: string, dependencies: string[]): Promise<string> {
        let context = "";

        // 1. Target File
        const targetContent = await this.vfs.readFile(fileTarget);
        if (targetContent) {
            context += `\n--- CURRENT CONTENT: ${fileTarget} ---\n${targetContent}\n`;
        }

        // 2. Dependencies
        for (const depPath of dependencies) {
            const content = await this.vfs.readFile(depPath);
            if (content) {
                context += `\n--- REFERENCE: ${depPath} ---\n${content}\n`;
            }
        }

        // 3. Language Specific Guidelines
        const provider = this.langRegistry.getProvider(fileTarget);
        if (provider) {
            context += `\n--- LANGUAGE RULES ---\n${provider.getSystemPrompt()}\n`;
        }

        return context;
    }

    async expandContext(errorMessage: string): Promise<string> {
        const match = errorMessage.match(/'([^']+)'/) || errorMessage.match(/"([^"]+)"/);

        if (match) {
            const symbol = match[1];
            console.log(`[ContextManager] Failsafe triggered. Hunting for symbol: ${symbol}`);

            const tree = await this.vfs.getDirectoryTree();
            const foundFile = this.findFileInTree(tree, symbol);

            if (foundFile) {
                const content = await this.vfs.readFile(foundFile);
                return `\n--- AUTO-DISCOVERED CONTEXT (${foundFile}) ---\n${content}\n`;
            }
        }

        return "";
    }

    private async generateFileTree(): Promise<string> {
        const tree = await this.vfs.getDirectoryTree();
        return this.renderTree(tree);
    }

    private renderTree(nodes: any[], depth = 0): string {
        let output = "";
        const indent = "  ".repeat(depth);

        for (const node of nodes) {
            if (['node_modules', 'target', 'venv', '.git', 'dist', '.maker'].includes(node.name)) continue;

            output += `${indent}${node.name}${node.isDirectory ? '/' : ''}\n`;
            if (node.children) {
                output += this.renderTree(node.children, depth + 1);
            }
        }
        return output;
    }

    private async getManifests(): Promise<string> {
        let output = "";

        // Dynamic Manifest Loading based on Language Registry
        const manifestNames = this.langRegistry.getAllManifests();
        // Deduplicate
        const uniqueManifests = [...new Set(manifestNames)];

        for (const name of uniqueManifests) {
            // We search in root for these files
            // In a real app we might search deeper, but root is standard for manifests
            const content = await this.vfs.readFile(`/${name}`);
            if (content) {
                output += `\n--- ${name} ---\n${content}\n`;
            }
        }

        return output;
    }

    private async scoutFiles(prompt: string): Promise<{ path: string, content: string }[]> {
        const keywords = prompt.toLowerCase().split(' ').filter(w => w.length > 4);
        const results: { path: string, content: string }[] = [];

        if (keywords.length === 0) return [];

        const tree = await this.vfs.getDirectoryTree();
        const files = this.flattenTree(tree);

        for (const file of files) {
            if (results.length >= 3) break;

            const fileName = file.split('/').pop()?.toLowerCase() || "";
            if (keywords.some(k => fileName.includes(k))) {
                const content = await this.vfs.readFile(file);
                if (content) results.push({ path: file, content: content.substring(0, 1000) + "..." });
            }
        }

        return results;
    }

    private flattenTree(nodes: any[], prefix = ''): string[] {
        let results: string[] = [];
        for (const node of nodes) {
            if (['node_modules', 'target', 'venv', '.git'].includes(node.name)) continue;
            if (!node.isDirectory) {
                results.push(node.path);
            } else if (node.children) {
                results = [...results, ...this.flattenTree(node.children)];
            }
        }
        return results;
    }

    private findFileInTree(nodes: any[], query: string): string | null {
        const q = query.toLowerCase();
        for (const node of nodes) {
            if (['node_modules', 'target', 'venv'].includes(node.name)) continue;

            // Heuristic matching for TS, Rust, Python
            if (!node.isDirectory) {
                const n = node.name.toLowerCase();
                if (n === `${q}.ts` || n === `${q}.tsx` || n === `${q}.rs` || n === `${q}.py`) {
                    return node.path;
                }
            }

            if (node.children) {
                const found = this.findFileInTree(node.children, query);
                if (found) return found;
            }
        }
        return null;
    }
}
</file>

<file path="src/services/engine/decompositionService.ts">
import { Type } from "@google/genai";
import { SubTask, ToolDefinition } from "../../types";
import { LLMClient } from "../llm";
import { ContextManager } from "../contextManager";

export class DecompositionService {
    constructor(
        private llm: LLMClient | null,
        private contextManager: ContextManager
    ) { }

    async decompose(prompt: string, tools: ToolDefinition[] = []): Promise<Partial<SubTask>[]> {
        if (!this.llm) {
            console.log("[Decomposition] No LLM Client. Using Mock.");
            await new Promise(r => setTimeout(r, 1000));
            return [
                { id: "1", description: "Setup Project Config", fileTarget: "package.json", dependencies: [] }
            ];
        }

        try {
            console.log("[Decomposition] Analyzing request...");

            const context = await this.contextManager.getArchitectContext(prompt);

            const scoutedInfo = context.scoutedFiles.length > 0
                ? `\nRELEVANT FILES FOUND:\n${context.scoutedFiles.map(f => `FILE: ${f.path}\n${f.content}`).join('\n')}`
                : "";

            const toolsInfo = tools.length > 0
                ? `\nAVAILABLE TOOLS:\n${tools.map(t => `- Name: ${t.name}\n  Description: ${t.description}\n  Args: ${t.command.match(/{{(.*?)}}/g)?.join(', ') || 'None'}`).join('\n')}`
                : "";

            const systemPrompt = `
                SYSTEM: You are the Lead Architect of the MAKER Framework.
                GOAL: Decompose the user's request into a set of ATOMIC steps.
                
                PROJECT CONTEXT:
                - Manifests: ${context.manifests}
                - File Tree:
                ${context.fileTree}
                ${scoutedInfo}
                ${toolsInfo}
                
                RULES:
                1. Granularity: Each step must touch ONLY ONE file OR execute ONE tool.
                2. Dependencies: Build a logical dependency graph.
                3. Tool Usage: If a tool is available and relevant (e.g. 'run_tests'), use it.
                4. Output: STRICT JSON Array.
                
                SCHEMA:
                {
                    id: string,
                    description: string,
                    fileTarget: string,
                    dependencies: string[],
                    toolCall?: { toolName: string, arguments: { [key: string]: string } }
                }
            `;

            const schema = {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        id: { type: Type.STRING },
                        description: { type: Type.STRING },
                        fileTarget: { type: Type.STRING },
                        dependencies: { type: Type.ARRAY, items: { type: Type.STRING } },
                        toolCall: {
                            type: Type.OBJECT,
                            properties: {
                                toolName: { type: Type.STRING },
                                arguments: { type: Type.OBJECT }
                            },
                            required: ["toolName", "arguments"]
                        }
                    },
                    required: ["id", "description", "fileTarget", "dependencies"]
                }
            };

            const response = await this.llm.generate(systemPrompt, `USER REQUEST: "${prompt}"`, schema);

            let jsonStr = response.text;
            if (jsonStr.includes('```json')) {
                jsonStr = jsonStr.split('```json')[1].split('```')[0].trim();
            } else if (jsonStr.includes('```')) {
                jsonStr = jsonStr.split('```')[1].split('```')[0].trim();
            }

            return JSON.parse(jsonStr);

        } catch (e: any) {
            console.error("AI Decomposition failed:", e);
            // FIX: Propagate the actual error message so it appears in the UI
            throw new Error(`AI Decomposition failed: ${e.message || JSON.stringify(e)}`);
        }
    }

    async replan(failedStep: SubTask, errorLog: string): Promise<Partial<SubTask>[]> {
        if (!this.llm) return [];

        console.log(`[Re-planning] Attempting to rescue step: ${failedStep.description}`);

        const systemPrompt = `
            SYSTEM: You are the Crisis Manager of the MAKER Framework.
            SITUATION: An agent failed to execute a step.
            GOAL: Break down the FAILED STEP into smaller, simpler sub-steps to resolve the error.
            
            FAILED STEP: "${failedStep.description}"
            TARGET FILE: ${failedStep.fileTarget}
            ERROR LOG:
            ${errorLog}
            
            RULES:
            1. Analyze the error. Is it a missing file? A syntax error? A logic error?
            2. Create 1-3 new atomic steps to fix the issue.
            3. If the error is unrecoverable (e.g. "API Key invalid"), return an empty array.
            4. Output: STRICT JSON Array of new steps.
        `;

        const schema = {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    id: { type: Type.STRING },
                    description: { type: Type.STRING },
                    fileTarget: { type: Type.STRING },
                    dependencies: { type: Type.ARRAY, items: { type: Type.STRING } },
                    riskReason: { type: Type.STRING }
                },
                required: ["id", "description", "fileTarget", "dependencies"]
            }
        };

        try {
            const response = await this.llm.generate(systemPrompt, "Please provide the rescue plan.", schema);

            let jsonStr = response.text;
            if (jsonStr.includes('```json')) {
                jsonStr = jsonStr.split('```json')[1].split('```')[0].trim();
            } else if (jsonStr.includes('```')) {
                jsonStr = jsonStr.split('```')[1].split('```')[0].trim();
            }

            const newSteps = JSON.parse(jsonStr);

            // Ensure IDs are unique
            return newSteps.map((s: any) => ({
                ...s,
                id: `${failedStep.id}-rescue-${Math.random().toString(36).substr(2, 4)}`,
                // Inherit dependencies from the failed step plus any internal sequence
                dependencies: s.dependencies.length ? s.dependencies : failedStep.dependencies
            }));

        } catch (e) {
            console.error("Re-planning failed:", e);
            return [];
        }
    }
}
</file>

<file path="src/services/engine/votingService.ts">
import { Type } from "@google/genai";
import { SubTask, VoteResult, AgentCandidate, AgentProfile } from "../../types";
import { LLMClient } from "../llm";

export class VotingService {
    constructor(private llm: LLMClient | null) { }

    async performVoting(
        step: SubTask,
        leadAgent: AgentProfile,
        context: string,
        agentProfiles: AgentProfile[],
        codeGenerator: (agent: AgentProfile) => Promise<string>
    ): Promise<VoteResult> {

        // 1. Select Voters
        const voters = agentProfiles.filter(p => p.id !== leadAgent.id).slice(0, 2);
        voters.unshift(leadAgent);

        const candidates: AgentCandidate[] = [];

        // 2. Generate Proposals
        await Promise.all(voters.map(async (voter) => {
            const content = await codeGenerator(voter);
            candidates.push({
                id: voter.id,
                agentName: voter.name,
                content: content,
                voteCount: 0,
                reasoning: `Proposed by ${voter.role}`
            });
        }));

        // 3. Semantic Judge
        if (this.llm) {
            try {
                const candidatesPrompt = candidates.map(c =>
                    `--- CANDIDATE ${c.id} (${c.agentName}) ---\n${c.content}\n`
                ).join('\n');

                const schema = {
                    type: Type.OBJECT,
                    properties: {
                        winnerId: { type: Type.STRING },
                        reasoning: { type: Type.STRING }
                    },
                    required: ["winnerId", "reasoning"]
                };

                const response = await this.llm.generate(
                    "SYSTEM: You are the Chief Architect. Evaluate these 3 implementations. Return JSON.",
                    `TASK: ${step.description}\nCONTEXT:\n${context}\n\n${candidatesPrompt}`,
                    schema
                );

                let jsonStr = response.text;
                if (jsonStr.includes('```json')) {
                    jsonStr = jsonStr.split('```json')[1].split('```')[0].trim();
                } else if (jsonStr.includes('```')) {
                    jsonStr = jsonStr.split('```')[1].split('```')[0].trim();
                }

                const decision = JSON.parse(jsonStr);
                const winner = candidates.find(c => c.id === decision.winnerId) || candidates[0];

                winner.voteCount = voters.length;
                winner.reasoning = `[JUDGE] ${decision.reasoning}`;

                return {
                    winner: winner.content,
                    voteCount: voters.length,
                    totalVotes: voters.length,
                    isConsensus: true,
                    candidates
                };
            } catch (e) {
                console.error("Judge failed:", e);
            }
        }

        // Fallback
        const winner = candidates[0];
        winner.voteCount = 1;
        return {
            winner: winner.content,
            voteCount: 1,
            totalVotes: voters.length,
            isConsensus: false,
            candidates
        };
    }
}
</file>

<file path="src/services/languages/interface.ts">
export interface LanguageProvider {
    /**
     * Unique ID for the language (e.g., "typescript", "rust")
     */
    id: string;

    /**
     * Returns true if this provider handles the given file extension
     */
    supports(filePath: string): boolean;

    /**
     * Returns the list of configuration files relevant to this language
     * (e.g., package.json, Cargo.toml)
     */
    getManifestFiles(): string[];

    /**
     * Runs the language-specific linter on a file.
     * Returns an array of error messages.
     */
    lintFile(filePath: string, projectRoot: string): Promise<string[]>;

    /**
     * Returns a system prompt snippet describing best practices for this language
     */
    getSystemPrompt(): string;
}
</file>

<file path="src/services/languages/python.ts">
import { LanguageProvider } from "./interface";
import { MockTauriService } from "../tauriBridge";

export class PythonProvider implements LanguageProvider {
    id = "python";

    supports(filePath: string): boolean {
        return /\.(py|txt|toml)$/.test(filePath);
    }

    getManifestFiles(): string[] {
        return ['requirements.txt', 'pyproject.toml', 'setup.py'];
    }

    getSystemPrompt(): string {
        return `
        LANGUAGE CONTEXT: Python
        - Follow PEP 8 style guide.
        - Use type hints (typing module) for all function signatures.
        - Use docstrings for classes and methods.
        - Prefer f-strings over .format().
        `;
    }

    async lintFile(filePath: string, projectRoot: string): Promise<string[]> {
        const errors: string[] = [];

        try {
            const content = await MockTauriService.readFile(filePath);

            // SECURITY CHECKS
            if (content.match(/import\s+subprocess/)) errors.push("SECURITY: 'subprocess' module forbidden.");
            if (content.match(/import\s+os/) && content.includes('os.system')) errors.push("SECURITY: 'os.system' usage forbidden.");
            if (content.match(/\beval\s*\(/)) errors.push("SECURITY: 'eval()' usage forbidden.");
            if (content.match(/\bexec\s*\(/)) errors.push("SECURITY: 'exec()' usage forbidden.");

            if (content.includes('print(')) errors.push("Use 'logging' module instead of print().");
        } catch { }

        try {
            const output = await MockTauriService.executeShell('flake8', ['--format=default', filePath], projectRoot);
            const lines = output.split('\n');
            for (const line of lines) {
                if (line.includes(filePath)) {
                    errors.push(`[Flake8] ${line}`);
                }
            }
        } catch (e) { }

        return errors;
    }
}
</file>

<file path="src/services/languages/registry.ts">
import { LanguageProvider } from "./interface";
import { TypeScriptProvider } from "./typescript";
import { RustProvider } from "./rust";
import { PythonProvider } from "./python";

export class LanguageRegistry {
    private static instance: LanguageRegistry;
    private providers: LanguageProvider[] = [];

    private constructor() {
        this.providers = [
            new TypeScriptProvider(),
            new RustProvider(),
            new PythonProvider()
        ];
    }

    public static getInstance(): LanguageRegistry {
        if (!LanguageRegistry.instance) {
            LanguageRegistry.instance = new LanguageRegistry();
        }
        return LanguageRegistry.instance;
    }

    public getProvider(filePath: string): LanguageProvider | null {
        return this.providers.find(p => p.supports(filePath)) || null;
    }

    public getAllManifests(): string[] {
        return this.providers.flatMap(p => p.getManifestFiles());
    }
}
</file>

<file path="src/services/languages/rust.ts">
import { LanguageProvider } from "./interface";
import { MockTauriService } from "../tauriBridge";

export class RustProvider implements LanguageProvider {
    id = "rust";

    supports(filePath: string): boolean {
        return /\.(rs|toml)$/.test(filePath);
    }

    getManifestFiles(): string[] {
        return ['Cargo.toml', 'Cargo.lock'];
    }

    getSystemPrompt(): string {
        return `
        LANGUAGE CONTEXT: Rust
        - Follow standard formatting (rustfmt).
        - Handle all Result/Option types (no .unwrap() in production code).
        - Use idiomatic error handling (thiserror/anyhow).
        - Prefer references (&str) over owning Strings where possible.
        `;
    }

    async lintFile(filePath: string, projectRoot: string): Promise<string[]> {
        const errors: string[] = [];

        try {
            const content = await MockTauriService.readFile(filePath);

            // SECURITY CHECKS
            if (content.includes('std::process::Command')) errors.push("SECURITY: 'std::process::Command' usage forbidden.");
            if (content.includes('unsafe {')) errors.push("SECURITY: 'unsafe' blocks require manual review.");

            if (content.includes('.unwrap()')) errors.push("Avoid .unwrap(), use match or ? operator.");
            if (content.includes('println!')) errors.push("Use proper logging instead of println!.");
        } catch { }

        try {
            const output = await MockTauriService.executeShell('cargo', ['clippy', '--message-format=json', '--no-deps'], projectRoot);
            const lines = output.split('\n');
            for (const line of lines) {
                if (!line.trim()) continue;
                try {
                    const msg = JSON.parse(line);
                    if (msg.reason === 'compiler-message' && msg.message) {
                        const span = msg.message.spans?.[0];
                        if (span && span.file_name && filePath.endsWith(span.file_name)) {
                            errors.push(`[Rustc] Line ${span.line_start}: ${msg.message.message}`);
                        }
                    }
                } catch { }
            }
        } catch (e) { }

        return errors;
    }
}
</file>

<file path="src/services/languages/typescript.ts">
import { LanguageProvider } from "./interface";
import { MockTauriService } from "../tauriBridge";

export class TypeScriptProvider implements LanguageProvider {
    id = "typescript";

    supports(filePath: string): boolean {
        return /\.(ts|tsx|js|jsx|json)$/.test(filePath);
    }

    getManifestFiles(): string[] {
        return ['package.json', 'tsconfig.json', '.eslintrc.json'];
    }

    getSystemPrompt(): string {
        return `
        LANGUAGE CONTEXT: TypeScript/Node.js
        - Use 'const' over 'var'.
        - Prefer Interfaces over Types for object definitions.
        - strictNullChecks is ON. Handle null/undefined explicitly.
        - Use ES Modules (import/export).
        `;
    }

    async lintFile(filePath: string, projectRoot: string): Promise<string[]> {
        const errors: string[] = [];

        try {
            const content = await MockTauriService.readFile(filePath);

            // SECURITY CHECKS
            if (content.match(/import\s+.*\s+from\s+['"]child_process['"]/)) errors.push("SECURITY: 'child_process' import forbidden.");
            if (content.match(/require\(['"]child_process['"]\)/)) errors.push("SECURITY: 'child_process' require forbidden.");
            if (content.match(/\beval\s*\(/)) errors.push("SECURITY: 'eval()' usage forbidden.");
            if (content.match(/\bexec\s*\(/)) errors.push("SECURITY: 'exec()' usage forbidden.");

            // Best Practices
            if (content.includes(': any')) errors.push("Explicit 'any' type is forbidden.");
            if (content.includes('console.log')) errors.push("Remove console.log before committing.");
        } catch { }

        try {
            const output = await MockTauriService.executeShell('npx', ['eslint', '--format=json', filePath], projectRoot);
            const results = JSON.parse(output);
            if (Array.isArray(results)) {
                results.forEach(res => {
                    res.messages?.forEach((msg: any) => {
                        errors.push(`[ESLint] Line ${msg.line}: ${msg.message}`);
                    });
                });
            }
        } catch (e) {
            // ESLint optional
        }

        return errors;
    }
}
</file>

<file path="src/services/llm.ts">
import { GoogleGenAI } from "@google/genai";
import { MakerConfig } from "../types";

export interface LLMResponse {
    text: string;
}

export interface LLMClient {
    generate(systemPrompt: string, userPrompt: string, schema?: any): Promise<LLMResponse>;
}

export class LLMFactory {
    static create(config: MakerConfig): LLMClient {
        if (config.llmProvider === 'openai') {
            return new OpenAIClient(config);
        }
        return new GeminiClient(config);
    }
}

class GeminiClient implements LLMClient {
    private ai: GoogleGenAI | null = null;

    constructor(private config: MakerConfig) {
        if (config.geminiApiKey) {
            this.ai = new GoogleGenAI({ apiKey: config.geminiApiKey });
        }
    }

    async generate(systemPrompt: string, userPrompt: string, schema?: any): Promise<LLMResponse> {
        if (!this.ai) throw new Error("Gemini API Key missing");

        const modelId = "gemini-2.0-flash";
        const reqConfig: any = { responseMimeType: "text/plain" };

        if (schema) {
            reqConfig.responseMimeType = "application/json";
            reqConfig.responseSchema = schema;
        }

        try {
            console.log(`[LLM] Gemini Request: ${modelId}`);
            const response = await this.ai.models.generateContent({
                model: modelId,
                contents: [
                    { role: 'user', parts: [{ text: systemPrompt + "\n\n" + userPrompt }] }
                ],
                config: reqConfig
            });
            return { text: response.text || "" };
        } catch (e: any) {
            console.error("[LLM] Gemini Error:", e);
            throw new Error(`Gemini Error: ${e.message}`);
        }
    }
}

class OpenAIClient implements LLMClient {
    constructor(private config: MakerConfig) { }

    async generate(systemPrompt: string, userPrompt: string, schema?: any): Promise<LLMResponse> {
        const apiKey = this.config.openaiApiKey || "";

        // DEBUG: Log key status (Masked)
        if (!apiKey) {
            console.error("[LLM] OpenAI Client initialized WITHOUT API Key.");
        } else {
            console.log(`[LLM] OpenAI Client using Key: ${apiKey.substring(0, 4)}...${apiKey.substring(apiKey.length - 4)}`);
        }

        let baseUrl = (this.config.openaiBaseUrl || "https://api.openai.com/v1").trim();
        if (baseUrl.endsWith('/')) baseUrl = baseUrl.slice(0, -1);
        if (baseUrl.endsWith('/chat/completions')) baseUrl = baseUrl.replace('/chat/completions', '');

        const model = this.config.openaiModel || "gpt-4o";
        const endpoint = `${baseUrl}/chat/completions`;

        console.log(`[LLM] OpenAI Request: ${model} -> ${endpoint}`);

        const headers = {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
        };

        const body: any = {
            model: model,
            messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: userPrompt }
            ],
            temperature: 0.2
        };

        if (schema) {
            body.response_format = { type: "json_object" };
            body.messages[0].content += `\n\nOUTPUT MUST BE VALID JSON MATCHING THIS SCHEMA:\n${JSON.stringify(schema, null, 2)}`;
        }

        try {
            const res = await fetch(endpoint, {
                method: "POST",
                headers,
                body: JSON.stringify(body)
            });

            if (!res.ok) {
                const errText = await res.text();
                let errJson;
                try { errJson = JSON.parse(errText); } catch { }

                console.error(`[LLM] API Error ${res.status} at ${endpoint}:`, errText);

                const friendlyMsg = errJson?.error?.message || errText || res.statusText;
                throw new Error(`API Error (${res.status}): ${friendlyMsg}`);
            }

            const data = await res.json();
            const text = data.choices?.[0]?.message?.content || "";
            return { text };
        } catch (e: any) {
            console.error("[LLM] Provider Error:", e);
            throw new Error(`Provider Error: ${e.message}`);
        }
    }
}
</file>

<file path="src/services/logger.ts">
export interface LogEntry {
    id: string;
    type: 'info' | 'warn' | 'error' | 'debug';
    message: string;
    timestamp: string;
}

export class Logger {
    private static instance: Logger;
    private logs: LogEntry[] = [];
    private listeners: ((logs: LogEntry[]) => void)[] = [];

    private constructor() {
        this.patchConsole();
    }

    public static getInstance(): Logger {
        if (!Logger.instance) {
            Logger.instance = new Logger();
        }
        return Logger.instance;
    }

    private patchConsole() {
        const originalError = console.error;
        const originalWarn = console.warn;
        const originalLog = console.log;

        console.error = (...args) => {
            this.addLog('error', args);
            originalError.apply(console, args);
        };

        console.warn = (...args) => {
            this.addLog('warn', args);
            originalWarn.apply(console, args);
        };

        console.log = (...args) => {
            const msg = args.map(a => (typeof a === 'object' ? JSON.stringify(a) : String(a))).join(' ');
            // Capture relevant app logs
            if (msg.startsWith('[MAKER]') || msg.startsWith('[Git]') || msg.startsWith('[LLM]')) {
                this.addLog('info', args);
            }
            originalLog.apply(console, args);
        };
    }

    private addLog(type: LogEntry['type'], args: any[]) {
        const message = args.map(a => (typeof a === 'object' ? JSON.stringify(a) : String(a))).join(' ');
        const entry: LogEntry = {
            id: Math.random().toString(36).substr(2, 9),
            type,
            message,
            timestamp: new Date().toLocaleTimeString()
        };
        this.logs.push(entry);
        this.notify();
    }

    public getLogs(): LogEntry[] {
        return this.logs;
    }

    public subscribe(listener: (logs: LogEntry[]) => void) {
        this.listeners.push(listener);
        // Send current state immediately
        listener(this.logs);
        return () => {
            this.listeners = this.listeners.filter(l => l !== listener);
        };
    }

    private notify() {
        this.listeners.forEach(l => l(this.logs));
    }

    public clear() {
        this.logs = [];
        this.notify();
    }
}
</file>

<file path="src/services/projectService.ts">
import { MockTauriService } from "./tauriBridge";
import { MakerConfig } from "../types";

const CONFIG_FILE = ".maker/config.json";

export class ProjectService {

    static async loadConfig(projectRoot: string): Promise<MakerConfig | null> {
        try {
            const fullPath = `${projectRoot}/${CONFIG_FILE}`;
            const content = await MockTauriService.readFile(fullPath);
            if (!content) return null;
            return JSON.parse(content) as MakerConfig;
        } catch (e) {
            // Silent fail on load is acceptable (new project)
            return null;
        }
    }

    static async saveConfig(projectRoot: string, config: MakerConfig): Promise<boolean> {
        try {
            const fullPath = `${projectRoot}/${CONFIG_FILE}`;

            // Ensure directories exist using FS plugin, not shell
            await this.ensureMakerDirectory(projectRoot);

            await MockTauriService.writeFile(fullPath, JSON.stringify(config, null, 2));
            return true;
        } catch (e) {
            console.error("Failed to save config:", e);
            return false;
        }
    }

    static async ensureMakerDirectory(projectRoot: string) {
        // Use the bridge's mkdir which wraps tauri-plugin-fs
        await MockTauriService.mkdir(`${projectRoot}/.maker`);
        await MockTauriService.mkdir(`${projectRoot}/.maker/worktrees`);
        await MockTauriService.mkdir(`${projectRoot}/.maker/logs`);
    }
}
</file>

<file path="src/services/tauriBridge.ts">
import { open } from '@tauri-apps/plugin-dialog';
import { readDir, readTextFile, writeTextFile, mkdir, watch } from '@tauri-apps/plugin-fs';
import { Command } from '@tauri-apps/plugin-shell';

declare global {
  interface Window {
    __TAURI__?: any;
    __TAURI_INTERNALS__?: any;
  }
}

// Browser Shim for Web Preview Mode
class BrowserShim {
  static async open(): Promise<string | null> {
    return prompt("Enter mock project path (Web Mode):", "/mock/project");
  }
  static async readDir(path: string): Promise<any[]> {
    console.log(`[Shim] readDir: ${path}`);
    return [];
  }
  static async readTextFile(path: string): Promise<string> {
    console.log(`[Shim] readTextFile: ${path}`);
    return "";
  }
}

export interface ProcessHandle {
  pid: number;
  kill: () => Promise<void>;
  write: (data: string) => Promise<void>;
}

export class MockTauriService {
  private static isTauri(): boolean {
    return typeof window !== 'undefined' && (!!window.__TAURI__ || !!window.__TAURI_INTERNALS__);
  }

  static async openDialog(): Promise<string | null> {
    if (this.isTauri()) {
      try {
        const selected = await open({
          directory: true,
          multiple: false,
          title: "Open MAKER Project"
        });
        return selected as string | null;
      } catch (e) {
        console.error("Dialog failed:", e);
        return null;
      }
    }
    return BrowserShim.open();
  }

  static async listFiles(path: string): Promise<any[]> {
    if (this.isTauri()) {
      try {
        return await readDir(path);
      } catch (e) {
        console.error(`Failed to read dir ${path}:`, e);
        return [];
      }
    }
    return BrowserShim.readDir(path);
  }

  static async writeFile(path: string, content: string): Promise<void> {
    if (this.isTauri()) {
      try {
        await writeTextFile(path, content);
        return;
      } catch (e) {
        console.error(`Failed to write file ${path}:`, e);
        throw e;
      }
    }
    console.log(`[Shim] Wrote to ${path}`);
  }

  static async readFile(path: string): Promise<string> {
    if (this.isTauri()) {
      try {
        return await readTextFile(path);
      } catch (e) {
        console.error(`Failed to read file ${path}:`, e);
        throw e;
      }
    }
    return BrowserShim.readTextFile(path);
  }

  static async mkdir(path: string): Promise<void> {
    if (this.isTauri()) {
      try {
        await mkdir(path, { recursive: true });
      } catch (e) {
        console.error(`Failed to mkdir ${path}:`, e);
      }
      return;
    }
    console.log(`[Shim] mkdir -p ${path}`);
  }

  static async executeShell(command: string, args: string[] = [], cwd?: string): Promise<string> {
    return new Promise((resolve, reject) => {
      let output = "";
      this.spawnShell(command, args, cwd,
        (data) => output += data + "\n",
        (code) => {
          if (code === 0) resolve(output);
          else reject(new Error(`Command failed with code ${code}\n${output}`));
        }
      ).catch(reject);
    });
  }

  static async spawnShell(
    command: string,
    args: string[],
    cwd: string | undefined,
    onOutput: (data: string, type: 'stdout' | 'stderr') => void,
    onExit: (code: number) => void
  ): Promise<ProcessHandle> {

    if (cwd && cwd.includes('..')) {
      throw new Error("Security Violation: Shell CWD traversal detected.");
    }

    if (this.isTauri()) {
      try {
        let cmd: Command<string>;

        if (command === 'git') cmd = Command.create('git', args, { cwd });
        else if (command === 'npx') cmd = Command.create('npx', args, { cwd });
        else if (command === 'npm') cmd = Command.create('npm', args, { cwd });
        else {
          console.warn(`Command '${command}' not explicitly allowed. Trying generic...`);
          cmd = Command.create(command, args, { cwd });
        }

        cmd.on('close', (data) => {
          onExit(data.code);
        });

        cmd.on('error', (error) => {
          onOutput(`Spawn Error: ${error}`, 'stderr');
          onExit(1);
        });

        cmd.stdout.on('data', (line) => onOutput(line, 'stdout'));
        cmd.stderr.on('data', (line) => onOutput(line, 'stderr'));

        const child = await cmd.spawn();

        return {
          pid: child.pid,
          kill: async () => {
            try {
              await child.kill();
            } catch (e) {
              console.error("Failed to kill process:", e);
            }
          },
          write: async (data) => {
            try {
              await child.write(data);
            } catch (e) {
              console.error("Failed to write to stdin:", e);
            }
          }
        };

      } catch (e: any) {
        // FIX: Ensure we return a valid string message
        const msg = e.message || (typeof e === 'string' ? e : JSON.stringify(e));
        throw new Error(`Failed to spawn '${command}': ${msg}`);
      }
    }

    // --- BROWSER SHIM ---
    console.log(`[Shim Spawn] ${command} ${args.join(' ')} in ${cwd || '.'}`);

    let interval: any;
    let step = 0;
    const mockPid = Math.floor(Math.random() * 10000);

    if (command === 'npm' && args.includes('install')) {
      interval = setInterval(() => {
        step++;
        if (step === 1) onOutput("npm warn deprecated ...", 'stderr');
        if (step === 2) onOutput("reify:fsevents: \u001b[32mhttp fetch\u001b[0m GET 200 ...", 'stdout');
        if (step === 3) onOutput("reify:rxjs: \u001b[32mhttp fetch\u001b[0m GET 200 ...", 'stdout');
        if (step === 4) onOutput("added 142 packages in 2s", 'stdout');
        if (step >= 5) {
          clearInterval(interval);
          onExit(0);
        }
      }, 800);
    } else {
      setTimeout(() => {
        if (command === 'ls') onOutput("src  package.json  tsconfig.json", 'stdout');
        else if (command === 'git' && args.includes('status')) onOutput("On branch main\nYour branch is up to date.", 'stdout');
        else onOutput(`[Mock] Executed ${command}`, 'stdout');
        onExit(0);
      }, 500);
    }

    return {
      pid: mockPid,
      kill: async () => {
        if (interval) clearInterval(interval);
        onOutput("^C [Process Killed]", 'stderr');
        onExit(130); // SIGINT
      },
      write: async () => { }
    };
  }

  static async watchPath(path: string, callback: (event: any) => void): Promise<() => void> {
    if (this.isTauri()) {
      try {
        const unwatch = await watch(path, (event) => {
          callback(event);
        }, { recursive: true });
        return unwatch;
      } catch (e) {
        console.warn("Failed to start watcher:", e);
        return () => { };
      }
    }
    return () => { };
  }
}
</file>

<file path="src/services/virtualFileSystem.ts">
import { MockTauriService } from './tauriBridge';

export class VirtualFileSystem {
    private static instance: VirtualFileSystem;
    private projectRoot: string | null = null;

    private fileCache: Map<string, string> = new Map();
    private listeners: (() => void)[] = [];

    private unwatchFn: (() => void) | null = null;
    private debounceTimer: any = null;

    private constructor() {
        this.fileCache.set('/package.json', '{\n  "name": "maker-project-demo",\n  "version": "1.0.0"\n}');
        this.fileCache.set('/src/index.ts', '// Entry point\nconsole.log("Hello MAKER");');
    }

    public static getInstance(): VirtualFileSystem {
        if (!VirtualFileSystem.instance) {
            VirtualFileSystem.instance = new VirtualFileSystem();
        }
        return VirtualFileSystem.instance;
    }

    async setRoot(path: string) {
        this.projectRoot = path;
        this.fileCache.clear();

        if (this.unwatchFn) {
            this.unwatchFn();
            this.unwatchFn = null;
        }

        this.unwatchFn = await MockTauriService.watchPath(path, (event) => {
            this.handleDiskChange(event);
        });

        this.notify();
    }

    private handleDiskChange(event: any) {
        if (this.debounceTimer) clearTimeout(this.debounceTimer);
        this.debounceTimer = setTimeout(() => {
            console.log("[VFS] Disk change detected:", event);
            this.notify();
        }, 300);
    }

    getRoot(): string | null {
        return this.projectRoot;
    }

    subscribe(listener: () => void) {
        this.listeners.push(listener);
        return () => {
            this.listeners = this.listeners.filter(l => l !== listener);
        };
    }

    private notify() {
        this.listeners.forEach(l => l());
    }

    async writeFile(path: string, content: string) {
        const cleanPath = this.normalizePath(path);
        this.fileCache.set(cleanPath, content);

        if (this.projectRoot) {
            const fullPath = `${this.projectRoot}${cleanPath}`;
            await MockTauriService.writeFile(fullPath, content);
        }
        this.notify();
    }

    async readFile(path: string): Promise<string | null> {
        const cleanPath = this.normalizePath(path);

        if (this.projectRoot) {
            try {
                const fullPath = `${this.projectRoot}${cleanPath}`;
                const content = await MockTauriService.readFile(fullPath);
                this.fileCache.set(cleanPath, content);
                return content;
            } catch (e) {
                return null;
            }
        }

        if (this.fileCache.has(cleanPath)) {
            return this.fileCache.get(cleanPath) || null;
        }
        return null;
    }

    async getDirectoryTree(): Promise<any[]> {
        if (!this.projectRoot) return this.buildTreeFromCache();

        try {
            const entries = await MockTauriService.listFiles(this.projectRoot);
            const nodes = entries.map((entry: any) => ({
                name: entry.name,
                path: `/${entry.name}`,
                isDirectory: entry.isDirectory,
                children: entry.isDirectory ? [] : undefined
            }));

            return nodes.sort((a: any, b: any) => {
                if (a.isDirectory === b.isDirectory) return a.name.localeCompare(b.name);
                return a.isDirectory ? -1 : 1;
            });
        } catch (e) {
            console.error("VFS: Failed to scan root", e);
            return [];
        }
    }

    private normalizePath(path: string): string {
        // 1. Convert backslashes
        let clean = path.replace(/\\/g, '/');

        // 2. Remove leading ./
        if (clean.startsWith('./')) clean = clean.substring(2);

        // 3. SECURITY: Prevent directory traversal
        // We do not allow '..' segments that could escape the project root
        if (clean.includes('../') || clean.endsWith('/..') || clean === '..') {
            throw new Error(`Security Violation: Path traversal detected in '${path}'. Access denied.`);
        }

        // 4. Ensure absolute path relative to VFS root
        return clean.startsWith('/') ? clean : '/' + clean;
    }

    private buildTreeFromCache(): any[] {
        const root: any[] = [];
        const paths = Array.from(this.fileCache.keys()).sort();

        paths.forEach(path => {
            const parts = path.split('/').filter(p => p);
            let currentLevel = root;

            parts.forEach((part, index) => {
                const isFile = index === parts.length - 1;
                const existing = currentLevel.find(n => n.name === part);

                if (existing) {
                    if (!isFile) currentLevel = existing.children;
                } else {
                    const newNode = {
                        name: part,
                        path: '/' + parts.slice(0, index + 1).join('/'),
                        isDirectory: !isFile,
                        children: isFile ? undefined : []
                    };
                    currentLevel.push(newNode);
                    if (!isFile) currentLevel = newNode.children;
                }
            });
        });
        return root;
    }
}
</file>

<file path="src/types.ts">
// MAKER Framework Types

export enum AgentStatus {
    IDLE = 'IDLE',
    QUEUED = 'QUEUED',
    PLANNING = 'PLANNING',
    ANALYZING = 'ANALYZING',
    THINKING = 'THINKING',
    VOTING = 'VOTING',
    PASSED = 'PASSED',
    FAILED = 'FAILED',
    EXECUTING = 'EXECUTING',
    SKIPPED_VOTE = 'FAST_TRACK',
    CHECKPOINTING = 'CHECKPOINTING',
    MERGING = 'MERGING',
    CONFLICT = 'CONFLICT'
}

export interface AgentCandidate {
    id: string;
    agentName: string;
    content: string;
    voteCount: number;
    reasoning: string;
}

export interface ToolDefinition {
    id: string;
    name: string;
    description: string;
    command: string; // e.g. "npm run test -- {{file}}"
    requiresApproval: boolean;
}

export interface ToolCall {
    toolName: string;
    arguments: Record<string, string>;
}

export interface SubTask {
    id: string;
    description: string;
    fileTarget: string; // If tool, this might be the output log file
    status: AgentStatus;
    attempts: number;
    votes: number;
    riskScore: number;
    riskReason?: string;
    logs: string[];

    // Tool Integration
    toolCall?: ToolCall;

    // Voting
    candidates?: AgentCandidate[];

    // Parallelism & Git
    dependencies: string[];
    gitBranch?: string;
    worktreePath?: string;

    assignedAgentId?: string;
}

export interface TaskStatus {
    taskId: string;
    originalPrompt: string;
    decomposition: SubTask[];
    totalSteps: number;
    completedSteps: number;
    errorCount: number;
    activeWorkers: number;
    conflicts: MergeConflict[];
    isPlanning: boolean;
}

export interface FileNode {
    id: string;
    name: string;
    type: 'file' | 'dir';
    children?: FileNode[];
    path: string;
}

export interface VoteResult {
    winner: string | null;
    voteCount: number;
    totalVotes: number;
    isConsensus: boolean;
    candidates: AgentCandidate[];
}

export interface AgentProfile {
    id: string;
    name: string;
    role: 'Architect' | 'Developer' | 'QA' | 'Security';
    riskTolerance: number;
    color: string;
    model: string;
}

export type LLMProviderType = 'gemini' | 'openai';

export interface MakerConfig {
    // LLM Configuration
    llmProvider: LLMProviderType;
    geminiApiKey?: string;
    openaiBaseUrl?: string;
    openaiApiKey?: string;
    openaiModel?: string;

    // Engine Settings
    riskThreshold: number;
    maxAgents: number;
    autoFixLinter: boolean;
    useGitWorktrees: boolean;
    maxParallelism: number;

    // Agent Roster
    agentProfiles: AgentProfile[];

    // Tool Registry
    tools: ToolDefinition[];
}

export interface GitLogEntry {
    hash: string;
    message: string;
    author: string;
    date: string;
    stats?: {
        additions: number;
        deletions: number;
    };
    tags?: string[];
}

export interface Worktree {
    id: string;
    path: string;
    branch: string;
    status: 'active' | 'merging' | 'stale';
    assignedAgentId?: string;
    lastActivity: string;
}

export interface MergeConflict {
    id: string;
    filePath: string;
    branchA: string;
    branchB: string;
    contentA: string;
    contentB: string;
    aiResolutionProposal?: string;
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "experimentalDecorators": true,
    "useDefineForClassFields": false,
    "module": "ESNext",
    "lib": [
      "ES2022",
      "DOM",
      "DOM.Iterable"
    ],
    "skipLibCheck": true,
    "types": [
      "node"
    ],
    "moduleResolution": "bundler",
    "isolatedModules": true,
    "moduleDetection": "force",
    "allowJs": true,
    "jsx": "react-jsx",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "allowImportingTsExtensions": true,
    "noEmit": true
  }
}
</file>

<file path="vite.config.ts">
import path from 'path';
import { defineConfig, loadEnv } from 'vite';
import react from '@vitejs/plugin-react';

export default defineConfig(({ mode }) => {
    const env = loadEnv(mode, '.', '');
    return {
      server: {
        port: 3000,
        host: '0.0.0.0',
      },
      plugins: [react()],
      define: {
        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY)
      },
      resolve: {
        alias: {
          '@': path.resolve(__dirname, '.'),
        }
      }
    };
});
</file>

<file path="src-tauri/capabilities/default.json">
{
  "identifier": "default",
  "description": "Capability for the main window",
  "windows": [
    "main"
  ],
  "permissions": [
    "core:default",
    "shell:allow-open",
    "dialog:default",
    "fs:default",
    "fs:allow-watch",
    "fs:allow-read-text-file",
    "fs:allow-write-text-file",
    "fs:allow-read-dir",
    "fs:allow-mkdir",
    "fs:allow-exists",
    {
      "identifier": "fs:scope",
      "allow": [
        "$HOME/**",
        "**",
        "C:\\**",
        "D:\\**",
        "E:\\**",
        "F:\\**",
        "/Users/**",
        "/home/**"
      ]
    },
    {
      "identifier": "shell:allow-execute",
      "allow": [
        {
          "name": "git",
          "cmd": "git",
          "args": true
        },
        {
          "name": "npx",
          "cmd": "npx",
          "args": true
        },
        {
          "name": "npm",
          "cmd": "npm",
          "args": true
        },
        {
          "name": "node",
          "cmd": "node",
          "args": true
        },
        {
          "name": "cargo",
          "cmd": "cargo",
          "args": true
        },
        {
          "name": "python",
          "cmd": "python",
          "args": true
        },
        {
          "name": "python3",
          "cmd": "python3",
          "args": true
        },
        {
          "name": "pip",
          "cmd": "pip",
          "args": true
        },
        {
          "name": "ls",
          "cmd": "ls",
          "args": true
        },
        {
          "name": "echo",
          "cmd": "echo",
          "args": true
        },
        {
          "name": "mkdir",
          "cmd": "mkdir",
          "args": true
        }
      ]
    },
    {
      "identifier": "shell:allow-spawn",
      "allow": [
        {
          "name": "git",
          "cmd": "git",
          "args": true
        },
        {
          "name": "npx",
          "cmd": "npx",
          "args": true
        },
        {
          "name": "npm",
          "cmd": "npm",
          "args": true
        },
        {
          "name": "node",
          "cmd": "node",
          "args": true
        },
        {
          "name": "cargo",
          "cmd": "cargo",
          "args": true
        },
        {
          "name": "python",
          "cmd": "python",
          "args": true
        },
        {
          "name": "python3",
          "cmd": "python3",
          "args": true
        },
        {
          "name": "pip",
          "cmd": "pip",
          "args": true
        },
        {
          "name": "ls",
          "cmd": "ls",
          "args": true
        },
        {
          "name": "echo",
          "cmd": "echo",
          "args": true
        },
        {
          "name": "mkdir",
          "cmd": "mkdir",
          "args": true
        }
      ]
    }
  ]
}
</file>

<file path="src-tauri/tauri.conf.json">
{
    "productName": "MakerCode",
    "version": "0.1.0",
    "identifier": "com.makercode.dev",
    "build": {
        "beforeDevCommand": "npm run dev",
        "devUrl": "http://localhost:3000",
        "beforeBuildCommand": "npm run build",
        "frontendDist": "../dist"
    },
    "app": {
        "windows": [
            {
                "label": "main",
                "title": "MakerCode",
                "width": 1200,
                "height": 800,
                "resizable": true,
                "fullscreen": false
            }
        ],
        "security": {
            "csp": null,
            "capabilities": [
                "default"
            ]
        }
    },
    "bundle": {
        "active": true,
        "targets": "all",
        "icon": [
            "icons/32x32.png",
            "icons/128x128.png",
            "icons/128x128@2x.png",
            "icons/icon.icns",
            "icons/icon.ico"
        ]
    },
    "plugins": {
        "shell": {
            "open": true
        }
    }
}
</file>

<file path="src/components/VersionControl.tsx">
import React, { useState, useEffect } from 'react';
import { GitCommit, GitBranch, AlertTriangle, Layers, RefreshCw, Cloud, ArrowUp, ArrowDown, Check, Loader2, Save } from 'lucide-react';
import { GitHistory } from './GitHistory';
import { MergeConflictResolver } from './MergeConflictResolver';
import { GitService, GitStatus } from '../services/gitService';
import { Worktree, MergeConflict } from '../types';

interface VersionControlProps {
    addToast?: (type: 'success' | 'error' | 'info', message: string) => void;
}

export const VersionControl: React.FC<VersionControlProps> = ({ addToast }) => {
    const [view, setView] = useState<'timeline' | 'worktrees' | 'conflicts'>('timeline');
    const [worktrees, setWorktrees] = useState<Worktree[]>([]);
    const [conflicts, setConflicts] = useState<MergeConflict[]>([]);
    const [status, setStatus] = useState<GitStatus | null>(null);
    const [isSyncing, setIsSyncing] = useState(false);

    const [commitMsg, setCommitMsg] = useState('');
    const [isCommitting, setIsCommitting] = useState(false);

    const loadData = async () => {
        const git = GitService.getInstance();
        const [wts, cfs, st] = await Promise.all([
            git.listWorktrees(),
            git.getConflicts(),
            git.getStatus()
        ]);
        setWorktrees(wts);
        setConflicts(cfs);
        setStatus(st);
    };

    useEffect(() => {
        loadData();
        const interval = setInterval(loadData, 5000);
        return () => clearInterval(interval);
    }, []);

    const handleSync = async () => {
        setIsSyncing(true);
        try {
            await GitService.getInstance().syncRemote();
            await loadData();
            addToast?.('success', 'Sync completed successfully.');
        } catch (e: any) {
            console.error("Sync failed", e);
            addToast?.('error', `Sync Failed: ${e.message}`);
        } finally {
            setIsSyncing(false);
        }
    };

    const handleCommit = async () => {
        if (!commitMsg.trim()) return;
        setIsCommitting(true);
        try {
            await GitService.getInstance().commitAll(commitMsg);
            setCommitMsg('');
            await loadData();
            addToast?.('success', 'Changes committed.');
        } catch (e: any) {
            console.error("Commit failed", e);
            addToast?.('error', `Commit Failed: ${e.message}`);
        } finally {
            setIsCommitting(false);
        }
    };

    const handleResolveConflict = async (id: string, content: string) => {
        const git = GitService.getInstance();
        await git.resolveConflict(id, content);
        setConflicts(prev => prev.filter(c => c.id !== id));
        addToast?.('success', 'Conflict resolved.');
    };

    return (
        <div className="flex flex-col h-full bg-gray-950">
            {/* Status Bar / External Integration */}
            <div className="h-12 border-b border-gray-800 bg-gray-900 flex items-center justify-between px-4">
                <div className="flex items-center gap-4">
                    <div className="flex items-center gap-2">
                        <div className={`w-2 h-2 rounded-full ${status?.isDirty ? 'bg-yellow-500' : 'bg-green-500'}`}></div>
                        <span className="text-xs font-mono text-gray-300">
                            {status?.isDirty ? 'Unsaved Changes' : 'Clean'}
                        </span>
                    </div>
                    {status?.currentBranch && (
                        <div className="flex items-center gap-1 text-xs text-gray-400 bg-gray-950 px-2 py-1 rounded-sm border border-gray-800">
                            <GitBranch size={10} />
                            {status.currentBranch}
                        </div>
                    )}
                </div>

                <div className="flex items-center gap-2">
                    {status?.hasRemote ? (
                        <button
                            onClick={handleSync}
                            disabled={isSyncing}
                            className="flex items-center gap-2 px-3 py-1.5 bg-indigo-600 hover:bg-indigo-500 text-white text-xs font-medium rounded-sm transition-colors disabled:opacity-50"
                        >
                            {isSyncing ? <Loader2 size={12} className="animate-spin" /> : <Cloud size={12} />}
                            Sync
                            {(status.behind > 0 || status.ahead > 0) && (
                                <span className="flex items-center gap-1 ml-1 text-[10px] bg-indigo-700 px-1.5 rounded-full">
                                    {status.behind > 0 && <span className="flex items-center"><ArrowDown size={8} />{status.behind}</span>}
                                    {status.ahead > 0 && <span className="flex items-center"><ArrowUp size={8} />{status.ahead}</span>}
                                </span>
                            )}
                        </button>
                    ) : (
                        <span className="text-xs text-gray-600 italic px-2">No Remote Configured</span>
                    )}
                </div>
            </div>

            {/* Dirty State Commit Box */}
            {status?.isDirty && (
                <div className="p-3 bg-yellow-900/10 border-b border-yellow-500/20 flex gap-2 items-center animate-in slide-in-from-top">
                    <input
                        value={commitMsg}
                        onChange={(e) => setCommitMsg(e.target.value)}
                        placeholder="Describe your changes..."
                        className="flex-1 bg-gray-900 border border-gray-700 rounded-sm px-3 py-1.5 text-xs text-white focus:border-yellow-500 outline-hidden"
                        onKeyDown={(e) => e.key === 'Enter' && handleCommit()}
                    />
                    <button
                        onClick={handleCommit}
                        disabled={isCommitting || !commitMsg.trim()}
                        className="bg-yellow-600 hover:bg-yellow-500 text-white px-4 py-1.5 rounded-sm text-xs font-medium flex items-center gap-2 disabled:opacity-50"
                    >
                        {isCommitting ? <Loader2 size={12} className="animate-spin" /> : <Save size={12} />}
                        Commit
                    </button>
                </div>
            )}

            {/* Sub-Navigation */}
            <div className="h-10 border-b border-gray-800 flex items-center px-4 gap-6 bg-gray-900/50">
                <button
                    onClick={() => setView('timeline')}
                    className={`text-xs flex items-center gap-2 h-full border-b-2 transition-colors ${view === 'timeline' ? 'border-indigo-500 text-indigo-400' : 'border-transparent text-gray-500 hover:text-gray-300'}`}
                >
                    <GitCommit size={14} /> Commit Timeline
                </button>
                <button
                    onClick={() => setView('worktrees')}
                    className={`text-xs flex items-center gap-2 h-full border-b-2 transition-colors ${view === 'worktrees' ? 'border-orange-500 text-orange-400' : 'border-transparent text-gray-500 hover:text-gray-300'}`}
                >
                    <Layers size={14} /> Active Worktrees
                    <span className="bg-gray-800 px-1.5 py-0.5 rounded-full text-[10px]">{worktrees.length}</span>
                </button>
                <button
                    onClick={() => setView('conflicts')}
                    className={`text-xs flex items-center gap-2 h-full border-b-2 transition-colors ${view === 'conflicts' ? 'border-red-500 text-red-400' : 'border-transparent text-gray-500 hover:text-gray-300'}`}
                >
                    <AlertTriangle size={14} /> Conflict Resolver
                    {conflicts.length > 0 && (
                        <span className="bg-red-500/20 text-red-400 px-1.5 py-0.5 rounded-full text-[10px]">{conflicts.length}</span>
                    )}
                </button>
            </div>

            {/* Content Area */}
            <div className="flex-1 overflow-hidden">
                {view === 'timeline' && <GitHistory />}

                {view === 'worktrees' && (
                    <div className="p-8">
                        <div className="max-w-4xl mx-auto grid grid-cols-1 md:grid-cols-2 gap-4">
                            {worktrees.length === 0 ? (
                                <div className="col-span-2 text-center text-gray-500 py-12">
                                    <Layers size={48} className="mx-auto mb-4 opacity-20" />
                                    <p>No active worktrees.</p>
                                    <p className="text-xs mt-1">Agents create isolated worktrees automatically during execution.</p>
                                </div>
                            ) : (
                                worktrees.map(wt => (
                                    <div key={wt.id} className="bg-gray-900 border border-gray-800 p-4 rounded-lg hover:border-orange-500/30 transition-colors">
                                        <div className="flex justify-between items-start mb-3">
                                            <div className="flex items-center gap-2 text-orange-400 text-sm font-semibold">
                                                <GitBranch size={16} />
                                                {wt.branch}
                                            </div>
                                            <span className="text-[10px] bg-green-900/30 text-green-400 px-2 py-0.5 rounded-sm uppercase">
                                                {wt.status}
                                            </span>
                                        </div>
                                        <div className="space-y-2 text-xs text-gray-500 font-mono">
                                            <div className="flex items-center gap-2">
                                                <Layers size={12} />
                                                <span className="truncate">{wt.path}</span>
                                            </div>
                                            <div className="flex items-center gap-2">
                                                <RefreshCw size={12} />
                                                <span>Active: {wt.lastActivity}</span>
                                            </div>
                                        </div>
                                    </div>
                                ))
                            )}
                        </div>
                    </div>
                )}

                {view === 'conflicts' && (
                    <MergeConflictResolver conflicts={conflicts} onResolve={handleResolveConflict} />
                )}
            </div>
        </div>
    );
};
</file>

<file path="src/services/gitService.ts">
import { MockTauriService } from "./tauriBridge";
import { GitLogEntry, Worktree, MergeConflict } from "../types";

export interface GitStatus {
    isRepo: boolean;
    currentBranch: string;
    isDirty: boolean;
    hasRemote: boolean;
    behind: number;
    ahead: number;
}

export class GitService {
    private static instance: GitService;

    public static getInstance(): GitService {
        if (!GitService.instance) {
            GitService.instance = new GitService();
        }
        return GitService.instance;
    }

    async getStatus(): Promise<GitStatus> {
        try {
            try {
                await MockTauriService.executeShell('git', ['rev-parse', '--is-inside-work-tree']);
            } catch {
                return { isRepo: false, currentBranch: '', isDirty: false, hasRemote: false, behind: 0, ahead: 0 };
            }

            const branch = (await MockTauriService.executeShell('git', ['branch', '--show-current'])).trim();
            const statusOutput = await MockTauriService.executeShell('git', ['status', '--porcelain']);
            const isDirty = statusOutput.trim().length > 0;

            let hasRemote = false;
            try {
                const remote = await MockTauriService.executeShell('git', ['remote']);
                hasRemote = remote.trim().length > 0;
            } catch { }

            let ahead = 0;
            let behind = 0;
            if (hasRemote) {
                try {
                    await MockTauriService.executeShell('git', ['fetch', '--dry-run']);
                    const count = await MockTauriService.executeShell('git', ['rev-list', '--left-right', '--count', `${branch}...origin/${branch}`]);
                    const parts = count.trim().split(/\s+/);
                    if (parts.length === 2) {
                        ahead = parseInt(parts[0]);
                        behind = parseInt(parts[1]);
                    }
                } catch { }
            }

            return { isRepo: true, currentBranch: branch, isDirty, hasRemote, behind, ahead };
        } catch (e) {
            console.error("[Git] Status check failed", e);
            return { isRepo: false, currentBranch: '', isDirty: false, hasRemote: false, behind: 0, ahead: 0 };
        }
    }

    async initRepo(): Promise<boolean> {
        try {
            await MockTauriService.executeShell('git', ['init']);
            await this.ensureGitIgnore(); // Ensure we don't track garbage
            await MockTauriService.executeShell('git', ['branch', '-M', 'main']);
            await MockTauriService.executeShell('git', ['add', '.']);
            await MockTauriService.executeShell('git', ['commit', '--allow-empty', '-m', 'Initial commit by MakerCode']);
            return true;
        } catch (e) {
            console.error("Failed to init repo", e);
            return false;
        }
    }

    async ensureGitIgnore() {
        // Basic ignore list for MakerCode projects
        const ignoreContent = `
node_modules
dist
src-tauri/target
.maker/worktrees
.DS_Store
.env
        `.trim();

        // Check if exists, if not write it
        try {
            await MockTauriService.readFile('.gitignore');
        } catch {
            console.log("[Git] Creating default .gitignore");
            await MockTauriService.writeFile('.gitignore', ignoreContent);
        }
    }

    async commitAll(message: string): Promise<void> {
        try {
            // Ensure ignore file exists to prevent adding 'target' folder issues
            await this.ensureGitIgnore();

            // Use -A (all) instead of . to handle deletions/moves better and usually avoids the ignore warning
            await MockTauriService.executeShell('git', ['add', '-A']);
            await MockTauriService.executeShell('git', ['commit', '-m', message]);
        } catch (e: any) {
            // Fallback: If add -A failed, try adding just the current directory non-recursively or handle the error
            console.error("Commit failed", e);
            throw new Error(`Commit failed: ${e.message || e}`);
        }
    }

    async syncRemote(): Promise<string> {
        try {
            const pullRes = await MockTauriService.executeShell('git', ['pull', '--rebase']);
            const pushRes = await MockTauriService.executeShell('git', ['push']);
            return `Sync Complete.\n${pullRes}\n${pushRes}`;
        } catch (e: any) {
            throw new Error(`Sync failed: ${e.message || e}`);
        }
    }

    async createWorktree(taskId: string, stepId: string): Promise<{ branch: string, path: string }> {
        const branchName = `maker/${taskId}/step-${stepId}`;
        const worktreeRelPath = `.maker/worktrees/${stepId}`;

        console.log(`[Git] Creating worktree for ${branchName}`);

        try {
            try {
                await MockTauriService.executeShell('git', ['rev-parse', '--verify', branchName]);
            } catch {
                await MockTauriService.executeShell('git', ['branch', branchName, 'HEAD']);
            }

            await MockTauriService.executeShell('git', ['worktree', 'add', '--force', worktreeRelPath, branchName]);

            return { branch: branchName, path: worktreeRelPath };
        } catch (error) {
            console.error("Failed to create worktree:", error);
            throw new Error(`Git Worktree creation failed: ${error}`);
        }
    }

    async cleanupWorktree(path: string, branchName: string) {
        console.log(`[Git] Cleaning up worktree ${path}`);
        try {
            await MockTauriService.executeShell('git', ['worktree', 'remove', path, '--force']);
            await MockTauriService.executeShell('git', ['branch', '-D', branchName]);
        } catch (e) {
            console.warn(`Failed to cleanup worktree ${path}:`, e);
        }
    }

    async listWorktrees(): Promise<Worktree[]> {
        try {
            const output = await MockTauriService.executeShell('git', ['worktree', 'list', '--porcelain']);
            const lines = output.split('\n');
            const worktrees: Worktree[] = [];

            let currentWt: Partial<Worktree> = {};

            for (const line of lines) {
                if (line.startsWith('worktree ')) {
                    if (currentWt.path && currentWt.branch) {
                        worktrees.push(currentWt as Worktree);
                    }
                    currentWt = {
                        path: line.substring(9),
                        id: Math.random().toString(36).substr(2, 5),
                        status: 'active',
                        lastActivity: 'Active'
                    };
                } else if (line.startsWith('branch ')) {
                    currentWt.branch = line.substring(11).replace('refs/heads/', '');
                }
            }
            if (currentWt.path && currentWt.branch) {
                worktrees.push(currentWt as Worktree);
            }

            return worktrees;
        } catch (e) {
            return [];
        }
    }

    async createCheckpoint(message: string, files: string[] = ['.']) {
        console.log(`[Git] Checkpointing: ${message}`);
        await MockTauriService.executeShell('git', ['add', ...files]);
        await MockTauriService.executeShell('git', ['commit', '-m', `MAKER: ${message}`]);
    }

    async mergeWorktreeToMain(branchName: string, message: string): Promise<boolean> {
        console.log(`[Git] Merging ${branchName} into main...`);
        try {
            await MockTauriService.executeShell('git', ['merge', '--squash', branchName]);
            await MockTauriService.executeShell('git', ['commit', '-m', `MAKER Merge: ${message}`]);
            return true;
        } catch (e) {
            console.error("Merge failed (likely conflict):", e);
            const status = await MockTauriService.executeShell('git', ['status']);
            if (status.includes('Unmerged paths')) {
                return false;
            }
            throw e;
        }
    }

    async getConflicts(): Promise<MergeConflict[]> {
        try {
            const output = await MockTauriService.executeShell('git', ['diff', '--name-only', '--diff-filter=U']);
            const files = output.split('\n').filter(line => line.trim() !== '');

            if (files.length === 0) return [];

            const conflicts: MergeConflict[] = [];

            for (const filePath of files) {
                let contentA = "";
                try {
                    contentA = await MockTauriService.executeShell('git', ['show', `:2:${filePath}`]);
                } catch { contentA = "(Deleted in HEAD)"; }

                let contentB = "";
                try {
                    contentB = await MockTauriService.executeShell('git', ['show', `:3:${filePath}`]);
                } catch { contentB = "(Deleted in Incoming)"; }

                const proposal = `// MAKER Semantic Merge Proposal\n// Resolving conflict in ${filePath}\n\n${contentB}`;

                conflicts.push({
                    id: filePath,
                    filePath,
                    branchA: 'Current (HEAD)',
                    branchB: 'Agent Branch',
                    contentA,
                    contentB,
                    aiResolutionProposal: proposal
                });
            }

            return conflicts;
        } catch (error) {
            return [];
        }
    }

    async resolveConflict(conflictId: string, resolutionContent: string): Promise<void> {
        console.log(`[Git] Resolving conflict for ${conflictId}`);
        await MockTauriService.writeFile(conflictId, resolutionContent);
        await MockTauriService.executeShell('git', ['add', conflictId]);
    }

    async getHistory(): Promise<GitLogEntry[]> {
        try {
            const output = await MockTauriService.executeShell('git', ['log', '-n', '20', '--pretty=format:%h|%an|%ar|%s']);
            if (!output) return [];

            return output.split('\n').filter(l => l).map(line => {
                const [hash, author, date, message] = line.split('|');
                return { hash, author, date, message, stats: { additions: 0, deletions: 0 } };
            });
        } catch {
            return [];
        }
    }
}
</file>

<file path="src/services/makerService.ts">
import { Type } from "@google/genai";
import { SubTask, AgentStatus, TaskStatus, MakerConfig, AgentProfile } from "../types";
import { MockTauriService } from "./tauriBridge";
import { GitService } from "./gitService";
import { VirtualFileSystem } from "./virtualFileSystem";
import { LLMFactory, LLMClient } from "./llm";
import { ContextManager } from "./contextManager";
import { LanguageRegistry } from "./languages/registry";
import { DecompositionService } from "./engine/decompositionService";
import { VotingService } from "./engine/votingService";
import { ToolService } from "./toolService";

export class MakerEngine {
    private llm: LLMClient | null = null;
    private git: GitService;
    private contextManager: ContextManager;
    private langRegistry: LanguageRegistry;
    private toolService: ToolService;

    private decomposer!: DecompositionService;
    private voter!: VotingService;

    private config: MakerConfig = {
        llmProvider: 'gemini',
        geminiApiKey: "",
        openaiBaseUrl: "https://api.openai.com/v1",
        openaiModel: "gpt-4o",
        riskThreshold: 0.6,
        maxAgents: 3,
        autoFixLinter: true,
        useGitWorktrees: false,
        maxParallelism: 1,
        agentProfiles: [
            { id: "1", name: "Atlas", role: "Architect", riskTolerance: 0.3, color: "text-purple-400", model: "gemini-2.0-flash" },
            { id: "2", name: "Bolt", role: "Developer", riskTolerance: 0.7, color: "text-blue-400", model: "gemini-2.0-flash" },
            { id: "3", name: "Cipher", role: "Security", riskTolerance: 0.1, color: "text-red-400", model: "gemini-2.0-flash" },
            { id: "4", name: "Dash", role: "QA", riskTolerance: 0.4, color: "text-green-400", model: "gemini-2.0-flash" }
        ],
        tools: []
    };

    private state: TaskStatus = {
        taskId: "init",
        originalPrompt: "",
        decomposition: [],
        totalSteps: 0,
        completedSteps: 0,
        errorCount: 0,
        activeWorkers: 0,
        conflicts: [],
        isPlanning: false
    };

    private listeners: ((state: TaskStatus) => void)[] = [];
    private isRunning: boolean = false;

    constructor() {
        this.git = GitService.getInstance();
        this.contextManager = ContextManager.getInstance();
        this.langRegistry = LanguageRegistry.getInstance();
        this.toolService = ToolService.getInstance();

        const savedKey = typeof localStorage !== 'undefined' ? localStorage.getItem('MAKER_API_KEY') : "";
        if (savedKey) {
            this.config.geminiApiKey = savedKey;
            this.llm = LLMFactory.create(this.config);
        }

        this.initSubServices();
    }

    private initSubServices() {
        this.decomposer = new DecompositionService(this.llm, this.contextManager);
        this.voter = new VotingService(this.llm);
    }

    subscribe(listener: (state: TaskStatus) => void) {
        this.listeners.push(listener);
        return () => {
            this.listeners = this.listeners.filter(l => l !== listener);
        };
    }

    updateConfig(newConfig: Partial<MakerConfig>) {
        console.log("[MakerEngine] updateConfig called. Keys present:",
            newConfig.openaiApiKey ? "Yes (OpenAI)" : "No",
            newConfig.geminiApiKey ? "Yes (Gemini)" : "No"
        );

        const prevKey = this.config.geminiApiKey;
        const prevProvider = this.config.llmProvider;
        const prevUrl = this.config.openaiBaseUrl;
        const prevOpenAiKey = this.config.openaiApiKey;

        this.config = { ...this.config, ...newConfig };

        if (
            newConfig.geminiApiKey !== prevKey ||
            newConfig.llmProvider !== prevProvider ||
            newConfig.openaiBaseUrl !== prevUrl ||
            newConfig.openaiApiKey !== prevOpenAiKey
        ) {
            console.log("[MAKER] Re-initializing LLM Client...");
            this.llm = LLMFactory.create(this.config);
            this.initSubServices();

            if (typeof localStorage !== 'undefined') {
                if (this.config.geminiApiKey) localStorage.setItem('MAKER_API_KEY', this.config.geminiApiKey);
            }
        }
        this.notify();
    }

    private notify() {
        this.listeners.forEach(l => l(this.state));
    }

    async startTask(prompt: string) {
        this.state = {
            taskId: Date.now().toString(),
            originalPrompt: prompt,
            decomposition: [],
            totalSteps: 0,
            completedSteps: 0,
            errorCount: 0,
            activeWorkers: 0,
            conflicts: [],
            isPlanning: true
        };
        this.notify();

        try {
            const status = await this.git.getStatus();
            if (!status.isRepo) await this.git.initRepo();
            if (status.isDirty) await this.git.createCheckpoint("Auto-Checkpoint before Task Start");

            const decomposition = await this.decomposer.decompose(prompt, this.config.tools || []);

            this.state.decomposition = decomposition.map(d => ({
                id: d.id || Math.random().toString(36).substring(2, 10),
                description: d.description || "Unspecified Task",
                fileTarget: d.fileTarget || "./",
                status: AgentStatus.PLANNING,
                attempts: 0,
                votes: 0,
                riskScore: 0,
                logs: [],
                dependencies: d.dependencies || [],
                riskReason: d.riskReason,
                candidates: [],
                toolCall: d.toolCall
            }));
            this.state.totalSteps = this.state.decomposition.length;
            this.notify();

        } catch (e: any) {
            // LOGGING FIX: Send to System Logs
            console.error("[MakerEngine] Start Task Failed:", e);

            this.state.errorCount++;
            this.state.decomposition = [{
                id: "error",
                description: "Decomposition Failed: " + e.message,
                fileTarget: "error.log",
                status: AgentStatus.FAILED,
                attempts: 1,
                votes: 0,
                riskScore: 1,
                logs: [e.message],
                dependencies: []
            }];
            this.notify();
        }
    }

    async executePlan() {
        this.state.isPlanning = false;
        this.state.decomposition = this.state.decomposition.map(s => ({ ...s, status: AgentStatus.QUEUED }));
        this.notify();
        this.isRunning = true;
        this.processQueue();
    }

    private async processQueue() {
        if (!this.isRunning) return;

        const allComplete = this.state.decomposition.every(s => s.status === AgentStatus.PASSED || s.status === AgentStatus.FAILED);
        if (allComplete) {
            this.isRunning = false;
            return;
        }

        const completedIds = new Set(this.state.decomposition.filter(s => s.status === AgentStatus.PASSED).map(s => s.id));
        const runnableIndices = this.state.decomposition
            .map((step, index) => ({ step, index }))
            .filter(({ step }) => step.status === AgentStatus.QUEUED && step.dependencies.every(depId => completedIds.has(depId)))
            .map(item => item.index);

        while (this.state.activeWorkers < this.config.maxParallelism && runnableIndices.length > 0) {
            const index = runnableIndices.shift();
            if (index !== undefined) {
                this.state.activeWorkers++;
                const assignedAgent = this.config.agentProfiles[index % this.config.agentProfiles.length];
                this.updateStepStatus(index, AgentStatus.QUEUED, { assignedAgentId: assignedAgent.id });
                this.notify();
                this.executeStep(index, assignedAgent).then(() => {
                    this.state.activeWorkers--;
                    this.processQueue();
                });
            }
        }
    }

    private async executeStep(index: number, agent: AgentProfile) {
        const step = this.state.decomposition[index];
        let worktreeInfo: { branch: string, path: string } | null = null;
        const vfs = VirtualFileSystem.getInstance();

        try {
            if (this.config.useGitWorktrees) {
                this.updateStepStatus(index, AgentStatus.IDLE);
                try {
                    worktreeInfo = await this.git.createWorktree(this.state.taskId, step.id);
                    this.updateStepStatus(index, AgentStatus.ANALYZING, { gitBranch: worktreeInfo.branch, worktreePath: worktreeInfo.path });
                } catch (e: any) {
                    console.error("[MakerEngine] Worktree Creation Failed:", e);
                    this.updateStepStatus(index, AgentStatus.FAILED, { logs: [`Worktree failed: ${e.message}`] });
                    return;
                }
            } else {
                this.updateStepStatus(index, AgentStatus.ANALYZING);
            }

            if (step.toolCall) {
                this.updateStepStatus(index, AgentStatus.EXECUTING);
                const toolDef = this.config.tools?.find(t => t.name === step.toolCall?.toolName);

                if (!toolDef) {
                    throw new Error(`Tool '${step.toolCall.toolName}' not found in registry.`);
                }

                const cwd = worktreeInfo ? worktreeInfo.path : vfs.getRoot() || ".";

                const outputFile = step.fileTarget && !step.fileTarget.endsWith('.ts') ? step.fileTarget : undefined;

                const output = await this.toolService.executeTool(toolDef, step.toolCall, cwd, outputFile);

                this.updateStepStatus(index, AgentStatus.PASSED, {
                    logs: [`Tool Executed: ${output.substring(0, 200)}...`]
                });
                this.state.completedSteps++;

                if (this.config.useGitWorktrees && worktreeInfo) {
                    await this.git.mergeWorktreeToMain(worktreeInfo.branch, `Executed Tool: ${step.description}`);
                    await this.git.cleanupWorktree(worktreeInfo.path, worktreeInfo.branch);
                }
                this.notify();
                return;
            }

            const riskAssessment = await this.assessRisk(step, agent);
            this.updateStepStatus(index, AgentStatus.THINKING, { riskScore: riskAssessment.score, riskReason: riskAssessment.reason });

            const dependencyFiles = this.state.decomposition
                .filter(s => step.dependencies.includes(s.id))
                .map(s => s.fileTarget);

            let context = await this.contextManager.getTaskContext(step.fileTarget, dependencyFiles);

            const shouldVote = riskAssessment.score > Math.min(this.config.riskThreshold, agent.riskTolerance + 0.3);
            let content = "";

            if (shouldVote && this.llm) {
                this.updateStepStatus(index, AgentStatus.VOTING);
                const result = await this.voter.performVoting(step, agent, context, this.config.agentProfiles,
                    (a) => this.generateCode(step, a, context)
                );
                this.updateStepStatus(index, AgentStatus.VOTING, { candidates: result.candidates });

                if (!result.isConsensus || !result.winner) {
                    content = result.candidates.find(c => c.agentName === agent.name)?.content || "";
                    if (!content) throw new Error("Consensus failed.");
                } else {
                    content = result.winner;
                }
            } else {
                this.updateStepStatus(index, AgentStatus.SKIPPED_VOTE);
                content = await this.generateCode(step, agent, context);
            }

            this.updateStepStatus(index, AgentStatus.EXECUTING);
            const targetPath = worktreeInfo ? `${worktreeInfo.path}/${step.fileTarget}` : step.fileTarget;

            const dir = targetPath.substring(0, targetPath.lastIndexOf('/'));
            if (dir && dir !== '.') await MockTauriService.mkdir(dir);

            await MockTauriService.writeFile(targetPath, content);

            const provider = this.langRegistry.getProvider(targetPath);
            let lintAttempts = 0;
            const maxLintAttempts = this.config.autoFixLinter ? 2 : 0;
            let isLintValid = false;

            while (!isLintValid) {
                const lintErrors = provider ? await provider.lintFile(targetPath, vfs.getRoot() || ".") : [];

                if (lintErrors.length === 0) {
                    isLintValid = true;
                    break;
                }

                if (lintErrors.some(e => e.includes('SECURITY:'))) {
                    throw new Error(`Security Check Failed: ${lintErrors.find(e => e.includes('SECURITY:'))}`);
                }

                if (lintAttempts < maxLintAttempts) {
                    const errorMsg = lintErrors[0];
                    const expandedContext = await this.contextManager.expandContext(errorMsg);
                    if (expandedContext) context += expandedContext;

                    this.updateStepStatus(index, AgentStatus.EXECUTING, {
                        logs: [...(this.state.decomposition[index].logs || []), `[AutoFix] ${provider?.id} Linter failed: ${errorMsg}. Retrying...`]
                    });

                    content = await this.generateCode(step, agent, context, lintErrors.join('\n'));
                    await MockTauriService.writeFile(targetPath, content);
                    lintAttempts++;
                } else {
                    console.log("Triggering Re-plan due to persistent lint errors...");
                    const newSteps = await this.decomposer.replan(step, lintErrors.join('\n'));

                    if (newSteps.length > 0) {
                        const safeNewSteps = newSteps.map(s => ({
                            id: s.id || `rescue-${Math.random().toString(36).substr(2, 5)}`,
                            description: s.description || "Rescue Step",
                            fileTarget: s.fileTarget || step.fileTarget,
                            status: AgentStatus.QUEUED,
                            attempts: 0,
                            votes: 0,
                            riskScore: 0,
                            logs: ["Re-planned from failed parent"],
                            dependencies: s.dependencies || step.dependencies,
                            candidates: []
                        }));

                        const newDecomp = [...this.state.decomposition];
                        newDecomp.splice(index, 1, ...safeNewSteps);

                        this.state.decomposition = newDecomp;
                        this.state.totalSteps = newDecomp.length;

                        if (worktreeInfo && this.config.useGitWorktrees) {
                            await this.git.cleanupWorktree(worktreeInfo.path, worktreeInfo.branch);
                        }

                        this.notify();
                        return;
                    } else {
                        throw new Error(`${provider?.id || 'System'} Linter validation failed: ${lintErrors[0]}`);
                    }
                }
            }

            this.updateStepStatus(index, AgentStatus.CHECKPOINTING);
            if (this.config.useGitWorktrees && worktreeInfo) {
                this.updateStepStatus(index, AgentStatus.MERGING);
                const mergeSuccess = await this.git.mergeWorktreeToMain(worktreeInfo.branch, step.description);
                if (!mergeSuccess) throw new Error("Merge Conflict.");
                await this.git.cleanupWorktree(worktreeInfo.path, worktreeInfo.branch);
            } else {
                await this.git.createCheckpoint(step.description, [step.fileTarget]);
            }

            this.updateStepStatus(index, AgentStatus.PASSED);
            this.state.completedSteps++;

        } catch (e: any) {
            // LOGGING FIX: Capture execution failures
            console.error(`[MakerEngine] Step ${index} Failed:`, e);

            this.failStep(index, e.message || "Unknown error");
            if (worktreeInfo && this.config.useGitWorktrees) {
                await this.git.cleanupWorktree(worktreeInfo.path, worktreeInfo.branch);
            }
        } finally {
            this.notify();
        }
    }

    private async generateCode(step: SubTask, agent: AgentProfile, context: string, feedback?: string): Promise<string> {
        if (!this.llm) return `// Mock Content`;
        try {
            const systemPrompt = `
                ROLE: You are ${agent.name}, a ${agent.role} engineer.
                TASK: Write the code for file "${step.fileTarget}".
                CONTEXT: Use idiomatic patterns for the target language. Write FULL file content.
            `;
            const userPrompt = `
                DESCRIPTION: ${step.description}
                --- RELEVANT CODEBASE CONTEXT ---
                ${context}
                ${feedback ? `--- PREVIOUS ERRORS (FIX THESE) ---\n${feedback}` : ''}
            `;
            const response = await this.llm.generate(systemPrompt, userPrompt);
            let text = response.text || "";
            if (text.startsWith('```')) text = text.replace(/^```[a-z]*\n/i, '').replace(/\n```$/, '');
            return text;
        } catch (e) {
            console.warn("AI Generation failed:", e);
            return "// Generation Failed";
        }
    }

    private async assessRisk(step: SubTask, agent: AgentProfile): Promise<{ score: number, reason: string }> {
        const isLogic = step.description.toLowerCase().includes("implement") || step.description.toLowerCase().includes("logic");
        let baseScore = isLogic ? 0.85 : 0.2;
        if (agent.role === 'Security' && (step.description.includes('Auth') || step.description.includes('JWT'))) {
            baseScore += 0.3;
            return { score: Math.min(0.99, baseScore), reason: `${agent.name} flagged security critical component` };
        }
        return { score: baseScore, reason: isLogic ? "Business Logic" : "Boilerplate/Scaffold" };
    }

    private failStep(index: number, reason: string) {
        const newDecomp = [...this.state.decomposition];
        newDecomp[index] = { ...newDecomp[index], status: AgentStatus.FAILED, logs: [...newDecomp[index].logs, reason] };
        this.state.decomposition = newDecomp;
        this.state.errorCount++;
        this.notify();
    }

    private updateStepStatus(index: number, status: AgentStatus, extra: Partial<SubTask> = {}) {
        const newDecomp = [...this.state.decomposition];
        newDecomp[index] = { ...newDecomp[index], status, ...extra };
        this.state.decomposition = newDecomp;
        this.notify();
    }
}
</file>

<file path="src/services/toolService.ts">
import { ToolDefinition, ToolCall } from "../types";
import { MockTauriService } from "./tauriBridge";

export class ToolService {
    private static instance: ToolService;

    private constructor() { }

    public static getInstance(): ToolService {
        if (!ToolService.instance) {
            ToolService.instance = new ToolService();
        }
        return ToolService.instance;
    }

    /**
     * Executes a tool and optionally writes output to a target file.
     */
    async executeTool(tool: ToolDefinition, call: ToolCall, cwd: string, outputFile?: string): Promise<string> {
        console.log(`[ToolService] Executing ${tool.name} in ${cwd}`);

        // 1. Interpolate Arguments
        let commandStr = tool.command;
        for (const [key, value] of Object.entries(call.arguments)) {
            const safeValue = value.replace(/"/g, '\\"');
            commandStr = commandStr.replace(new RegExp(`{{${key}}}`, 'g'), safeValue);
        }

        // 2. Parse Command
        const parts = commandStr.match(/(?:[^\s"]+|"[^"]*")+/g)?.map(s => s.replace(/"/g, '')) || [];
        if (parts.length === 0) throw new Error("Tool command empty.");

        const cmd = parts[0];
        const args = parts.slice(1);

        // 3. Execute
        try {
            const output = await MockTauriService.executeShell(cmd, args, cwd);

            // 4. Output Redirection (Context Persistence)
            if (outputFile && outputFile !== 'stdout' && outputFile !== 'stderr') {
                console.log(`[ToolService] Saving output to ${outputFile}`);
                // Ensure path is absolute or relative to cwd
                const targetPath = outputFile.startsWith('/') ? outputFile : `${cwd}/${outputFile}`;
                await MockTauriService.writeFile(targetPath, output);
            }

            return output;
        } catch (e: any) {
            throw new Error(`Tool execution failed: ${e.message}`);
        }
    }

    validateToolCall(tool: ToolDefinition, call: ToolCall): string | null {
        const matches = tool.command.match(/{{(.*?)}}/g);
        if (!matches) return null;

        for (const match of matches) {
            const key = match.replace(/{{|}}/g, '');
            if (!call.arguments[key]) {
                return `Missing argument: ${key}`;
            }
        }
        return null;
    }
}
</file>

<file path="src/App.tsx">
import React, { useState, useEffect, useCallback, useRef } from 'react';
import {
  Play,
  Terminal as TerminalIcon,
  FileCode,
  Layers,
  Cpu,
  ShieldCheck,
  Activity,
  FolderOpen,
  Settings,
  GitGraph,
  Bot,
  CheckCircle,
  Edit2,
  AlertTriangle,
  FileText,
  Save
} from 'lucide-react';
import { MakerVisualizer } from './components/MakerVisualizer';
import { TerminalView } from './components/TerminalView';
import { FileExplorer } from './components/FileExplorer';
import { SettingsPanel } from './components/SettingsPanel';
import { VersionControl } from './components/VersionControl';
import { CodeEditor } from './components/CodeEditor';
import { AgentManager } from './components/AgentManager';
import { PlanEditor } from './components/PlanEditor';
import { ToastContainer, ToastMessage } from './components/Toast';
import { SystemLogs } from './components/SystemLogs';
import { MakerEngine } from './services/makerService';
import { TaskStatus, MakerConfig, AgentStatus, SubTask } from './types';
import { MockTauriService } from './services/tauriBridge';
import { VirtualFileSystem } from './services/virtualFileSystem';
import { ProjectService } from './services/projectService';
import { GitService } from './services/gitService';

export default function App() {
  const [prompt, setPrompt] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [makerState, setMakerState] = useState<TaskStatus | null>(null);
  const [activeTab, setActiveTab] = useState<'editor' | 'visualizer' | 'git' | 'agents'>('visualizer');
  const [bottomTab, setBottomTab] = useState<'terminal' | 'logs'>('terminal');
  const [showSettings, setShowSettings] = useState(false);
  const [showPlanEditor, setShowPlanEditor] = useState(false);
  const [activeFile, setActiveFile] = useState<string | null>(null);
  const [projectPath, setProjectPath] = useState<string | null>(null);
  const [isDirty, setIsDirty] = useState(false);
  const [isQuickSaving, setIsQuickSaving] = useState(false);

  const [toasts, setToasts] = useState<ToastMessage[]>([]);

  const [config, setConfig] = useState<MakerConfig>({
    llmProvider: 'gemini',
    geminiApiKey: "",
    openaiBaseUrl: "https://api.openai.com/v1",
    openaiModel: "gpt-4o",
    riskThreshold: 0.6,
    maxAgents: 3,
    autoFixLinter: true,
    useGitWorktrees: false,
    maxParallelism: 1,
    agentProfiles: [
      { id: "1", name: "Atlas", role: "Architect", riskTolerance: 0.3, color: "text-purple-400", model: "gemini-2.0-flash" },
      { id: "2", name: "Bolt", role: "Developer", riskTolerance: 0.7, color: "text-blue-400", model: "gemini-2.0-flash" },
      { id: "3", name: "Cipher", role: "Security", riskTolerance: 0.1, color: "text-red-400", model: "gemini-2.0-flash" },
      { id: "4", name: "Dash", role: "QA", riskTolerance: 0.4, color: "text-green-400", model: "gemini-2.0-flash" }
    ],
    tools: []
  });

  const engineRef = useRef<MakerEngine | null>(null);

  const addToast = (type: 'success' | 'error' | 'info', message: string) => {
    const id = Math.random().toString(36).substring(2);
    setToasts(prev => [...prev, { id, type, message }]);
  };

  const removeToast = (id: string) => {
    setToasts(prev => prev.filter(t => t.id !== id));
  };

  // --- STARTUP HEALTH CHECK ---
  useEffect(() => {
    const verifySystem = async () => {
      try {
        const version = await MockTauriService.executeShell('git', ['--version']);
        console.log(`[Health] Git detected: ${version.trim()}`);
        addToast('success', `System Ready: ${version.trim()}`);
      } catch (e: any) {
        console.error("[Health] Git check failed:", JSON.stringify(e, Object.getOwnPropertyNames(e)));
        const msg = e.message || JSON.stringify(e);
        addToast('error', `CRITICAL: Git not accessible. ${msg}`);
      }
    };
    setTimeout(verifySystem, 1000);
  }, []);

  useEffect(() => {
    const checkGit = async () => {
      if (projectPath) {
        const status = await GitService.getInstance().getStatus();
        setIsDirty(status.isDirty);
      }
    };
    const interval = setInterval(checkGit, 5000);
    return () => clearInterval(interval);
  }, [projectPath]);

  useEffect(() => {
    engineRef.current = new MakerEngine();
    const unsubscribe = engineRef.current.subscribe((state) => {
      setMakerState(state);
      if (state.errorCount > (makerState?.errorCount || 0)) {
        addToast('error', 'An error occurred during execution. Check logs.');
      }
    });
    return () => unsubscribe();
  }, []);

  const handleConfigUpdate = async (newConfig: Partial<MakerConfig>) => {
    console.log("[App] Updating Config:", JSON.stringify(newConfig, null, 2));
    setConfig(prev => {
      const next = { ...prev, ...newConfig };
      if (engineRef.current) {
        engineRef.current.updateConfig(next);
      }
      if (projectPath) {
        ProjectService.saveConfig(projectPath, next)
          .catch(err => console.error("Failed to auto-save config", err));
      }
      return next;
    });
  };

  const handleQuickSave = async () => {
    setIsQuickSaving(true);
    try {
      await GitService.getInstance().commitAll("WIP: Quick Save before Maker Task");
      addToast('success', 'Changes saved successfully.');
      setIsDirty(false); // Optimistic update
    } catch (e: any) {
      addToast('error', `Quick Save Failed: ${e.message}`);
    } finally {
      setIsQuickSaving(false);
    }
  };

  const handleStartMaker = useCallback(async () => {
    if (!prompt.trim() || !engineRef.current) {
      addToast('error', 'Please enter a task description.');
      return;
    }

    const hasKey = config.llmProvider === 'openai'
      ? !!config.openaiApiKey
      : !!config.geminiApiKey;

    if (!hasKey) {
      addToast('error', `Missing API Key for ${config.llmProvider.toUpperCase()}. Check Settings.`);
      setShowSettings(true);
      return;
    }

    if (isDirty) {
      addToast('error', 'Repo has uncommitted changes. Please commit or stash first.');
      setActiveTab('git');
      return;
    }

    setIsProcessing(true);
    addToast('info', 'Analyzing task requirements...');

    try {
      engineRef.current.updateConfig(config);
      await engineRef.current.startTask(prompt);
      addToast('success', 'Plan generated. Please review.');
    } catch (error: any) {
      console.error("Task failed:", error);
      addToast('error', `Task initialization failed: ${error.message}`);
    } finally {
      setIsProcessing(false);
    }
  }, [prompt, config, isDirty]);

  const handleExecutePlan = useCallback(() => {
    if (engineRef.current) {
      engineRef.current.executePlan();
      addToast('info', 'Execution started. Agents deployed.');
    }
  }, []);

  const handlePlanUpdate = (updatedSteps: SubTask[]) => {
    if (engineRef.current && makerState) {
      (engineRef.current as any).state.decomposition = updatedSteps;
      (engineRef.current as any).state.totalSteps = updatedSteps.length;
      (engineRef.current as any).notify();
      addToast('success', 'Plan updated successfully.');
    }
  };

  const handleOpenFile = async () => {
    const path = await MockTauriService.openDialog();
    if (path) {
      setProjectPath(path);
      const vfs = VirtualFileSystem.getInstance();
      vfs.setRoot(path);

      addToast('info', `Opened project: ${path}`);

      const savedConfig = await ProjectService.loadConfig(path);
      if (savedConfig) {
        setConfig(savedConfig);
        engineRef.current?.updateConfig(savedConfig);
        addToast('success', 'Loaded project configuration.');
      } else {
        await ProjectService.ensureMakerDirectory(path);
        await ProjectService.saveConfig(path, config);
      }
    }
  };

  const handleSelectFile = (path: string) => {
    setActiveFile(path);
    setActiveTab('editor');
  };

  const isPlanning = makerState?.isPlanning || false;

  return (
    <div className="flex h-screen w-full bg-gray-950 text-gray-300 font-sans selection:bg-indigo-500/30 relative">
      <ToastContainer toasts={toasts} onDismiss={removeToast} />

      {showPlanEditor && makerState && (
        <PlanEditor
          steps={makerState.decomposition}
          onUpdate={handlePlanUpdate}
          onClose={() => setShowPlanEditor(false)}
        />
      )}

      {/* Sidebar */}
      <div className="w-64 border-r border-gray-800 bg-gray-900 flex flex-col">
        <div className="h-12 flex items-center px-4 border-b border-gray-800 font-bold text-indigo-400 gap-2">
          <Cpu size={20} />
          <span>MAKER<span className="text-gray-500">.code</span></span>
        </div>

        <div className="flex-1 overflow-y-auto p-2">
          <div className="mb-4">
            <button
              onClick={handleOpenFile}
              className="w-full flex items-center gap-2 px-3 py-2 text-sm bg-gray-800 hover:bg-gray-700 rounded-sm transition-colors text-gray-300"
            >
              <FolderOpen size={14} />
              <span className="truncate">{projectPath ? projectPath.split(/[/\\]/).pop() : "Open Project"}</span>
            </button>
            {projectPath && <div className="text-[10px] text-gray-600 px-3 mt-1 truncate">{projectPath}</div>}
          </div>
          <div className="text-xs font-semibold text-gray-500 uppercase mb-2 px-2">Explorer</div>
          <FileExplorer onSelectFile={handleSelectFile} activeFile={activeFile} />
        </div>

        <div className="p-4 border-t border-gray-800 text-xs text-gray-500">
          <div className="flex items-center gap-2 mb-1">
            <div className={`w-2 h-2 rounded-full ${makerState?.activeWorkers ? 'bg-green-500 animate-pulse' : 'bg-gray-600'}`}></div>
            Status: {makerState?.activeWorkers ? 'Agent Active' : 'Idle'}
          </div>
          <div>Mode: Tauri v2 / Strict</div>
        </div>
      </div>

      {/* Main Content Area */}
      <div className="flex-1 flex flex-col min-w-0">

        {/* Top Bar / Navigation */}
        <div className="h-12 border-b border-gray-800 bg-gray-900 flex items-center justify-between px-4">
          <div className="flex items-center gap-4">
            <button onClick={() => setActiveTab('visualizer')} className={`flex items-center gap-2 px-3 py-1.5 rounded-sm text-sm transition-colors ${activeTab === 'visualizer' ? 'bg-indigo-600/20 text-indigo-300' : 'hover:bg-gray-800'}`}>
              <Activity size={16} /> MAKER Visualizer
            </button>
            <button onClick={() => setActiveTab('git')} className={`flex items-center gap-2 px-3 py-1.5 rounded-sm text-sm transition-colors ${activeTab === 'git' ? 'bg-indigo-600/20 text-indigo-300' : 'hover:bg-gray-800'}`}>
              <GitGraph size={16} /> Version Control
              {isDirty && <span className="w-2 h-2 rounded-full bg-yellow-500 animate-pulse" title="Unsaved Changes"></span>}
            </button>
            <button onClick={() => setActiveTab('editor')} className={`flex items-center gap-2 px-3 py-1.5 rounded-sm text-sm transition-colors ${activeTab === 'editor' ? 'bg-indigo-600/20 text-indigo-300' : 'hover:bg-gray-800'}`}>
              <FileCode size={16} /> Code Editor
            </button>
          </div>

          <div className="flex items-center gap-6">
            <div className="flex items-center gap-2 text-xs text-gray-500">
              <ShieldCheck size={14} className="text-green-500" />
              <span>Adaptive Consensus: {config.riskThreshold < 1 ? 'Active' : 'Disabled'}</span>
            </div>
            <div className="h-6 w-px bg-gray-800"></div>
            <button onClick={() => setActiveTab('agents')} className={`flex items-center gap-2 px-3 py-1.5 rounded-sm text-sm transition-colors ${activeTab === 'agents' ? 'bg-teal-600/20 text-teal-300 border border-teal-500/30' : 'hover:bg-gray-800 text-gray-400'}`}>
              <Bot size={16} /> Agent Manager
              {makerState?.activeWorkers ? (
                <span className="bg-teal-500 text-gray-900 text-[10px] font-bold px-1.5 rounded-full">{makerState.activeWorkers}</span>
              ) : null}
            </button>
          </div>
        </div>

        {/* Dynamic Content */}
        <div className="flex-1 overflow-hidden relative bg-gray-950 flex flex-col">
          {activeTab === 'visualizer' && <div className="flex-1 relative overflow-hidden"><MakerVisualizer state={makerState} config={config} /></div>}
          {activeTab === 'git' && <VersionControl addToast={addToast} />}
          {activeTab === 'editor' && <CodeEditor activeFile={activeFile} />}
          {activeTab === 'agents' && <div className="flex-1 p-8 overflow-y-auto"><div className="max-w-4xl mx-auto"><AgentManager activeWorkers={makerState?.activeWorkers || 0} maxParallelism={config.maxParallelism} activeTasks={makerState ? makerState.decomposition.filter(t => t.status === AgentStatus.EXECUTING) : []} agentProfiles={config.agentProfiles} onConfigUpdate={handleConfigUpdate} /></div></div>}

          <div className="border-t border-gray-800 bg-gray-900 p-4 z-20">
            <div className="max-w-4xl mx-auto flex gap-4">
              <div className="flex-1 relative">
                <textarea
                  value={prompt}
                  onChange={(e) => setPrompt(e.target.value)}
                  placeholder={isDirty ? "Commit changes in 'Version Control' before starting a new task." : "Describe the task. Example: 'Refactor the authentication logic in src/auth.ts to use JWTs and add error handling.'"}
                  disabled={isDirty}
                  className={`w-full bg-gray-950 border rounded-lg p-3 text-sm focus:ring-1 outline-hidden resize-none h-24 font-mono transition-colors ${isDirty ? 'border-yellow-900/50 text-gray-500 cursor-not-allowed' : 'border-gray-700 text-gray-300 focus:border-indigo-500 focus:ring-indigo-500'}`}
                />
                <div className="absolute bottom-3 right-3 text-xs flex items-center gap-2">
                  {isDirty && (
                    <div className="flex items-center gap-2">
                      <span className="text-yellow-500 flex items-center gap-1 font-bold"><AlertTriangle size={12} /> Unsaved Changes</span>
                      <button
                        onClick={handleQuickSave}
                        disabled={isQuickSaving}
                        className="flex items-center gap-1 bg-yellow-600 hover:bg-yellow-500 text-white px-2 py-1 rounded-sm text-[10px] font-bold uppercase transition-colors"
                      >
                        {isQuickSaving ? <Activity size={10} className="animate-spin" /> : <Save size={10} />}
                        Quick Save
                      </button>
                    </div>
                  )}
                  <span className="text-gray-600">MAKER Framework Enabled</span>
                </div>
              </div>
              <div className="flex flex-col gap-2 justify-between relative">
                <div className="relative">
                  <button onClick={() => setShowSettings(!showSettings)} className={`p-2 rounded-sm hover:bg-gray-800 transition-colors ${showSettings ? 'text-indigo-400 bg-gray-800' : 'text-gray-500'}`}>
                    <Settings size={18} />
                  </button>
                  <SettingsPanel config={config} onUpdate={handleConfigUpdate} isOpen={showSettings} onToggle={() => setShowSettings(!showSettings)} />
                </div>

                {isPlanning ? (
                  <div className="flex gap-2">
                    <button onClick={() => setShowPlanEditor(true)} className="h-10 px-4 rounded-lg font-medium text-sm bg-gray-700 hover:bg-gray-600 text-gray-200 transition-all flex items-center gap-2"><Edit2 size={16} /> Edit Plan</button>
                    <button onClick={handleExecutePlan} className="h-10 px-6 rounded-lg font-medium text-sm flex items-center gap-2 transition-all bg-green-600 hover:bg-green-500 text-white shadow-lg shadow-green-500/20"><CheckCircle size={16} /> Approve</button>
                  </div>
                ) : (
                  <button onClick={handleStartMaker} disabled={isProcessing || makerState?.activeWorkers > 0 || isDirty} className={`h-10 px-6 rounded-lg font-medium text-sm flex items-center gap-2 transition-all ${(isProcessing || makerState?.activeWorkers > 0 || isDirty) ? 'bg-gray-700 text-gray-500 cursor-not-allowed' : 'bg-indigo-600 hover:bg-indigo-500 text-white shadow-lg shadow-indigo-500/20'}`}>
                    {makerState?.activeWorkers > 0 ? <Activity className="animate-spin" size={16} /> : <Play size={16} />}
                    {makerState?.activeWorkers > 0 ? 'Executing...' : 'Start Task'}
                  </button>
                )}
              </div>
            </div>
          </div>
        </div>

        {/* Bottom Panel */}
        <div className="h-64 border-t border-gray-800 bg-gray-900 flex flex-col">
          <div className="flex items-center h-8 bg-gray-900 border-b border-gray-800 px-2 gap-2">
            <button
              onClick={() => setBottomTab('terminal')}
              className={`flex items-center gap-2 px-3 py-1 text-xs rounded-t-sm transition-colors ${bottomTab === 'terminal' ? 'bg-gray-800 text-gray-200 border-t border-x border-gray-700' : 'text-gray-500 hover:bg-gray-800/50'}`}
            >
              <TerminalIcon size={12} /> Terminal
            </button>
            <button
              onClick={() => setBottomTab('logs')}
              className={`flex items-center gap-2 px-3 py-1 text-xs rounded-t-sm transition-colors ${bottomTab === 'logs' ? 'bg-gray-800 text-gray-200 border-t border-x border-gray-700' : 'text-gray-500 hover:bg-gray-800/50'}`}
            >
              <FileText size={12} /> System Logs
            </button>
          </div>
          <div className="flex-1 p-0 overflow-hidden relative">
            {bottomTab === 'terminal' && <TerminalView />}
            {bottomTab === 'logs' && <SystemLogs />}
          </div>
        </div>
      </div>
    </div>
  );
}
</file>

</files>
